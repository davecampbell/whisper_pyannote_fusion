{
  "whisper_outputs": [
    {
      "text": " Hey, what's up everyone? This is Sam. In today's interview, part of our guest host series, you'll hear a conversation led by longtime friend of the show, John Bohannon, Director of Science at Primer AI, and former journalist for publications like Science Magazine, Wired, and others. I'm sure you're going to enjoy this conversation, so let's jump in. Peace.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 1.36,
          "text": " Hey, what's up everyone?",
          "tokens": [
            50364,
            1911,
            11,
            437,
            311,
            493,
            1518,
            30,
            50432
          ],
          "temperature": 0.0,
          "avg_logprob": -0.22669623238699776,
          "compression_ratio": 1.4552845528455285,
          "no_speech_prob": 0.00021835140069015324
        },
        {
          "id": 1,
          "seek": 0,
          "start": 1.36,
          "end": 2.62,
          "text": " This is Sam.",
          "tokens": [
            50432,
            639,
            307,
            4832,
            13,
            50495
          ],
          "temperature": 0.0,
          "avg_logprob": -0.22669623238699776,
          "compression_ratio": 1.4552845528455285,
          "no_speech_prob": 0.00021835140069015324
        },
        {
          "id": 2,
          "seek": 0,
          "start": 2.62,
          "end": 5.5600000000000005,
          "text": " In today's interview, part of our guest host series,",
          "tokens": [
            50495,
            682,
            965,
            311,
            4049,
            11,
            644,
            295,
            527,
            8341,
            3975,
            2638,
            11,
            50642
          ],
          "temperature": 0.0,
          "avg_logprob": -0.22669623238699776,
          "compression_ratio": 1.4552845528455285,
          "no_speech_prob": 0.00021835140069015324
        },
        {
          "id": 3,
          "seek": 0,
          "start": 5.5600000000000005,
          "end": 8.120000000000001,
          "text": " you'll hear a conversation led by longtime friend",
          "tokens": [
            50642,
            291,
            603,
            1568,
            257,
            3761,
            4684,
            538,
            44363,
            1277,
            50770
          ],
          "temperature": 0.0,
          "avg_logprob": -0.22669623238699776,
          "compression_ratio": 1.4552845528455285,
          "no_speech_prob": 0.00021835140069015324
        },
        {
          "id": 4,
          "seek": 0,
          "start": 8.120000000000001,
          "end": 10.040000000000001,
          "text": " of the show, John Bohannon,",
          "tokens": [
            50770,
            295,
            264,
            855,
            11,
            2619,
            32484,
            16138,
            11,
            50866
          ],
          "temperature": 0.0,
          "avg_logprob": -0.22669623238699776,
          "compression_ratio": 1.4552845528455285,
          "no_speech_prob": 0.00021835140069015324
        },
        {
          "id": 5,
          "seek": 0,
          "start": 10.040000000000001,
          "end": 12.48,
          "text": " Director of Science at Primer AI,",
          "tokens": [
            50866,
            7680,
            295,
            8976,
            412,
            2114,
            9713,
            7318,
            11,
            50988
          ],
          "temperature": 0.0,
          "avg_logprob": -0.22669623238699776,
          "compression_ratio": 1.4552845528455285,
          "no_speech_prob": 0.00021835140069015324
        },
        {
          "id": 6,
          "seek": 0,
          "start": 12.48,
          "end": 14.32,
          "text": " and former journalist for publications",
          "tokens": [
            50988,
            293,
            5819,
            17277,
            337,
            25618,
            51080
          ],
          "temperature": 0.0,
          "avg_logprob": -0.22669623238699776,
          "compression_ratio": 1.4552845528455285,
          "no_speech_prob": 0.00021835140069015324
        },
        {
          "id": 7,
          "seek": 0,
          "start": 14.32,
          "end": 17.36,
          "text": " like Science Magazine, Wired, and others.",
          "tokens": [
            51080,
            411,
            8976,
            27618,
            11,
            343,
            1824,
            11,
            293,
            2357,
            13,
            51232
          ],
          "temperature": 0.0,
          "avg_logprob": -0.22669623238699776,
          "compression_ratio": 1.4552845528455285,
          "no_speech_prob": 0.00021835140069015324
        },
        {
          "id": 8,
          "seek": 0,
          "start": 17.36,
          "end": 19.6,
          "text": " I'm sure you're going to enjoy this conversation,",
          "tokens": [
            51232,
            286,
            478,
            988,
            291,
            434,
            516,
            281,
            2103,
            341,
            3761,
            11,
            51344
          ],
          "temperature": 0.0,
          "avg_logprob": -0.22669623238699776,
          "compression_ratio": 1.4552845528455285,
          "no_speech_prob": 0.00021835140069015324
        },
        {
          "id": 9,
          "seek": 0,
          "start": 19.6,
          "end": 21.28,
          "text": " so let's jump in.",
          "tokens": [
            51344,
            370,
            718,
            311,
            3012,
            294,
            13,
            51428
          ],
          "temperature": 0.0,
          "avg_logprob": -0.22669623238699776,
          "compression_ratio": 1.4552845528455285,
          "no_speech_prob": 0.00021835140069015324
        },
        {
          "id": 10,
          "seek": 0,
          "start": 21.28,
          "end": 22.12,
          "text": " Peace.",
          "tokens": [
            51428,
            13204,
            13,
            51470
          ],
          "temperature": 0.0,
          "avg_logprob": -0.22669623238699776,
          "compression_ratio": 1.4552845528455285,
          "no_speech_prob": 0.00021835140069015324
        }
      ],
      "language": "en"
    },
    {
      "text": "",
      "segments": [],
      "language": "en"
    },
    {
      "text": " Good morning, Marti.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 1.0,
          "text": " Good morning, Marti.",
          "tokens": [
            50364,
            2205,
            2446,
            11,
            5807,
            72,
            13,
            50414
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3724486298031277,
          "compression_ratio": 0.7142857142857143,
          "no_speech_prob": 0.0009726276621222496
        }
      ],
      "language": "en"
    },
    {
      "text": " Good morning, John.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 1.2,
          "text": " Good morning, John.",
          "tokens": [
            50364,
            2205,
            2446,
            11,
            2619,
            13,
            50424
          ],
          "temperature": 0.0,
          "avg_logprob": -0.5942682027816772,
          "compression_ratio": 0.7037037037037037,
          "no_speech_prob": 0.003791950875893235
        }
      ],
      "language": "en"
    },
    {
      "text": " So we are just a few miles away from each other across a body of water. I'm in San Francisco. You're across the bay in Berkeley at your office at University of California Berkeley, where you are the head of the School of Information and a computer scientist who's been in the game for many decades.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 5.5200000000000005,
          "text": " So we are just a few miles away from each other across a body of water. I'm in San Francisco.",
          "tokens": [
            50364,
            407,
            321,
            366,
            445,
            257,
            1326,
            6193,
            1314,
            490,
            1184,
            661,
            2108,
            257,
            1772,
            295,
            1281,
            13,
            286,
            478,
            294,
            5271,
            12279,
            13,
            50640
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2577340073055691,
          "compression_ratio": 1.4752475247524752,
          "no_speech_prob": 0.0004016684542875737
        },
        {
          "id": 1,
          "seek": 0,
          "start": 5.5200000000000005,
          "end": 11.200000000000001,
          "text": " You're across the bay in Berkeley at your office at University of California Berkeley, where you",
          "tokens": [
            50640,
            509,
            434,
            2108,
            264,
            13642,
            294,
            23684,
            412,
            428,
            3398,
            412,
            3535,
            295,
            5384,
            23684,
            11,
            689,
            291,
            50924
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2577340073055691,
          "compression_ratio": 1.4752475247524752,
          "no_speech_prob": 0.0004016684542875737
        },
        {
          "id": 2,
          "seek": 0,
          "start": 11.200000000000001,
          "end": 16.080000000000002,
          "text": " are the head of the School of Information and a computer scientist who's been in the game for",
          "tokens": [
            50924,
            366,
            264,
            1378,
            295,
            264,
            5070,
            295,
            15357,
            293,
            257,
            3820,
            12662,
            567,
            311,
            668,
            294,
            264,
            1216,
            337,
            51168
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2577340073055691,
          "compression_ratio": 1.4752475247524752,
          "no_speech_prob": 0.0004016684542875737
        },
        {
          "id": 3,
          "seek": 0,
          "start": 16.080000000000002,
          "end": 16.96,
          "text": " many decades.",
          "tokens": [
            51168,
            867,
            7878,
            13,
            51212
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2577340073055691,
          "compression_ratio": 1.4752475247524752,
          "no_speech_prob": 0.0004016684542875737
        }
      ],
      "language": "en"
    },
    {
      "text": " That's right.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 0.84,
          "text": " That's right.",
          "tokens": [
            50364,
            663,
            311,
            558,
            13,
            50406
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3592292240687779,
          "compression_ratio": 0.6190476190476191,
          "no_speech_prob": 0.0024532638490200043
        }
      ],
      "language": "en"
    },
    {
      "text": " So I'm excited to finally do this interview because it's been almost a year in the making. We had a great interview here on the show with Orin Etzioni, and former head of AI2 in Seattle. And after that interview, I asked Orin, who would be a really good guest who would have something worth sharing with the audience? And you were the first person he said.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 4.64,
          "text": " So I'm excited to finally do this interview because it's been almost a year in the making.",
          "tokens": [
            50364,
            407,
            286,
            478,
            2919,
            281,
            2721,
            360,
            341,
            4049,
            570,
            309,
            311,
            668,
            1920,
            257,
            1064,
            294,
            264,
            1455,
            13,
            50596
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24553058458411176,
          "compression_ratio": 1.5411255411255411,
          "no_speech_prob": 0.0018877435941249132
        },
        {
          "id": 1,
          "seek": 0,
          "start": 4.64,
          "end": 8.16,
          "text": " We had a great interview here on the show with Orin Etzioni,",
          "tokens": [
            50596,
            492,
            632,
            257,
            869,
            4049,
            510,
            322,
            264,
            855,
            365,
            1610,
            259,
            3790,
            89,
            15273,
            11,
            50772
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24553058458411176,
          "compression_ratio": 1.5411255411255411,
          "no_speech_prob": 0.0018877435941249132
        },
        {
          "id": 2,
          "seek": 0,
          "start": 8.16,
          "end": 12.96,
          "text": " and former head of AI2 in Seattle. And after that interview, I asked Orin,",
          "tokens": [
            50772,
            293,
            5819,
            1378,
            295,
            7318,
            17,
            294,
            15721,
            13,
            400,
            934,
            300,
            4049,
            11,
            286,
            2351,
            1610,
            259,
            11,
            51012
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24553058458411176,
          "compression_ratio": 1.5411255411255411,
          "no_speech_prob": 0.0018877435941249132
        },
        {
          "id": 3,
          "seek": 0,
          "start": 12.96,
          "end": 17.28,
          "text": " who would be a really good guest who would have something worth sharing with the audience?",
          "tokens": [
            51012,
            567,
            576,
            312,
            257,
            534,
            665,
            8341,
            567,
            576,
            362,
            746,
            3163,
            5414,
            365,
            264,
            4034,
            30,
            51228
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24553058458411176,
          "compression_ratio": 1.5411255411255411,
          "no_speech_prob": 0.0018877435941249132
        },
        {
          "id": 4,
          "seek": 0,
          "start": 17.28,
          "end": 19.12,
          "text": " And you were the first person he said.",
          "tokens": [
            51228,
            400,
            291,
            645,
            264,
            700,
            954,
            415,
            848,
            13,
            51320
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24553058458411176,
          "compression_ratio": 1.5411255411255411,
          "no_speech_prob": 0.0018877435941249132
        }
      ],
      "language": "en"
    },
    {
      "text": " Well, I listened to that interview and it was an excellent interview. Oren is so articulate and you're a great interviewer. And I'm really honored to be here. And I'm really honored that Oren thought it was worthwhile to recommend me.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 3.0,
          "text": " Well, I listened to that interview and it was an excellent interview.",
          "tokens": [
            50364,
            1042,
            11,
            286,
            13207,
            281,
            300,
            4049,
            293,
            309,
            390,
            364,
            7103,
            4049,
            13,
            50514
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2622594208013816,
          "compression_ratio": 1.6137931034482758,
          "no_speech_prob": 7.742291927570477e-05
        },
        {
          "id": 1,
          "seek": 0,
          "start": 3.0,
          "end": 5.9,
          "text": " Oren is so articulate and you're a great interviewer.",
          "tokens": [
            50514,
            422,
            1095,
            307,
            370,
            30305,
            293,
            291,
            434,
            257,
            869,
            4049,
            260,
            13,
            50659
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2622594208013816,
          "compression_ratio": 1.6137931034482758,
          "no_speech_prob": 7.742291927570477e-05
        },
        {
          "id": 2,
          "seek": 0,
          "start": 5.9,
          "end": 8.1,
          "text": " And I'm really honored to be here.",
          "tokens": [
            50659,
            400,
            286,
            478,
            534,
            14556,
            281,
            312,
            510,
            13,
            50769
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2622594208013816,
          "compression_ratio": 1.6137931034482758,
          "no_speech_prob": 7.742291927570477e-05
        },
        {
          "id": 3,
          "seek": 0,
          "start": 8.1,
          "end": 12.200000000000001,
          "text": " And I'm really honored that Oren thought it was worthwhile to recommend me.",
          "tokens": [
            50769,
            400,
            286,
            478,
            534,
            14556,
            300,
            422,
            1095,
            1194,
            309,
            390,
            28159,
            281,
            2748,
            385,
            13,
            50974
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2622594208013816,
          "compression_ratio": 1.6137931034482758,
          "no_speech_prob": 7.742291927570477e-05
        }
      ],
      "language": "en"
    },
    {
      "text": " And you don't do that many interviews, from what I gather.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 2.8000000000000003,
          "text": " And you don't do that many interviews, from what I gather.",
          "tokens": [
            50364,
            400,
            291,
            500,
            380,
            360,
            300,
            867,
            12318,
            11,
            490,
            437,
            286,
            5448,
            13,
            50504
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3519699433270623,
          "compression_ratio": 0.9354838709677419,
          "no_speech_prob": 0.00036708201514557004
        }
      ],
      "language": "en"
    },
    {
      "text": " No, I don't. I'm a little bit camera shy, even though I do have to be on camera a lot. Also, I like to be pretty careful about what I say, kind of more from the scientist's perspective. I think Oren is really great at linking science to business and where technology is going. But yeah, I guess I'm just a little bit shy that way.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 6.16,
          "text": " No, I don't. I'm a little bit camera shy, even though I do have to be on camera a lot.",
          "tokens": [
            50364,
            883,
            11,
            286,
            500,
            380,
            13,
            286,
            478,
            257,
            707,
            857,
            2799,
            12685,
            11,
            754,
            1673,
            286,
            360,
            362,
            281,
            312,
            322,
            2799,
            257,
            688,
            13,
            50672
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21457547081841363,
          "compression_ratio": 1.5348837209302326,
          "no_speech_prob": 0.00026909232838079333
        },
        {
          "id": 1,
          "seek": 0,
          "start": 6.16,
          "end": 12.4,
          "text": " Also, I like to be pretty careful about what I say, kind of more from the scientist's perspective.",
          "tokens": [
            50672,
            2743,
            11,
            286,
            411,
            281,
            312,
            1238,
            5026,
            466,
            437,
            286,
            584,
            11,
            733,
            295,
            544,
            490,
            264,
            12662,
            311,
            4585,
            13,
            50984
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21457547081841363,
          "compression_ratio": 1.5348837209302326,
          "no_speech_prob": 0.00026909232838079333
        },
        {
          "id": 2,
          "seek": 0,
          "start": 12.4,
          "end": 18.72,
          "text": " I think Oren is really great at linking science to business and where technology is going.",
          "tokens": [
            50984,
            286,
            519,
            422,
            1095,
            307,
            534,
            869,
            412,
            25775,
            3497,
            281,
            1606,
            293,
            689,
            2899,
            307,
            516,
            13,
            51300
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21457547081841363,
          "compression_ratio": 1.5348837209302326,
          "no_speech_prob": 0.00026909232838079333
        },
        {
          "id": 3,
          "seek": 0,
          "start": 18.72,
          "end": 21.2,
          "text": " But yeah, I guess I'm just a little bit shy that way.",
          "tokens": [
            51300,
            583,
            1338,
            11,
            286,
            2041,
            286,
            478,
            445,
            257,
            707,
            857,
            12685,
            300,
            636,
            13,
            51424
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21457547081841363,
          "compression_ratio": 1.5348837209302326,
          "no_speech_prob": 0.00026909232838079333
        }
      ],
      "language": "en"
    },
    {
      "text": " And that brings me to kind of the big story here for those listening at home. Marty and I had a chat recently in advance of this interview, just to talk about what we might talk about. And something really striking was that there's this moment, let's call it the Chat GPT moment. It's really the large language model moment where artificial intelligence seems to be at some kind of inflection point. And you told me about your long career and how you have kind of seen these moments before, and you're more cautious about speaking publicly to add to the hype cycle because it's often disappointing and often regrettable. You know, it's easy to say things that you later think were overhyped. Why is this different?",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 3.84,
          "text": " And that brings me to kind of the big story here for those listening at home.",
          "tokens": [
            50364,
            400,
            300,
            5607,
            385,
            281,
            733,
            295,
            264,
            955,
            1657,
            510,
            337,
            729,
            4764,
            412,
            1280,
            13,
            50556
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2508854173187517,
          "compression_ratio": 1.6928571428571428,
          "no_speech_prob": 0.03666495159268379
        },
        {
          "id": 1,
          "seek": 0,
          "start": 3.92,
          "end": 8.32,
          "text": " Marty and I had a chat recently in advance of this interview, just to talk",
          "tokens": [
            50560,
            29192,
            293,
            286,
            632,
            257,
            5081,
            3938,
            294,
            7295,
            295,
            341,
            4049,
            11,
            445,
            281,
            751,
            50780
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2508854173187517,
          "compression_ratio": 1.6928571428571428,
          "no_speech_prob": 0.03666495159268379
        },
        {
          "id": 2,
          "seek": 0,
          "start": 8.32,
          "end": 9.4,
          "text": " about what we might talk about.",
          "tokens": [
            50780,
            466,
            437,
            321,
            1062,
            751,
            466,
            13,
            50834
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2508854173187517,
          "compression_ratio": 1.6928571428571428,
          "no_speech_prob": 0.03666495159268379
        },
        {
          "id": 3,
          "seek": 0,
          "start": 9.72,
          "end": 14.4,
          "text": " And something really striking was that there's this moment, let's",
          "tokens": [
            50850,
            400,
            746,
            534,
            18559,
            390,
            300,
            456,
            311,
            341,
            1623,
            11,
            718,
            311,
            51084
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2508854173187517,
          "compression_ratio": 1.6928571428571428,
          "no_speech_prob": 0.03666495159268379
        },
        {
          "id": 4,
          "seek": 0,
          "start": 14.4,
          "end": 15.84,
          "text": " call it the Chat GPT moment.",
          "tokens": [
            51084,
            818,
            309,
            264,
            27503,
            26039,
            51,
            1623,
            13,
            51156
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2508854173187517,
          "compression_ratio": 1.6928571428571428,
          "no_speech_prob": 0.03666495159268379
        },
        {
          "id": 5,
          "seek": 0,
          "start": 16.080000000000002,
          "end": 20.68,
          "text": " It's really the large language model moment where artificial intelligence seems",
          "tokens": [
            51168,
            467,
            311,
            534,
            264,
            2416,
            2856,
            2316,
            1623,
            689,
            11677,
            7599,
            2544,
            51398
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2508854173187517,
          "compression_ratio": 1.6928571428571428,
          "no_speech_prob": 0.03666495159268379
        },
        {
          "id": 6,
          "seek": 0,
          "start": 20.68,
          "end": 22.44,
          "text": " to be at some kind of inflection point.",
          "tokens": [
            51398,
            281,
            312,
            412,
            512,
            733,
            295,
            1536,
            5450,
            935,
            13,
            51486
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2508854173187517,
          "compression_ratio": 1.6928571428571428,
          "no_speech_prob": 0.03666495159268379
        },
        {
          "id": 7,
          "seek": 0,
          "start": 22.84,
          "end": 28.28,
          "text": " And you told me about your long career and how you have kind of seen these",
          "tokens": [
            51506,
            400,
            291,
            1907,
            385,
            466,
            428,
            938,
            3988,
            293,
            577,
            291,
            362,
            733,
            295,
            1612,
            613,
            51778
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2508854173187517,
          "compression_ratio": 1.6928571428571428,
          "no_speech_prob": 0.03666495159268379
        },
        {
          "id": 8,
          "seek": 2828,
          "start": 28.28,
          "end": 32.44,
          "text": " moments before, and you're more cautious about speaking publicly to add to the",
          "tokens": [
            50364,
            6065,
            949,
            11,
            293,
            291,
            434,
            544,
            25278,
            466,
            4124,
            14843,
            281,
            909,
            281,
            264,
            50572
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21862514948440812,
          "compression_ratio": 1.4397590361445782,
          "no_speech_prob": 0.0029803684446960688
        },
        {
          "id": 9,
          "seek": 2828,
          "start": 32.44,
          "end": 36.28,
          "text": " hype cycle because it's often disappointing and often regrettable.",
          "tokens": [
            50572,
            24144,
            6586,
            570,
            309,
            311,
            2049,
            25054,
            293,
            2049,
            10879,
            23811,
            13,
            50764
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21862514948440812,
          "compression_ratio": 1.4397590361445782,
          "no_speech_prob": 0.0029803684446960688
        },
        {
          "id": 10,
          "seek": 2828,
          "start": 36.480000000000004,
          "end": 39.84,
          "text": " You know, it's easy to say things that you later think were overhyped.",
          "tokens": [
            50774,
            509,
            458,
            11,
            309,
            311,
            1858,
            281,
            584,
            721,
            300,
            291,
            1780,
            519,
            645,
            670,
            3495,
            3452,
            13,
            50942
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21862514948440812,
          "compression_ratio": 1.4397590361445782,
          "no_speech_prob": 0.0029803684446960688
        },
        {
          "id": 11,
          "seek": 2828,
          "start": 40.04,
          "end": 40.88,
          "text": " Why is this different?",
          "tokens": [
            50952,
            1545,
            307,
            341,
            819,
            30,
            50994
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21862514948440812,
          "compression_ratio": 1.4397590361445782,
          "no_speech_prob": 0.0029803684446960688
        }
      ],
      "language": "en"
    },
    {
      "text": " Yeah, so I have seen a lot over the years. I've been, I'd say, primarily in natural language processing, that part of AI. And, you know, it's just been a slog in terms of making progress in having machines be able to process language the way people do. I entered it really because I was interested in the brain and interested in language. And I thought it'd be kind of neat if we could have a computer do something with language, maybe, you know, make cartoons speak, something like that. Animation interested me as well. We're so far from accomplishing anything that would be realistic, that was more of a scientific endeavor. I think I'm more of a scientist at heart than, you know, I'm not an entrepreneur, for example. So I've seen claims, for example, I remember, I guess, in the early 90s, there was this claim that Oracle bought some NLP company and it was going to transform everything. And, you know, and it was just so obviously ludicrous. But you also see, you know, I remember when WebFountain came out with IBM, and that was going to transform everything. And, you know, it's very much.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 2.4,
          "text": " Yeah, so I have seen a lot over the years.",
          "tokens": [
            50364,
            865,
            11,
            370,
            286,
            362,
            1612,
            257,
            688,
            670,
            264,
            924,
            13,
            50484
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2645039379148555,
          "compression_ratio": 1.754208754208754,
          "no_speech_prob": 0.02512214332818985
        },
        {
          "id": 1,
          "seek": 0,
          "start": 2.4,
          "end": 6.8,
          "text": " I've been, I'd say, primarily in natural language processing, that part of AI.",
          "tokens": [
            50484,
            286,
            600,
            668,
            11,
            286,
            1116,
            584,
            11,
            10029,
            294,
            3303,
            2856,
            9007,
            11,
            300,
            644,
            295,
            7318,
            13,
            50704
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2645039379148555,
          "compression_ratio": 1.754208754208754,
          "no_speech_prob": 0.02512214332818985
        },
        {
          "id": 2,
          "seek": 0,
          "start": 6.8,
          "end": 12.64,
          "text": " And, you know, it's just been a slog in terms of making progress in having machines be able",
          "tokens": [
            50704,
            400,
            11,
            291,
            458,
            11,
            309,
            311,
            445,
            668,
            257,
            49760,
            294,
            2115,
            295,
            1455,
            4205,
            294,
            1419,
            8379,
            312,
            1075,
            50996
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2645039379148555,
          "compression_ratio": 1.754208754208754,
          "no_speech_prob": 0.02512214332818985
        },
        {
          "id": 3,
          "seek": 0,
          "start": 12.64,
          "end": 15.08,
          "text": " to process language the way people do.",
          "tokens": [
            50996,
            281,
            1399,
            2856,
            264,
            636,
            561,
            360,
            13,
            51118
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2645039379148555,
          "compression_ratio": 1.754208754208754,
          "no_speech_prob": 0.02512214332818985
        },
        {
          "id": 4,
          "seek": 0,
          "start": 15.08,
          "end": 18.84,
          "text": " I entered it really because I was interested in the brain and interested in language.",
          "tokens": [
            51118,
            286,
            9065,
            309,
            534,
            570,
            286,
            390,
            3102,
            294,
            264,
            3567,
            293,
            3102,
            294,
            2856,
            13,
            51306
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2645039379148555,
          "compression_ratio": 1.754208754208754,
          "no_speech_prob": 0.02512214332818985
        },
        {
          "id": 5,
          "seek": 0,
          "start": 18.84,
          "end": 23.16,
          "text": " And I thought it'd be kind of neat if we could have a computer do something with language,",
          "tokens": [
            51306,
            400,
            286,
            1194,
            309,
            1116,
            312,
            733,
            295,
            10654,
            498,
            321,
            727,
            362,
            257,
            3820,
            360,
            746,
            365,
            2856,
            11,
            51522
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2645039379148555,
          "compression_ratio": 1.754208754208754,
          "no_speech_prob": 0.02512214332818985
        },
        {
          "id": 6,
          "seek": 0,
          "start": 23.16,
          "end": 26.92,
          "text": " maybe, you know, make cartoons speak, something like that.",
          "tokens": [
            51522,
            1310,
            11,
            291,
            458,
            11,
            652,
            34855,
            1710,
            11,
            746,
            411,
            300,
            13,
            51710
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2645039379148555,
          "compression_ratio": 1.754208754208754,
          "no_speech_prob": 0.02512214332818985
        },
        {
          "id": 7,
          "seek": 0,
          "start": 26.92,
          "end": 27.92,
          "text": " Animation interested me as well.",
          "tokens": [
            51710,
            44635,
            3102,
            385,
            382,
            731,
            13,
            51760
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2645039379148555,
          "compression_ratio": 1.754208754208754,
          "no_speech_prob": 0.02512214332818985
        },
        {
          "id": 8,
          "seek": 2792,
          "start": 28.32,
          "end": 34.480000000000004,
          "text": " We're so far from accomplishing anything that would be realistic, that was more of a scientific",
          "tokens": [
            50384,
            492,
            434,
            370,
            1400,
            490,
            6548,
            3807,
            1340,
            300,
            576,
            312,
            12465,
            11,
            300,
            390,
            544,
            295,
            257,
            8134,
            50692
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2539268991221552,
          "compression_ratio": 1.705298013245033,
          "no_speech_prob": 0.035133522003889084
        },
        {
          "id": 9,
          "seek": 2792,
          "start": 34.480000000000004,
          "end": 35.480000000000004,
          "text": " endeavor.",
          "tokens": [
            50692,
            34975,
            13,
            50742
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2539268991221552,
          "compression_ratio": 1.705298013245033,
          "no_speech_prob": 0.035133522003889084
        },
        {
          "id": 10,
          "seek": 2792,
          "start": 35.480000000000004,
          "end": 39.400000000000006,
          "text": " I think I'm more of a scientist at heart than, you know, I'm not an entrepreneur, for example.",
          "tokens": [
            50742,
            286,
            519,
            286,
            478,
            544,
            295,
            257,
            12662,
            412,
            1917,
            813,
            11,
            291,
            458,
            11,
            286,
            478,
            406,
            364,
            14307,
            11,
            337,
            1365,
            13,
            50938
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2539268991221552,
          "compression_ratio": 1.705298013245033,
          "no_speech_prob": 0.035133522003889084
        },
        {
          "id": 11,
          "seek": 2792,
          "start": 39.400000000000006,
          "end": 44.32,
          "text": " So I've seen claims, for example, I remember, I guess, in the early 90s, there was this",
          "tokens": [
            50938,
            407,
            286,
            600,
            1612,
            9441,
            11,
            337,
            1365,
            11,
            286,
            1604,
            11,
            286,
            2041,
            11,
            294,
            264,
            2440,
            4289,
            82,
            11,
            456,
            390,
            341,
            51184
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2539268991221552,
          "compression_ratio": 1.705298013245033,
          "no_speech_prob": 0.035133522003889084
        },
        {
          "id": 12,
          "seek": 2792,
          "start": 44.32,
          "end": 49.08,
          "text": " claim that Oracle bought some NLP company and it was going to transform everything.",
          "tokens": [
            51184,
            3932,
            300,
            25654,
            4243,
            512,
            426,
            45196,
            2237,
            293,
            309,
            390,
            516,
            281,
            4088,
            1203,
            13,
            51422
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2539268991221552,
          "compression_ratio": 1.705298013245033,
          "no_speech_prob": 0.035133522003889084
        },
        {
          "id": 13,
          "seek": 2792,
          "start": 49.08,
          "end": 52.92,
          "text": " And, you know, and it was just so obviously ludicrous.",
          "tokens": [
            51422,
            400,
            11,
            291,
            458,
            11,
            293,
            309,
            390,
            445,
            370,
            2745,
            15946,
            299,
            21189,
            13,
            51614
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2539268991221552,
          "compression_ratio": 1.705298013245033,
          "no_speech_prob": 0.035133522003889084
        },
        {
          "id": 14,
          "seek": 2792,
          "start": 52.92,
          "end": 56.64,
          "text": " But you also see, you know, I remember when WebFountain came out with IBM, and that was",
          "tokens": [
            51614,
            583,
            291,
            611,
            536,
            11,
            291,
            458,
            11,
            286,
            1604,
            562,
            9573,
            37,
            22838,
            1361,
            484,
            365,
            23487,
            11,
            293,
            300,
            390,
            51800
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2539268991221552,
          "compression_ratio": 1.705298013245033,
          "no_speech_prob": 0.035133522003889084
        },
        {
          "id": 15,
          "seek": 5664,
          "start": 56.72,
          "end": 58.480000000000004,
          "text": " going to transform everything.",
          "tokens": [
            50368,
            516,
            281,
            4088,
            1203,
            13,
            50456
          ],
          "temperature": 0.0,
          "avg_logprob": -0.5165975570678711,
          "compression_ratio": 0.9384615384615385,
          "no_speech_prob": 0.9555801153182983
        },
        {
          "id": 16,
          "seek": 5664,
          "start": 58.480000000000004,
          "end": 59.88,
          "text": " And, you know, it's very much.",
          "tokens": [
            50456,
            400,
            11,
            291,
            458,
            11,
            309,
            311,
            588,
            709,
            13,
            50526
          ],
          "temperature": 0.0,
          "avg_logprob": -0.5165975570678711,
          "compression_ratio": 0.9384615384615385,
          "no_speech_prob": 0.9555801153182983
        }
      ],
      "language": "en"
    },
    {
      "text": " Or how about IBM Watson?",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 1.6,
          "text": " Or how about IBM Watson?",
          "tokens": [
            50364,
            1610,
            577,
            466,
            23487,
            25640,
            30,
            50444
          ],
          "temperature": 0.0,
          "avg_logprob": -0.510582341088189,
          "compression_ratio": 0.75,
          "no_speech_prob": 0.001090947655029595
        }
      ],
      "language": "en"
    },
    {
      "text": " Well, you know, Watson was a special case in that it was amazing what they did with Jeopardy, and we can talk about that a bit more. But then there was the claim that it was going to transform healthcare. And again, there was no path from that to directly to healthcare being transformed in the immediate future. So I learned that if you read the New York Times regularly, as I do, technology is in the business section, as opposed to the science section. And that's kind of how technology is talked about in, at least in the US. And of course, there is scientific reporting on it. And your podcast, I think is wonderful, and that it goes into a lot of technical details, which is really exciting. But there's always the business angle when it comes to technology, even when I started out in the late 80s. And, you know, at most there were PCs.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 4.96,
          "text": " Well, you know, Watson was a special case in that it was amazing what they did with Jeopardy,",
          "tokens": [
            50364,
            1042,
            11,
            291,
            458,
            11,
            25640,
            390,
            257,
            2121,
            1389,
            294,
            300,
            309,
            390,
            2243,
            437,
            436,
            630,
            365,
            2588,
            22918,
            88,
            11,
            50612
          ],
          "temperature": 0.0,
          "avg_logprob": -0.18453397506322616,
          "compression_ratio": 1.7464285714285714,
          "no_speech_prob": 0.01998383179306984
        },
        {
          "id": 1,
          "seek": 0,
          "start": 4.96,
          "end": 9.68,
          "text": " and we can talk about that a bit more. But then there was the claim that it was going to transform",
          "tokens": [
            50612,
            293,
            321,
            393,
            751,
            466,
            300,
            257,
            857,
            544,
            13,
            583,
            550,
            456,
            390,
            264,
            3932,
            300,
            309,
            390,
            516,
            281,
            4088,
            50848
          ],
          "temperature": 0.0,
          "avg_logprob": -0.18453397506322616,
          "compression_ratio": 1.7464285714285714,
          "no_speech_prob": 0.01998383179306984
        },
        {
          "id": 2,
          "seek": 0,
          "start": 9.68,
          "end": 14.96,
          "text": " healthcare. And again, there was no path from that to directly to healthcare being transformed in the",
          "tokens": [
            50848,
            8884,
            13,
            400,
            797,
            11,
            456,
            390,
            572,
            3100,
            490,
            300,
            281,
            3838,
            281,
            8884,
            885,
            16894,
            294,
            264,
            51112
          ],
          "temperature": 0.0,
          "avg_logprob": -0.18453397506322616,
          "compression_ratio": 1.7464285714285714,
          "no_speech_prob": 0.01998383179306984
        },
        {
          "id": 3,
          "seek": 0,
          "start": 14.96,
          "end": 21.28,
          "text": " immediate future. So I learned that if you read the New York Times regularly, as I do, technology",
          "tokens": [
            51112,
            11629,
            2027,
            13,
            407,
            286,
            3264,
            300,
            498,
            291,
            1401,
            264,
            1873,
            3609,
            11366,
            11672,
            11,
            382,
            286,
            360,
            11,
            2899,
            51428
          ],
          "temperature": 0.0,
          "avg_logprob": -0.18453397506322616,
          "compression_ratio": 1.7464285714285714,
          "no_speech_prob": 0.01998383179306984
        },
        {
          "id": 4,
          "seek": 0,
          "start": 21.28,
          "end": 26.400000000000002,
          "text": " is in the business section, as opposed to the science section. And that's kind of how technology",
          "tokens": [
            51428,
            307,
            294,
            264,
            1606,
            3541,
            11,
            382,
            8851,
            281,
            264,
            3497,
            3541,
            13,
            400,
            300,
            311,
            733,
            295,
            577,
            2899,
            51684
          ],
          "temperature": 0.0,
          "avg_logprob": -0.18453397506322616,
          "compression_ratio": 1.7464285714285714,
          "no_speech_prob": 0.01998383179306984
        },
        {
          "id": 5,
          "seek": 2640,
          "start": 26.4,
          "end": 31.919999999999998,
          "text": " is talked about in, at least in the US. And of course, there is scientific reporting on it. And",
          "tokens": [
            50364,
            307,
            2825,
            466,
            294,
            11,
            412,
            1935,
            294,
            264,
            2546,
            13,
            400,
            295,
            1164,
            11,
            456,
            307,
            8134,
            10031,
            322,
            309,
            13,
            400,
            50640
          ],
          "temperature": 0.0,
          "avg_logprob": -0.22985007736709093,
          "compression_ratio": 1.51931330472103,
          "no_speech_prob": 0.014277633279561996
        },
        {
          "id": 6,
          "seek": 2640,
          "start": 31.919999999999998,
          "end": 36.0,
          "text": " your podcast, I think is wonderful, and that it goes into a lot of technical details, which is",
          "tokens": [
            50640,
            428,
            7367,
            11,
            286,
            519,
            307,
            3715,
            11,
            293,
            300,
            309,
            1709,
            666,
            257,
            688,
            295,
            6191,
            4365,
            11,
            597,
            307,
            50844
          ],
          "temperature": 0.0,
          "avg_logprob": -0.22985007736709093,
          "compression_ratio": 1.51931330472103,
          "no_speech_prob": 0.014277633279561996
        },
        {
          "id": 7,
          "seek": 2640,
          "start": 36.0,
          "end": 40.48,
          "text": " really exciting. But there's always the business angle when it comes to technology, even when I",
          "tokens": [
            50844,
            534,
            4670,
            13,
            583,
            456,
            311,
            1009,
            264,
            1606,
            5802,
            562,
            309,
            1487,
            281,
            2899,
            11,
            754,
            562,
            286,
            51068
          ],
          "temperature": 0.0,
          "avg_logprob": -0.22985007736709093,
          "compression_ratio": 1.51931330472103,
          "no_speech_prob": 0.014277633279561996
        },
        {
          "id": 8,
          "seek": 2640,
          "start": 40.48,
          "end": 44.879999999999995,
          "text": " started out in the late 80s. And, you know, at most there were PCs.",
          "tokens": [
            51068,
            1409,
            484,
            294,
            264,
            3469,
            4688,
            82,
            13,
            400,
            11,
            291,
            458,
            11,
            412,
            881,
            456,
            645,
            46913,
            13,
            51288
          ],
          "temperature": 0.0,
          "avg_logprob": -0.22985007736709093,
          "compression_ratio": 1.51931330472103,
          "no_speech_prob": 0.014277633279561996
        }
      ],
      "language": "en"
    },
    {
      "text": "",
      "segments": [],
      "language": "en"
    },
    {
      "text": "",
      "segments": [],
      "language": "en"
    },
    {
      "text": " Well, in the late eighties and into the nineties, you became one of the main researchers in search and search really defined the era that I think is probably coming to a close, the Google era, the era of search, search driving everything. And so you did really see the business side of your research explode and change the world. Are we in a moment like that now?",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 4.44,
          "text": " Well, in the late eighties and into the nineties, you became one of the main",
          "tokens": [
            50364,
            1042,
            11,
            294,
            264,
            3469,
            3180,
            530,
            293,
            666,
            264,
            9616,
            43469,
            11,
            291,
            3062,
            472,
            295,
            264,
            2135,
            50586
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2546419206556383,
          "compression_ratio": 1.6805555555555556,
          "no_speech_prob": 0.00010379014565842226
        },
        {
          "id": 1,
          "seek": 0,
          "start": 4.44,
          "end": 9.36,
          "text": " researchers in search and search really defined the era that I think is probably",
          "tokens": [
            50586,
            10309,
            294,
            3164,
            293,
            3164,
            534,
            7642,
            264,
            4249,
            300,
            286,
            519,
            307,
            1391,
            50832
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2546419206556383,
          "compression_ratio": 1.6805555555555556,
          "no_speech_prob": 0.00010379014565842226
        },
        {
          "id": 2,
          "seek": 0,
          "start": 9.36,
          "end": 14.0,
          "text": " coming to a close, the Google era, the era of search, search driving everything.",
          "tokens": [
            50832,
            1348,
            281,
            257,
            1998,
            11,
            264,
            3329,
            4249,
            11,
            264,
            4249,
            295,
            3164,
            11,
            3164,
            4840,
            1203,
            13,
            51064
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2546419206556383,
          "compression_ratio": 1.6805555555555556,
          "no_speech_prob": 0.00010379014565842226
        },
        {
          "id": 3,
          "seek": 0,
          "start": 14.64,
          "end": 18.76,
          "text": " And so you did really see the business side of your research",
          "tokens": [
            51096,
            400,
            370,
            291,
            630,
            534,
            536,
            264,
            1606,
            1252,
            295,
            428,
            2132,
            51302
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2546419206556383,
          "compression_ratio": 1.6805555555555556,
          "no_speech_prob": 0.00010379014565842226
        },
        {
          "id": 4,
          "seek": 0,
          "start": 18.92,
          "end": 20.32,
          "text": " explode and change the world.",
          "tokens": [
            51310,
            21411,
            293,
            1319,
            264,
            1002,
            13,
            51380
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2546419206556383,
          "compression_ratio": 1.6805555555555556,
          "no_speech_prob": 0.00010379014565842226
        },
        {
          "id": 5,
          "seek": 0,
          "start": 20.64,
          "end": 22.0,
          "text": " Are we in a moment like that now?",
          "tokens": [
            51396,
            2014,
            321,
            294,
            257,
            1623,
            411,
            300,
            586,
            30,
            51464
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2546419206556383,
          "compression_ratio": 1.6805555555555556,
          "no_speech_prob": 0.00010379014565842226
        }
      ],
      "language": "en"
    },
    {
      "text": " Well, I wouldn't mind talking about search for a few minutes since it is close to my heart. I mean, I was interested in search because I wanted to be able to find things. I didn't like the library catalog when I was a little kid. And in fact, when I was an intern, I tried to be an intern in my public library in high school and I was rejected because I wasn't fast enough with filing alphabetically in the card catalog. But I never thought that makes sense. So actually I always wanted to do a dynamic, smart version of the card catalog, which is what I did in search user interfaces. There's only one spot in the bookshelf for the book representation. What I focused on was search user interfaces. I wouldn't say I was the leading person in search, but I was a leader in search user interfaces, which was kind of a hybrid topic at the time because most of the search field was more on algorithms and not so much on the user interface. So I brought those two together. And that was super exciting because the technology or the kind of framework that I advocated for and showed empirically worked, did become the standard for, it's still a standard faceted interaction like what you see on a website when you're shopping or library catalogs where you can slice and dice and filter in different ways to find the items that you want. Getting that interface to work well was the big challenge and that was sort of the breakthrough.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 2.48,
          "text": " Well, I wouldn't mind talking about search for a few minutes",
          "tokens": [
            50364,
            1042,
            11,
            286,
            2759,
            380,
            1575,
            1417,
            466,
            3164,
            337,
            257,
            1326,
            2077,
            50488
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19223246996915794,
          "compression_ratio": 1.8512658227848102,
          "no_speech_prob": 0.02883506566286087
        },
        {
          "id": 1,
          "seek": 0,
          "start": 2.48,
          "end": 4.32,
          "text": " since it is close to my heart.",
          "tokens": [
            50488,
            1670,
            309,
            307,
            1998,
            281,
            452,
            1917,
            13,
            50580
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19223246996915794,
          "compression_ratio": 1.8512658227848102,
          "no_speech_prob": 0.02883506566286087
        },
        {
          "id": 2,
          "seek": 0,
          "start": 4.32,
          "end": 5.8,
          "text": " I mean, I was interested in search",
          "tokens": [
            50580,
            286,
            914,
            11,
            286,
            390,
            3102,
            294,
            3164,
            50654
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19223246996915794,
          "compression_ratio": 1.8512658227848102,
          "no_speech_prob": 0.02883506566286087
        },
        {
          "id": 3,
          "seek": 0,
          "start": 5.8,
          "end": 7.72,
          "text": " because I wanted to be able to find things.",
          "tokens": [
            50654,
            570,
            286,
            1415,
            281,
            312,
            1075,
            281,
            915,
            721,
            13,
            50750
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19223246996915794,
          "compression_ratio": 1.8512658227848102,
          "no_speech_prob": 0.02883506566286087
        },
        {
          "id": 4,
          "seek": 0,
          "start": 7.72,
          "end": 10.08,
          "text": " I didn't like the library catalog when I was a little kid.",
          "tokens": [
            50750,
            286,
            994,
            380,
            411,
            264,
            6405,
            19746,
            562,
            286,
            390,
            257,
            707,
            1636,
            13,
            50868
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19223246996915794,
          "compression_ratio": 1.8512658227848102,
          "no_speech_prob": 0.02883506566286087
        },
        {
          "id": 5,
          "seek": 0,
          "start": 10.08,
          "end": 11.6,
          "text": " And in fact, when I was an intern,",
          "tokens": [
            50868,
            400,
            294,
            1186,
            11,
            562,
            286,
            390,
            364,
            2154,
            11,
            50944
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19223246996915794,
          "compression_ratio": 1.8512658227848102,
          "no_speech_prob": 0.02883506566286087
        },
        {
          "id": 6,
          "seek": 0,
          "start": 11.6,
          "end": 15.120000000000001,
          "text": " I tried to be an intern in my public library in high school",
          "tokens": [
            50944,
            286,
            3031,
            281,
            312,
            364,
            2154,
            294,
            452,
            1908,
            6405,
            294,
            1090,
            1395,
            51120
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19223246996915794,
          "compression_ratio": 1.8512658227848102,
          "no_speech_prob": 0.02883506566286087
        },
        {
          "id": 7,
          "seek": 0,
          "start": 15.120000000000001,
          "end": 17.32,
          "text": " and I was rejected because I wasn't fast enough",
          "tokens": [
            51120,
            293,
            286,
            390,
            15749,
            570,
            286,
            2067,
            380,
            2370,
            1547,
            51230
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19223246996915794,
          "compression_ratio": 1.8512658227848102,
          "no_speech_prob": 0.02883506566286087
        },
        {
          "id": 8,
          "seek": 0,
          "start": 17.32,
          "end": 19.76,
          "text": " with filing alphabetically in the card catalog.",
          "tokens": [
            51230,
            365,
            26854,
            23339,
            984,
            294,
            264,
            2920,
            19746,
            13,
            51352
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19223246996915794,
          "compression_ratio": 1.8512658227848102,
          "no_speech_prob": 0.02883506566286087
        },
        {
          "id": 9,
          "seek": 0,
          "start": 19.76,
          "end": 21.240000000000002,
          "text": " But I never thought that makes sense.",
          "tokens": [
            51352,
            583,
            286,
            1128,
            1194,
            300,
            1669,
            2020,
            13,
            51426
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19223246996915794,
          "compression_ratio": 1.8512658227848102,
          "no_speech_prob": 0.02883506566286087
        },
        {
          "id": 10,
          "seek": 0,
          "start": 21.240000000000002,
          "end": 23.48,
          "text": " So actually I always wanted to do a dynamic,",
          "tokens": [
            51426,
            407,
            767,
            286,
            1009,
            1415,
            281,
            360,
            257,
            8546,
            11,
            51538
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19223246996915794,
          "compression_ratio": 1.8512658227848102,
          "no_speech_prob": 0.02883506566286087
        },
        {
          "id": 11,
          "seek": 0,
          "start": 23.48,
          "end": 25.84,
          "text": " smart version of the card catalog,",
          "tokens": [
            51538,
            4069,
            3037,
            295,
            264,
            2920,
            19746,
            11,
            51656
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19223246996915794,
          "compression_ratio": 1.8512658227848102,
          "no_speech_prob": 0.02883506566286087
        },
        {
          "id": 12,
          "seek": 0,
          "start": 25.84,
          "end": 28.36,
          "text": " which is what I did in search user interfaces.",
          "tokens": [
            51656,
            597,
            307,
            437,
            286,
            630,
            294,
            3164,
            4195,
            28416,
            13,
            51782
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19223246996915794,
          "compression_ratio": 1.8512658227848102,
          "no_speech_prob": 0.02883506566286087
        },
        {
          "id": 13,
          "seek": 2836,
          "start": 28.36,
          "end": 30.36,
          "text": " There's only one spot in the bookshelf",
          "tokens": [
            50364,
            821,
            311,
            787,
            472,
            4008,
            294,
            264,
            1446,
            46626,
            50464
          ],
          "temperature": 0.0,
          "avg_logprob": -0.16436913177257276,
          "compression_ratio": 1.7380952380952381,
          "no_speech_prob": 0.0002378151984885335
        },
        {
          "id": 14,
          "seek": 2836,
          "start": 30.36,
          "end": 32.12,
          "text": " for the book representation.",
          "tokens": [
            50464,
            337,
            264,
            1446,
            10290,
            13,
            50552
          ],
          "temperature": 0.0,
          "avg_logprob": -0.16436913177257276,
          "compression_ratio": 1.7380952380952381,
          "no_speech_prob": 0.0002378151984885335
        },
        {
          "id": 15,
          "seek": 2836,
          "start": 32.12,
          "end": 34.24,
          "text": " What I focused on was search user interfaces.",
          "tokens": [
            50552,
            708,
            286,
            5178,
            322,
            390,
            3164,
            4195,
            28416,
            13,
            50658
          ],
          "temperature": 0.0,
          "avg_logprob": -0.16436913177257276,
          "compression_ratio": 1.7380952380952381,
          "no_speech_prob": 0.0002378151984885335
        },
        {
          "id": 16,
          "seek": 2836,
          "start": 34.24,
          "end": 36.44,
          "text": " I wouldn't say I was the leading person in search,",
          "tokens": [
            50658,
            286,
            2759,
            380,
            584,
            286,
            390,
            264,
            5775,
            954,
            294,
            3164,
            11,
            50768
          ],
          "temperature": 0.0,
          "avg_logprob": -0.16436913177257276,
          "compression_ratio": 1.7380952380952381,
          "no_speech_prob": 0.0002378151984885335
        },
        {
          "id": 17,
          "seek": 2836,
          "start": 36.44,
          "end": 38.92,
          "text": " but I was a leader in search user interfaces,",
          "tokens": [
            50768,
            457,
            286,
            390,
            257,
            5263,
            294,
            3164,
            4195,
            28416,
            11,
            50892
          ],
          "temperature": 0.0,
          "avg_logprob": -0.16436913177257276,
          "compression_ratio": 1.7380952380952381,
          "no_speech_prob": 0.0002378151984885335
        },
        {
          "id": 18,
          "seek": 2836,
          "start": 38.92,
          "end": 41.6,
          "text": " which was kind of a hybrid topic at the time",
          "tokens": [
            50892,
            597,
            390,
            733,
            295,
            257,
            13051,
            4829,
            412,
            264,
            565,
            51026
          ],
          "temperature": 0.0,
          "avg_logprob": -0.16436913177257276,
          "compression_ratio": 1.7380952380952381,
          "no_speech_prob": 0.0002378151984885335
        },
        {
          "id": 19,
          "seek": 2836,
          "start": 41.6,
          "end": 44.6,
          "text": " because most of the search field was more on algorithms",
          "tokens": [
            51026,
            570,
            881,
            295,
            264,
            3164,
            2519,
            390,
            544,
            322,
            14642,
            51176
          ],
          "temperature": 0.0,
          "avg_logprob": -0.16436913177257276,
          "compression_ratio": 1.7380952380952381,
          "no_speech_prob": 0.0002378151984885335
        },
        {
          "id": 20,
          "seek": 2836,
          "start": 44.6,
          "end": 46.120000000000005,
          "text": " and not so much on the user interface.",
          "tokens": [
            51176,
            293,
            406,
            370,
            709,
            322,
            264,
            4195,
            9226,
            13,
            51252
          ],
          "temperature": 0.0,
          "avg_logprob": -0.16436913177257276,
          "compression_ratio": 1.7380952380952381,
          "no_speech_prob": 0.0002378151984885335
        },
        {
          "id": 21,
          "seek": 2836,
          "start": 46.120000000000005,
          "end": 47.68,
          "text": " So I brought those two together.",
          "tokens": [
            51252,
            407,
            286,
            3038,
            729,
            732,
            1214,
            13,
            51330
          ],
          "temperature": 0.0,
          "avg_logprob": -0.16436913177257276,
          "compression_ratio": 1.7380952380952381,
          "no_speech_prob": 0.0002378151984885335
        },
        {
          "id": 22,
          "seek": 2836,
          "start": 47.68,
          "end": 50.92,
          "text": " And that was super exciting because the technology",
          "tokens": [
            51330,
            400,
            300,
            390,
            1687,
            4670,
            570,
            264,
            2899,
            51492
          ],
          "temperature": 0.0,
          "avg_logprob": -0.16436913177257276,
          "compression_ratio": 1.7380952380952381,
          "no_speech_prob": 0.0002378151984885335
        },
        {
          "id": 23,
          "seek": 2836,
          "start": 50.92,
          "end": 53.64,
          "text": " or the kind of framework that I advocated for",
          "tokens": [
            51492,
            420,
            264,
            733,
            295,
            8388,
            300,
            286,
            7915,
            770,
            337,
            51628
          ],
          "temperature": 0.0,
          "avg_logprob": -0.16436913177257276,
          "compression_ratio": 1.7380952380952381,
          "no_speech_prob": 0.0002378151984885335
        },
        {
          "id": 24,
          "seek": 2836,
          "start": 53.64,
          "end": 55.879999999999995,
          "text": " and showed empirically worked,",
          "tokens": [
            51628,
            293,
            4712,
            25790,
            984,
            2732,
            11,
            51740
          ],
          "temperature": 0.0,
          "avg_logprob": -0.16436913177257276,
          "compression_ratio": 1.7380952380952381,
          "no_speech_prob": 0.0002378151984885335
        },
        {
          "id": 25,
          "seek": 5588,
          "start": 55.92,
          "end": 57.440000000000005,
          "text": " did become the standard for,",
          "tokens": [
            50366,
            630,
            1813,
            264,
            3832,
            337,
            11,
            50442
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21200796998577354,
          "compression_ratio": 1.6417910447761195,
          "no_speech_prob": 0.0004107756831217557
        },
        {
          "id": 26,
          "seek": 5588,
          "start": 57.440000000000005,
          "end": 59.6,
          "text": " it's still a standard faceted interaction",
          "tokens": [
            50442,
            309,
            311,
            920,
            257,
            3832,
            1915,
            10993,
            9285,
            50550
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21200796998577354,
          "compression_ratio": 1.6417910447761195,
          "no_speech_prob": 0.0004107756831217557
        },
        {
          "id": 27,
          "seek": 5588,
          "start": 59.6,
          "end": 62.400000000000006,
          "text": " like what you see on a website when you're shopping",
          "tokens": [
            50550,
            411,
            437,
            291,
            536,
            322,
            257,
            3144,
            562,
            291,
            434,
            8688,
            50690
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21200796998577354,
          "compression_ratio": 1.6417910447761195,
          "no_speech_prob": 0.0004107756831217557
        },
        {
          "id": 28,
          "seek": 5588,
          "start": 62.400000000000006,
          "end": 65.28,
          "text": " or library catalogs where you can slice and dice",
          "tokens": [
            50690,
            420,
            6405,
            19746,
            82,
            689,
            291,
            393,
            13153,
            293,
            10313,
            50834
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21200796998577354,
          "compression_ratio": 1.6417910447761195,
          "no_speech_prob": 0.0004107756831217557
        },
        {
          "id": 29,
          "seek": 5588,
          "start": 65.28,
          "end": 69.08,
          "text": " and filter in different ways to find the items that you want.",
          "tokens": [
            50834,
            293,
            6608,
            294,
            819,
            2098,
            281,
            915,
            264,
            4754,
            300,
            291,
            528,
            13,
            51024
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21200796998577354,
          "compression_ratio": 1.6417910447761195,
          "no_speech_prob": 0.0004107756831217557
        },
        {
          "id": 30,
          "seek": 5588,
          "start": 69.08,
          "end": 72.08,
          "text": " Getting that interface to work well was the big challenge",
          "tokens": [
            51024,
            13674,
            300,
            9226,
            281,
            589,
            731,
            390,
            264,
            955,
            3430,
            51174
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21200796998577354,
          "compression_ratio": 1.6417910447761195,
          "no_speech_prob": 0.0004107756831217557
        },
        {
          "id": 31,
          "seek": 5588,
          "start": 72.08,
          "end": 73.96000000000001,
          "text": " and that was sort of the breakthrough.",
          "tokens": [
            51174,
            293,
            300,
            390,
            1333,
            295,
            264,
            22397,
            13,
            51268
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21200796998577354,
          "compression_ratio": 1.6417910447761195,
          "no_speech_prob": 0.0004107756831217557
        }
      ],
      "language": "en"
    },
    {
      "text": " What was the big problem with search interfaces before you got into the game?",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 3.6,
          "text": " What was the big problem with search interfaces before you got into the game?",
          "tokens": [
            50364,
            708,
            390,
            264,
            955,
            1154,
            365,
            3164,
            28416,
            949,
            291,
            658,
            666,
            264,
            1216,
            30,
            50544
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3347426520453559,
          "compression_ratio": 1.0547945205479452,
          "no_speech_prob": 0.00022071249259170145
        }
      ],
      "language": "en"
    },
    {
      "text": " Well, when I got into the game, most software did not have search full stop. I mean, if you had an application, you couldn't search for material within it. It was just rare. It just didn't happen much. When I got into the game, library catalogs were searched by saying, you know, P N Bonneman comma J to find the personal name of the author. I mean, it was command line. And then there were Westlaw and these very expensive tools that you could subscribe to, say, if you were a lawyer, it was all keyword based. But the interface, there was no thought to the interface. It's just a listing of the output that you got, usually in chronological order. And so there was just was no there there. The web changed things. But even with the web, the initial search was, you know, the 10 blue links, which has actually been really hard to improve on. And I would say until now, which we could get to the new moment, you know, Google's inch towards showing answers to questions. But I remember talking with someone there saying that they were conservative initially because they didn't want to show incorrect information. And I thought that was the right way to go.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 5.24,
          "text": " Well, when I got into the game, most software did not have search full stop.",
          "tokens": [
            50364,
            1042,
            11,
            562,
            286,
            658,
            666,
            264,
            1216,
            11,
            881,
            4722,
            630,
            406,
            362,
            3164,
            1577,
            1590,
            13,
            50626
          ],
          "temperature": 0.0,
          "avg_logprob": -0.35294842529296877,
          "compression_ratio": 1.6962962962962962,
          "no_speech_prob": 0.0031708695460110903
        },
        {
          "id": 1,
          "seek": 0,
          "start": 5.48,
          "end": 9.200000000000001,
          "text": " I mean, if you had an application, you couldn't search for material within it.",
          "tokens": [
            50638,
            286,
            914,
            11,
            498,
            291,
            632,
            364,
            3861,
            11,
            291,
            2809,
            380,
            3164,
            337,
            2527,
            1951,
            309,
            13,
            50824
          ],
          "temperature": 0.0,
          "avg_logprob": -0.35294842529296877,
          "compression_ratio": 1.6962962962962962,
          "no_speech_prob": 0.0031708695460110903
        },
        {
          "id": 2,
          "seek": 0,
          "start": 9.36,
          "end": 10.64,
          "text": " It was just rare.",
          "tokens": [
            50832,
            467,
            390,
            445,
            5892,
            13,
            50896
          ],
          "temperature": 0.0,
          "avg_logprob": -0.35294842529296877,
          "compression_ratio": 1.6962962962962962,
          "no_speech_prob": 0.0031708695460110903
        },
        {
          "id": 3,
          "seek": 0,
          "start": 10.64,
          "end": 11.96,
          "text": " It just didn't happen much.",
          "tokens": [
            50896,
            467,
            445,
            994,
            380,
            1051,
            709,
            13,
            50962
          ],
          "temperature": 0.0,
          "avg_logprob": -0.35294842529296877,
          "compression_ratio": 1.6962962962962962,
          "no_speech_prob": 0.0031708695460110903
        },
        {
          "id": 4,
          "seek": 0,
          "start": 12.0,
          "end": 16.36,
          "text": " When I got into the game, library catalogs were searched by saying, you know, P N",
          "tokens": [
            50964,
            1133,
            286,
            658,
            666,
            264,
            1216,
            11,
            6405,
            19746,
            82,
            645,
            22961,
            538,
            1566,
            11,
            291,
            458,
            11,
            430,
            426,
            51182
          ],
          "temperature": 0.0,
          "avg_logprob": -0.35294842529296877,
          "compression_ratio": 1.6962962962962962,
          "no_speech_prob": 0.0031708695460110903
        },
        {
          "id": 5,
          "seek": 0,
          "start": 16.52,
          "end": 20.28,
          "text": " Bonneman comma J to find the personal name of the author.",
          "tokens": [
            51190,
            7368,
            77,
            15023,
            22117,
            508,
            281,
            915,
            264,
            2973,
            1315,
            295,
            264,
            3793,
            13,
            51378
          ],
          "temperature": 0.0,
          "avg_logprob": -0.35294842529296877,
          "compression_ratio": 1.6962962962962962,
          "no_speech_prob": 0.0031708695460110903
        },
        {
          "id": 6,
          "seek": 0,
          "start": 20.32,
          "end": 21.56,
          "text": " I mean, it was command line.",
          "tokens": [
            51380,
            286,
            914,
            11,
            309,
            390,
            5622,
            1622,
            13,
            51442
          ],
          "temperature": 0.0,
          "avg_logprob": -0.35294842529296877,
          "compression_ratio": 1.6962962962962962,
          "no_speech_prob": 0.0031708695460110903
        },
        {
          "id": 7,
          "seek": 0,
          "start": 22.2,
          "end": 27.8,
          "text": " And then there were Westlaw and these very expensive tools that you could subscribe to,",
          "tokens": [
            51474,
            400,
            550,
            456,
            645,
            4055,
            5901,
            293,
            613,
            588,
            5124,
            3873,
            300,
            291,
            727,
            3022,
            281,
            11,
            51754
          ],
          "temperature": 0.0,
          "avg_logprob": -0.35294842529296877,
          "compression_ratio": 1.6962962962962962,
          "no_speech_prob": 0.0031708695460110903
        },
        {
          "id": 8,
          "seek": 2780,
          "start": 27.8,
          "end": 30.6,
          "text": " say, if you were a lawyer, it was all keyword based.",
          "tokens": [
            50364,
            584,
            11,
            498,
            291,
            645,
            257,
            11613,
            11,
            309,
            390,
            439,
            20428,
            2361,
            13,
            50504
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2520638775351821,
          "compression_ratio": 1.7874251497005988,
          "no_speech_prob": 0.10667143762111664
        },
        {
          "id": 9,
          "seek": 2780,
          "start": 30.68,
          "end": 33.36,
          "text": " But the interface, there was no thought to the interface.",
          "tokens": [
            50508,
            583,
            264,
            9226,
            11,
            456,
            390,
            572,
            1194,
            281,
            264,
            9226,
            13,
            50642
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2520638775351821,
          "compression_ratio": 1.7874251497005988,
          "no_speech_prob": 0.10667143762111664
        },
        {
          "id": 10,
          "seek": 2780,
          "start": 33.36,
          "end": 37.32,
          "text": " It's just a listing of the output that you got, usually in chronological order.",
          "tokens": [
            50642,
            467,
            311,
            445,
            257,
            22161,
            295,
            264,
            5598,
            300,
            291,
            658,
            11,
            2673,
            294,
            19393,
            4383,
            1668,
            13,
            50840
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2520638775351821,
          "compression_ratio": 1.7874251497005988,
          "no_speech_prob": 0.10667143762111664
        },
        {
          "id": 11,
          "seek": 2780,
          "start": 37.52,
          "end": 39.84,
          "text": " And so there was just was no there there.",
          "tokens": [
            50850,
            400,
            370,
            456,
            390,
            445,
            390,
            572,
            456,
            456,
            13,
            50966
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2520638775351821,
          "compression_ratio": 1.7874251497005988,
          "no_speech_prob": 0.10667143762111664
        },
        {
          "id": 12,
          "seek": 2780,
          "start": 40.04,
          "end": 40.96,
          "text": " The web changed things.",
          "tokens": [
            50976,
            440,
            3670,
            3105,
            721,
            13,
            51022
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2520638775351821,
          "compression_ratio": 1.7874251497005988,
          "no_speech_prob": 0.10667143762111664
        },
        {
          "id": 13,
          "seek": 2780,
          "start": 40.96,
          "end": 44.2,
          "text": " But even with the web, the initial search was, you know, the 10 blue links, which has",
          "tokens": [
            51022,
            583,
            754,
            365,
            264,
            3670,
            11,
            264,
            5883,
            3164,
            390,
            11,
            291,
            458,
            11,
            264,
            1266,
            3344,
            6123,
            11,
            597,
            575,
            51184
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2520638775351821,
          "compression_ratio": 1.7874251497005988,
          "no_speech_prob": 0.10667143762111664
        },
        {
          "id": 14,
          "seek": 2780,
          "start": 44.2,
          "end": 47.040000000000006,
          "text": " actually been really hard to improve on.",
          "tokens": [
            51184,
            767,
            668,
            534,
            1152,
            281,
            3470,
            322,
            13,
            51326
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2520638775351821,
          "compression_ratio": 1.7874251497005988,
          "no_speech_prob": 0.10667143762111664
        },
        {
          "id": 15,
          "seek": 2780,
          "start": 47.32,
          "end": 51.24,
          "text": " And I would say until now, which we could get to the new moment, you know, Google's",
          "tokens": [
            51340,
            400,
            286,
            576,
            584,
            1826,
            586,
            11,
            597,
            321,
            727,
            483,
            281,
            264,
            777,
            1623,
            11,
            291,
            458,
            11,
            3329,
            311,
            51536
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2520638775351821,
          "compression_ratio": 1.7874251497005988,
          "no_speech_prob": 0.10667143762111664
        },
        {
          "id": 16,
          "seek": 2780,
          "start": 51.24,
          "end": 53.480000000000004,
          "text": " inch towards showing answers to questions.",
          "tokens": [
            51536,
            7227,
            3030,
            4099,
            6338,
            281,
            1651,
            13,
            51648
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2520638775351821,
          "compression_ratio": 1.7874251497005988,
          "no_speech_prob": 0.10667143762111664
        },
        {
          "id": 17,
          "seek": 2780,
          "start": 53.480000000000004,
          "end": 56.760000000000005,
          "text": " But I remember talking with someone there saying that they were conservative initially",
          "tokens": [
            51648,
            583,
            286,
            1604,
            1417,
            365,
            1580,
            456,
            1566,
            300,
            436,
            645,
            13780,
            9105,
            51812
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2520638775351821,
          "compression_ratio": 1.7874251497005988,
          "no_speech_prob": 0.10667143762111664
        },
        {
          "id": 18,
          "seek": 5676,
          "start": 56.76,
          "end": 58.879999999999995,
          "text": " because they didn't want to show incorrect information.",
          "tokens": [
            50364,
            570,
            436,
            994,
            380,
            528,
            281,
            855,
            18424,
            1589,
            13,
            50470
          ],
          "temperature": 0.0,
          "avg_logprob": -0.26043455417339617,
          "compression_ratio": 1.125,
          "no_speech_prob": 0.0013659682590514421
        },
        {
          "id": 19,
          "seek": 5676,
          "start": 58.879999999999995,
          "end": 61.16,
          "text": " And I thought that was the right way to go.",
          "tokens": [
            50470,
            400,
            286,
            1194,
            300,
            390,
            264,
            558,
            636,
            281,
            352,
            13,
            50584
          ],
          "temperature": 0.0,
          "avg_logprob": -0.26043455417339617,
          "compression_ratio": 1.125,
          "no_speech_prob": 0.0013659682590514421
        }
      ],
      "language": "en"
    },
    {
      "text": " Hmm.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 0.5,
          "text": " Hmm.",
          "tokens": [
            50364,
            8239,
            13,
            50389
          ],
          "temperature": 0.0,
          "avg_logprob": -0.7172256469726562,
          "compression_ratio": 0.3333333333333333,
          "no_speech_prob": 0.8348808288574219
        }
      ],
      "language": "en"
    },
    {
      "text": " Isn't that one of the big shifts? It's like once upon a time, the purpose of search was to find a document or find a resource. But nowadays you want the answer to a question. It's almost a shift in intention.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 1.36,
          "text": " Isn't that one of the big shifts?",
          "tokens": [
            50364,
            6998,
            380,
            300,
            472,
            295,
            264,
            955,
            19201,
            30,
            50432
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2564150174458822,
          "compression_ratio": 1.395973154362416,
          "no_speech_prob": 0.006762467324733734
        },
        {
          "id": 1,
          "seek": 0,
          "start": 1.48,
          "end": 5.36,
          "text": " It's like once upon a time, the purpose of search was to find a",
          "tokens": [
            50438,
            467,
            311,
            411,
            1564,
            3564,
            257,
            565,
            11,
            264,
            4334,
            295,
            3164,
            390,
            281,
            915,
            257,
            50632
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2564150174458822,
          "compression_ratio": 1.395973154362416,
          "no_speech_prob": 0.006762467324733734
        },
        {
          "id": 2,
          "seek": 0,
          "start": 5.36,
          "end": 7.08,
          "text": " document or find a resource.",
          "tokens": [
            50632,
            4166,
            420,
            915,
            257,
            7684,
            13,
            50718
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2564150174458822,
          "compression_ratio": 1.395973154362416,
          "no_speech_prob": 0.006762467324733734
        },
        {
          "id": 3,
          "seek": 0,
          "start": 7.24,
          "end": 9.34,
          "text": " But nowadays you want the answer to a question.",
          "tokens": [
            50726,
            583,
            13434,
            291,
            528,
            264,
            1867,
            281,
            257,
            1168,
            13,
            50831
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2564150174458822,
          "compression_ratio": 1.395973154362416,
          "no_speech_prob": 0.006762467324733734
        },
        {
          "id": 4,
          "seek": 0,
          "start": 9.48,
          "end": 11.48,
          "text": " It's almost a shift in intention.",
          "tokens": [
            50838,
            467,
            311,
            1920,
            257,
            5513,
            294,
            7789,
            13,
            50938
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2564150174458822,
          "compression_ratio": 1.395973154362416,
          "no_speech_prob": 0.006762467324733734
        }
      ],
      "language": "en"
    },
    {
      "text": " Actually, I speak to that. I think people always wanted to ask questions, but it wasn't possible to get an answer.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 1.6,
          "text": " Actually, I speak to that.",
          "tokens": [
            50364,
            5135,
            11,
            286,
            1710,
            281,
            300,
            13,
            50444
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2422500887224751,
          "compression_ratio": 1.1515151515151516,
          "no_speech_prob": 5.2929535740986466e-05
        },
        {
          "id": 1,
          "seek": 0,
          "start": 1.6,
          "end": 6.48,
          "text": " I think people always wanted to ask questions, but it wasn't possible to get an answer.",
          "tokens": [
            50444,
            286,
            519,
            561,
            1009,
            1415,
            281,
            1029,
            1651,
            11,
            457,
            309,
            2067,
            380,
            1944,
            281,
            483,
            364,
            1867,
            13,
            50688
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2422500887224751,
          "compression_ratio": 1.1515151515151516,
          "no_speech_prob": 5.2929535740986466e-05
        }
      ],
      "language": "en"
    },
    {
      "text": " So we were just adapting to a bad system.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 2.24,
          "text": " So we were just adapting to a bad system.",
          "tokens": [
            50364,
            407,
            321,
            645,
            445,
            34942,
            281,
            257,
            1578,
            1185,
            13,
            50476
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3575778007507324,
          "compression_ratio": 0.8723404255319149,
          "no_speech_prob": 6.989650137256831e-05
        }
      ],
      "language": "en"
    },
    {
      "text": " Well, I always like to use the example of this old website called Ask Jeeves, which was an attempt to allow people to ask questions and get answers. And it didn't work because the technology didn't work, but people kept using it and always said they liked it because they liked the idea of being able to get, ask a question and get an answer. And I have some old screenshots of it. It just didn't work. It's like someone saying, oh, people like the mouse, but now we have touchscreens and their tastes have changed. And I'm like, no, no, it's that we didn't know how to do touchscreens. We didn't know how to do gestures technologically. In the early days, it was a bridge to that. So often the interface we see now is the interface people always wanted, but we didn't have the technology to support it. And I'd say that's true for question answering. Now, there's an exception for scholars and people doing research who want to see the documents and primary resources, but that's always been a minority.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 3.84,
          "text": " Well, I always like to use the example of this old website called Ask Jeeves,",
          "tokens": [
            50364,
            1042,
            11,
            286,
            1009,
            411,
            281,
            764,
            264,
            1365,
            295,
            341,
            1331,
            3144,
            1219,
            12320,
            508,
            1653,
            977,
            11,
            50556
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25156987508138023,
          "compression_ratio": 1.9150326797385622,
          "no_speech_prob": 0.004824819974601269
        },
        {
          "id": 1,
          "seek": 0,
          "start": 3.84,
          "end": 7.54,
          "text": " which was an attempt to allow people to ask questions and get answers.",
          "tokens": [
            50556,
            597,
            390,
            364,
            5217,
            281,
            2089,
            561,
            281,
            1029,
            1651,
            293,
            483,
            6338,
            13,
            50741
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25156987508138023,
          "compression_ratio": 1.9150326797385622,
          "no_speech_prob": 0.004824819974601269
        },
        {
          "id": 2,
          "seek": 0,
          "start": 7.54,
          "end": 10.3,
          "text": " And it didn't work because the technology didn't work,",
          "tokens": [
            50741,
            400,
            309,
            994,
            380,
            589,
            570,
            264,
            2899,
            994,
            380,
            589,
            11,
            50879
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25156987508138023,
          "compression_ratio": 1.9150326797385622,
          "no_speech_prob": 0.004824819974601269
        },
        {
          "id": 3,
          "seek": 0,
          "start": 10.3,
          "end": 12.6,
          "text": " but people kept using it and always said they liked it",
          "tokens": [
            50879,
            457,
            561,
            4305,
            1228,
            309,
            293,
            1009,
            848,
            436,
            4501,
            309,
            50994
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25156987508138023,
          "compression_ratio": 1.9150326797385622,
          "no_speech_prob": 0.004824819974601269
        },
        {
          "id": 4,
          "seek": 0,
          "start": 12.6,
          "end": 15.4,
          "text": " because they liked the idea of being able to get,",
          "tokens": [
            50994,
            570,
            436,
            4501,
            264,
            1558,
            295,
            885,
            1075,
            281,
            483,
            11,
            51134
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25156987508138023,
          "compression_ratio": 1.9150326797385622,
          "no_speech_prob": 0.004824819974601269
        },
        {
          "id": 5,
          "seek": 0,
          "start": 15.4,
          "end": 17.1,
          "text": " ask a question and get an answer.",
          "tokens": [
            51134,
            1029,
            257,
            1168,
            293,
            483,
            364,
            1867,
            13,
            51219
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25156987508138023,
          "compression_ratio": 1.9150326797385622,
          "no_speech_prob": 0.004824819974601269
        },
        {
          "id": 6,
          "seek": 0,
          "start": 17.1,
          "end": 19.2,
          "text": " And I have some old screenshots of it.",
          "tokens": [
            51219,
            400,
            286,
            362,
            512,
            1331,
            40661,
            295,
            309,
            13,
            51324
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25156987508138023,
          "compression_ratio": 1.9150326797385622,
          "no_speech_prob": 0.004824819974601269
        },
        {
          "id": 7,
          "seek": 0,
          "start": 19.2,
          "end": 20.240000000000002,
          "text": " It just didn't work.",
          "tokens": [
            51324,
            467,
            445,
            994,
            380,
            589,
            13,
            51376
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25156987508138023,
          "compression_ratio": 1.9150326797385622,
          "no_speech_prob": 0.004824819974601269
        },
        {
          "id": 8,
          "seek": 0,
          "start": 20.240000000000002,
          "end": 21.740000000000002,
          "text": " It's like someone saying,",
          "tokens": [
            51376,
            467,
            311,
            411,
            1580,
            1566,
            11,
            51451
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25156987508138023,
          "compression_ratio": 1.9150326797385622,
          "no_speech_prob": 0.004824819974601269
        },
        {
          "id": 9,
          "seek": 0,
          "start": 21.740000000000002,
          "end": 25.400000000000002,
          "text": " oh, people like the mouse, but now we have touchscreens",
          "tokens": [
            51451,
            1954,
            11,
            561,
            411,
            264,
            9719,
            11,
            457,
            586,
            321,
            362,
            2557,
            4417,
            9098,
            51634
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25156987508138023,
          "compression_ratio": 1.9150326797385622,
          "no_speech_prob": 0.004824819974601269
        },
        {
          "id": 10,
          "seek": 0,
          "start": 25.400000000000002,
          "end": 26.7,
          "text": " and their tastes have changed.",
          "tokens": [
            51634,
            293,
            641,
            8666,
            362,
            3105,
            13,
            51699
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25156987508138023,
          "compression_ratio": 1.9150326797385622,
          "no_speech_prob": 0.004824819974601269
        },
        {
          "id": 11,
          "seek": 0,
          "start": 26.7,
          "end": 29.36,
          "text": " And I'm like, no, no, it's that we didn't know how to do touchscreens.",
          "tokens": [
            51699,
            400,
            286,
            478,
            411,
            11,
            572,
            11,
            572,
            11,
            309,
            311,
            300,
            321,
            994,
            380,
            458,
            577,
            281,
            360,
            2557,
            4417,
            9098,
            13,
            51832
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25156987508138023,
          "compression_ratio": 1.9150326797385622,
          "no_speech_prob": 0.004824819974601269
        },
        {
          "id": 12,
          "seek": 2936,
          "start": 29.36,
          "end": 31.86,
          "text": " We didn't know how to do gestures technologically.",
          "tokens": [
            50364,
            492,
            994,
            380,
            458,
            577,
            281,
            360,
            28475,
            1537,
            17157,
            13,
            50489
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21457506575674382,
          "compression_ratio": 1.6613545816733069,
          "no_speech_prob": 0.00015590933617204428
        },
        {
          "id": 13,
          "seek": 2936,
          "start": 31.86,
          "end": 35.6,
          "text": " In the early days, it was a bridge to that.",
          "tokens": [
            50489,
            682,
            264,
            2440,
            1708,
            11,
            309,
            390,
            257,
            7283,
            281,
            300,
            13,
            50676
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21457506575674382,
          "compression_ratio": 1.6613545816733069,
          "no_speech_prob": 0.00015590933617204428
        },
        {
          "id": 14,
          "seek": 2936,
          "start": 35.6,
          "end": 39.56,
          "text": " So often the interface we see now is the interface people always wanted,",
          "tokens": [
            50676,
            407,
            2049,
            264,
            9226,
            321,
            536,
            586,
            307,
            264,
            9226,
            561,
            1009,
            1415,
            11,
            50874
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21457506575674382,
          "compression_ratio": 1.6613545816733069,
          "no_speech_prob": 0.00015590933617204428
        },
        {
          "id": 15,
          "seek": 2936,
          "start": 39.56,
          "end": 41.66,
          "text": " but we didn't have the technology to support it.",
          "tokens": [
            50874,
            457,
            321,
            994,
            380,
            362,
            264,
            2899,
            281,
            1406,
            309,
            13,
            50979
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21457506575674382,
          "compression_ratio": 1.6613545816733069,
          "no_speech_prob": 0.00015590933617204428
        },
        {
          "id": 16,
          "seek": 2936,
          "start": 41.66,
          "end": 43.8,
          "text": " And I'd say that's true for question answering.",
          "tokens": [
            50979,
            400,
            286,
            1116,
            584,
            300,
            311,
            2074,
            337,
            1168,
            13430,
            13,
            51086
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21457506575674382,
          "compression_ratio": 1.6613545816733069,
          "no_speech_prob": 0.00015590933617204428
        },
        {
          "id": 17,
          "seek": 2936,
          "start": 43.8,
          "end": 47.56,
          "text": " Now, there's an exception for scholars and people doing research",
          "tokens": [
            51086,
            823,
            11,
            456,
            311,
            364,
            11183,
            337,
            8553,
            293,
            561,
            884,
            2132,
            51274
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21457506575674382,
          "compression_ratio": 1.6613545816733069,
          "no_speech_prob": 0.00015590933617204428
        },
        {
          "id": 18,
          "seek": 2936,
          "start": 47.56,
          "end": 50.0,
          "text": " who want to see the documents and primary resources,",
          "tokens": [
            51274,
            567,
            528,
            281,
            536,
            264,
            8512,
            293,
            6194,
            3593,
            11,
            51396
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21457506575674382,
          "compression_ratio": 1.6613545816733069,
          "no_speech_prob": 0.00015590933617204428
        },
        {
          "id": 19,
          "seek": 2936,
          "start": 50.0,
          "end": 51.7,
          "text": " but that's always been a minority.",
          "tokens": [
            51396,
            457,
            300,
            311,
            1009,
            668,
            257,
            16166,
            13,
            51481
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21457506575674382,
          "compression_ratio": 1.6613545816733069,
          "no_speech_prob": 0.00015590933617204428
        }
      ],
      "language": "en"
    },
    {
      "text": " Yeah. So that brings us to the current moment where the machine behind your screen, that's going to try and answer your questions is suddenly, and I really mean suddenly able to answer it almost like a human. It feels like at times.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 12.72,
          "text": " Yeah. So that brings us to the current moment where the machine behind your screen, that's going to try and answer your questions is suddenly, and I really mean suddenly able to answer it almost like a human. It feels like at times.",
          "tokens": [
            50364,
            865,
            13,
            407,
            300,
            5607,
            505,
            281,
            264,
            2190,
            1623,
            689,
            264,
            3479,
            2261,
            428,
            2568,
            11,
            300,
            311,
            516,
            281,
            853,
            293,
            1867,
            428,
            1651,
            307,
            5800,
            11,
            293,
            286,
            534,
            914,
            5800,
            1075,
            281,
            1867,
            309,
            1920,
            411,
            257,
            1952,
            13,
            467,
            3417,
            411,
            412,
            1413,
            13,
            51000
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2937020155099722,
          "compression_ratio": 1.5163398692810457,
          "no_speech_prob": 0.0027888407930731773
        }
      ],
      "language": "en"
    },
    {
      "text": " I agree. I think it's a sea change. So I gave a keynote talk in October to the Information Visualization Society, the IEEE society. And in that talk, part of what I did was talked about, you know, this is coming. We are going to see, instead of people developing visualizations manually, it's probably going to be done with text interface. And that's a pretty radical thing to say. And it was a month later that Chat GPT came out. And again, I told the audience at that time that I've been in the NLP field for more than 25 years, maybe 30 years. And I've never said this is a major change. And I say it now, I was saying it right before Chat GPT. And it is transformational in terms of what we can do with processing language and producing language. It's not transformational in everything, as some of the hype says, just like we had a mouse and then we had a touchscreen. We had keyword query or statistical ranking, or we had these very complex pipelines for making natural language processing systems. And now it's kind of one relatively simple architecture that does everything as opposed to specific algorithms. And it's kind of head spinning, really.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 5.4,
          "text": " I agree. I think it's a sea change. So I gave a keynote talk in October to the Information",
          "tokens": [
            50364,
            286,
            3986,
            13,
            286,
            519,
            309,
            311,
            257,
            4158,
            1319,
            13,
            407,
            286,
            2729,
            257,
            33896,
            751,
            294,
            7617,
            281,
            264,
            15357,
            50634
          ],
          "temperature": 0.0,
          "avg_logprob": -0.22318174044291178,
          "compression_ratio": 1.6232394366197183,
          "no_speech_prob": 0.006187546532601118
        },
        {
          "id": 1,
          "seek": 0,
          "start": 5.4,
          "end": 10.78,
          "text": " Visualization Society, the IEEE society. And in that talk, part of what I did was talked",
          "tokens": [
            50634,
            23187,
            2144,
            13742,
            11,
            264,
            286,
            7258,
            36,
            4086,
            13,
            400,
            294,
            300,
            751,
            11,
            644,
            295,
            437,
            286,
            630,
            390,
            2825,
            50903
          ],
          "temperature": 0.0,
          "avg_logprob": -0.22318174044291178,
          "compression_ratio": 1.6232394366197183,
          "no_speech_prob": 0.006187546532601118
        },
        {
          "id": 2,
          "seek": 0,
          "start": 10.78,
          "end": 16.8,
          "text": " about, you know, this is coming. We are going to see, instead of people developing visualizations",
          "tokens": [
            50903,
            466,
            11,
            291,
            458,
            11,
            341,
            307,
            1348,
            13,
            492,
            366,
            516,
            281,
            536,
            11,
            2602,
            295,
            561,
            6416,
            5056,
            14455,
            51204
          ],
          "temperature": 0.0,
          "avg_logprob": -0.22318174044291178,
          "compression_ratio": 1.6232394366197183,
          "no_speech_prob": 0.006187546532601118
        },
        {
          "id": 3,
          "seek": 0,
          "start": 16.8,
          "end": 21.3,
          "text": " manually, it's probably going to be done with text interface. And that's a pretty radical",
          "tokens": [
            51204,
            16945,
            11,
            309,
            311,
            1391,
            516,
            281,
            312,
            1096,
            365,
            2487,
            9226,
            13,
            400,
            300,
            311,
            257,
            1238,
            12001,
            51429
          ],
          "temperature": 0.0,
          "avg_logprob": -0.22318174044291178,
          "compression_ratio": 1.6232394366197183,
          "no_speech_prob": 0.006187546532601118
        },
        {
          "id": 4,
          "seek": 0,
          "start": 21.3,
          "end": 26.92,
          "text": " thing to say. And it was a month later that Chat GPT came out. And again, I told the audience",
          "tokens": [
            51429,
            551,
            281,
            584,
            13,
            400,
            309,
            390,
            257,
            1618,
            1780,
            300,
            27503,
            26039,
            51,
            1361,
            484,
            13,
            400,
            797,
            11,
            286,
            1907,
            264,
            4034,
            51710
          ],
          "temperature": 0.0,
          "avg_logprob": -0.22318174044291178,
          "compression_ratio": 1.6232394366197183,
          "no_speech_prob": 0.006187546532601118
        },
        {
          "id": 5,
          "seek": 2692,
          "start": 26.92,
          "end": 32.0,
          "text": " at that time that I've been in the NLP field for more than 25 years, maybe 30 years. And",
          "tokens": [
            50364,
            412,
            300,
            565,
            300,
            286,
            600,
            668,
            294,
            264,
            426,
            45196,
            2519,
            337,
            544,
            813,
            3552,
            924,
            11,
            1310,
            2217,
            924,
            13,
            400,
            50618
          ],
          "temperature": 0.0,
          "avg_logprob": -0.23020999184970198,
          "compression_ratio": 1.6402877697841727,
          "no_speech_prob": 0.0009398186230100691
        },
        {
          "id": 6,
          "seek": 2692,
          "start": 32.0,
          "end": 37.72,
          "text": " I've never said this is a major change. And I say it now, I was saying it right before",
          "tokens": [
            50618,
            286,
            600,
            1128,
            848,
            341,
            307,
            257,
            2563,
            1319,
            13,
            400,
            286,
            584,
            309,
            586,
            11,
            286,
            390,
            1566,
            309,
            558,
            949,
            50904
          ],
          "temperature": 0.0,
          "avg_logprob": -0.23020999184970198,
          "compression_ratio": 1.6402877697841727,
          "no_speech_prob": 0.0009398186230100691
        },
        {
          "id": 7,
          "seek": 2692,
          "start": 37.72,
          "end": 44.32000000000001,
          "text": " Chat GPT. And it is transformational in terms of what we can do with processing language",
          "tokens": [
            50904,
            27503,
            26039,
            51,
            13,
            400,
            309,
            307,
            4088,
            1478,
            294,
            2115,
            295,
            437,
            321,
            393,
            360,
            365,
            9007,
            2856,
            51234
          ],
          "temperature": 0.0,
          "avg_logprob": -0.23020999184970198,
          "compression_ratio": 1.6402877697841727,
          "no_speech_prob": 0.0009398186230100691
        },
        {
          "id": 8,
          "seek": 2692,
          "start": 44.32000000000001,
          "end": 49.480000000000004,
          "text": " and producing language. It's not transformational in everything, as some of the hype says, just",
          "tokens": [
            51234,
            293,
            10501,
            2856,
            13,
            467,
            311,
            406,
            4088,
            1478,
            294,
            1203,
            11,
            382,
            512,
            295,
            264,
            24144,
            1619,
            11,
            445,
            51492
          ],
          "temperature": 0.0,
          "avg_logprob": -0.23020999184970198,
          "compression_ratio": 1.6402877697841727,
          "no_speech_prob": 0.0009398186230100691
        },
        {
          "id": 9,
          "seek": 2692,
          "start": 49.480000000000004,
          "end": 56.480000000000004,
          "text": " like we had a mouse and then we had a touchscreen. We had keyword query or statistical ranking,",
          "tokens": [
            51492,
            411,
            321,
            632,
            257,
            9719,
            293,
            550,
            321,
            632,
            257,
            46775,
            13,
            492,
            632,
            20428,
            14581,
            420,
            22820,
            17833,
            11,
            51842
          ],
          "temperature": 0.0,
          "avg_logprob": -0.23020999184970198,
          "compression_ratio": 1.6402877697841727,
          "no_speech_prob": 0.0009398186230100691
        },
        {
          "id": 10,
          "seek": 5648,
          "start": 56.48,
          "end": 61.36,
          "text": " or we had these very complex pipelines for making natural language processing systems.",
          "tokens": [
            50364,
            420,
            321,
            632,
            613,
            588,
            3997,
            40168,
            337,
            1455,
            3303,
            2856,
            9007,
            3652,
            13,
            50608
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2608627700805664,
          "compression_ratio": 1.4691358024691359,
          "no_speech_prob": 0.0001511533191660419
        },
        {
          "id": 11,
          "seek": 5648,
          "start": 61.36,
          "end": 67.6,
          "text": " And now it's kind of one relatively simple architecture that does everything as opposed",
          "tokens": [
            50608,
            400,
            586,
            309,
            311,
            733,
            295,
            472,
            7226,
            2199,
            9482,
            300,
            775,
            1203,
            382,
            8851,
            50920
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2608627700805664,
          "compression_ratio": 1.4691358024691359,
          "no_speech_prob": 0.0001511533191660419
        },
        {
          "id": 12,
          "seek": 5648,
          "start": 67.6,
          "end": 71.08,
          "text": " to specific algorithms. And it's kind of head spinning, really.",
          "tokens": [
            50920,
            281,
            2685,
            14642,
            13,
            400,
            309,
            311,
            733,
            295,
            1378,
            15640,
            11,
            534,
            13,
            51094
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2608627700805664,
          "compression_ratio": 1.4691358024691359,
          "no_speech_prob": 0.0001511533191660419
        }
      ],
      "language": "en"
    },
    {
      "text": " Well, simple schematically, but very complicated in terms of what structure might be hidden in all those billions of neurons.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 5.16,
          "text": " Well, simple schematically, but very complicated in terms of what structure",
          "tokens": [
            50364,
            1042,
            11,
            2199,
            22627,
            5030,
            11,
            457,
            588,
            6179,
            294,
            2115,
            295,
            437,
            3877,
            50622
          ],
          "temperature": 0.0,
          "avg_logprob": -0.31841182708740234,
          "compression_ratio": 1.2135922330097086,
          "no_speech_prob": 0.0005504361470229924
        },
        {
          "id": 1,
          "seek": 0,
          "start": 5.16,
          "end": 7.4,
          "text": " might be hidden in all those billions of neurons.",
          "tokens": [
            50622,
            1062,
            312,
            7633,
            294,
            439,
            729,
            17375,
            295,
            22027,
            13,
            50734
          ],
          "temperature": 0.0,
          "avg_logprob": -0.31841182708740234,
          "compression_ratio": 1.2135922330097086,
          "no_speech_prob": 0.0005504361470229924
        }
      ],
      "language": "en"
    },
    {
      "text": " Yeah, it's simple in terms of what the people have to do and complex in terms of what the program is doing. I actually have an example that I was just trying last night because in the same talk, I gave an example of comparatives being very difficult to process automatically.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 2.08,
          "text": " Yeah, it's simple in terms of what the people have to do",
          "tokens": [
            50364,
            865,
            11,
            309,
            311,
            2199,
            294,
            2115,
            295,
            437,
            264,
            561,
            362,
            281,
            360,
            50468
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24120916639055526,
          "compression_ratio": 1.608187134502924,
          "no_speech_prob": 0.03770732879638672
        },
        {
          "id": 1,
          "seek": 0,
          "start": 2.08,
          "end": 4.42,
          "text": " and complex in terms of what the program is doing.",
          "tokens": [
            50468,
            293,
            3997,
            294,
            2115,
            295,
            437,
            264,
            1461,
            307,
            884,
            13,
            50585
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24120916639055526,
          "compression_ratio": 1.608187134502924,
          "no_speech_prob": 0.03770732879638672
        },
        {
          "id": 2,
          "seek": 0,
          "start": 4.42,
          "end": 7.34,
          "text": " I actually have an example that I was just trying last night",
          "tokens": [
            50585,
            286,
            767,
            362,
            364,
            1365,
            300,
            286,
            390,
            445,
            1382,
            1036,
            1818,
            50731
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24120916639055526,
          "compression_ratio": 1.608187134502924,
          "no_speech_prob": 0.03770732879638672
        },
        {
          "id": 3,
          "seek": 0,
          "start": 7.34,
          "end": 9.1,
          "text": " because in the same talk,",
          "tokens": [
            50731,
            570,
            294,
            264,
            912,
            751,
            11,
            50819
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24120916639055526,
          "compression_ratio": 1.608187134502924,
          "no_speech_prob": 0.03770732879638672
        },
        {
          "id": 4,
          "seek": 0,
          "start": 9.1,
          "end": 11.18,
          "text": " I gave an example of comparatives",
          "tokens": [
            50819,
            286,
            2729,
            364,
            1365,
            295,
            6311,
            4884,
            50923
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24120916639055526,
          "compression_ratio": 1.608187134502924,
          "no_speech_prob": 0.03770732879638672
        },
        {
          "id": 5,
          "seek": 0,
          "start": 11.18,
          "end": 13.48,
          "text": " being very difficult to process automatically.",
          "tokens": [
            50923,
            885,
            588,
            2252,
            281,
            1399,
            6772,
            13,
            51038
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24120916639055526,
          "compression_ratio": 1.608187134502924,
          "no_speech_prob": 0.03770732879638672
        }
      ],
      "language": "en"
    },
    {
      "text": " What's a comparative?",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 2.0,
          "text": " What's a comparative?",
          "tokens": [
            50364,
            708,
            311,
            257,
            39292,
            30,
            50464
          ],
          "temperature": 0.0,
          "avg_logprob": -0.5059148669242859,
          "compression_ratio": 0.7241379310344828,
          "no_speech_prob": 0.0003290668537374586
        }
      ],
      "language": "en"
    },
    {
      "text": " So if you have, say, a review of a camera and someone in their regular casual language is saying, oh, the DLSR has a wider angle, but the pixels are not as crisply retained. What are they saying is better than what? There's a lot implied there, and there's an implicit comparison between kind of the overall merits of some camera and then these specific components, the pixels and so on. And I use that as an example of something that it would be very hard to write an algorithm to process automatically. And one of the reviewers of the paper that I wrote said, yeah, that was true, but I just put this in Chat GPT and it worked really well. So last night I put all these super complex descriptions of reviews of cameras in Chat GPT and it did an amazing job of saying what was being compared to what. But I still say that it would be very hard to write an algorithm to process the language to do that.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 6.08,
          "text": " So if you have, say, a review of a camera and someone in their regular casual language is saying,",
          "tokens": [
            50364,
            407,
            498,
            291,
            362,
            11,
            584,
            11,
            257,
            3131,
            295,
            257,
            2799,
            293,
            1580,
            294,
            641,
            3890,
            13052,
            2856,
            307,
            1566,
            11,
            50668
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21509783246875863,
          "compression_ratio": 1.6451612903225807,
          "no_speech_prob": 0.07051416486501694
        },
        {
          "id": 1,
          "seek": 0,
          "start": 6.08,
          "end": 13.92,
          "text": " oh, the DLSR has a wider angle, but the pixels are not as crisply retained.",
          "tokens": [
            50668,
            1954,
            11,
            264,
            413,
            19198,
            49,
            575,
            257,
            11842,
            5802,
            11,
            457,
            264,
            18668,
            366,
            406,
            382,
            4661,
            2724,
            33438,
            13,
            51060
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21509783246875863,
          "compression_ratio": 1.6451612903225807,
          "no_speech_prob": 0.07051416486501694
        },
        {
          "id": 2,
          "seek": 0,
          "start": 13.92,
          "end": 19.12,
          "text": " What are they saying is better than what? There's a lot implied there, and there's an implicit",
          "tokens": [
            51060,
            708,
            366,
            436,
            1566,
            307,
            1101,
            813,
            437,
            30,
            821,
            311,
            257,
            688,
            32614,
            456,
            11,
            293,
            456,
            311,
            364,
            26947,
            51320
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21509783246875863,
          "compression_ratio": 1.6451612903225807,
          "no_speech_prob": 0.07051416486501694
        },
        {
          "id": 3,
          "seek": 0,
          "start": 19.12,
          "end": 25.44,
          "text": " comparison between kind of the overall merits of some camera and then these specific components,",
          "tokens": [
            51320,
            9660,
            1296,
            733,
            295,
            264,
            4787,
            40923,
            295,
            512,
            2799,
            293,
            550,
            613,
            2685,
            6677,
            11,
            51636
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21509783246875863,
          "compression_ratio": 1.6451612903225807,
          "no_speech_prob": 0.07051416486501694
        },
        {
          "id": 4,
          "seek": 0,
          "start": 25.44,
          "end": 29.68,
          "text": " the pixels and so on. And I use that as an example of something that it would be very hard to",
          "tokens": [
            51636,
            264,
            18668,
            293,
            370,
            322,
            13,
            400,
            286,
            764,
            300,
            382,
            364,
            1365,
            295,
            746,
            300,
            309,
            576,
            312,
            588,
            1152,
            281,
            51848
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21509783246875863,
          "compression_ratio": 1.6451612903225807,
          "no_speech_prob": 0.07051416486501694
        },
        {
          "id": 5,
          "seek": 3000,
          "start": 30.4,
          "end": 35.04,
          "text": " write an algorithm to process automatically. And one of the reviewers of the paper that I wrote",
          "tokens": [
            50384,
            2464,
            364,
            9284,
            281,
            1399,
            6772,
            13,
            400,
            472,
            295,
            264,
            45837,
            295,
            264,
            3035,
            300,
            286,
            4114,
            50616
          ],
          "temperature": 0.0,
          "avg_logprob": -0.20245257939133687,
          "compression_ratio": 1.753968253968254,
          "no_speech_prob": 0.00017129501793533564
        },
        {
          "id": 6,
          "seek": 3000,
          "start": 35.04,
          "end": 38.8,
          "text": " said, yeah, that was true, but I just put this in Chat GPT and it worked really well.",
          "tokens": [
            50616,
            848,
            11,
            1338,
            11,
            300,
            390,
            2074,
            11,
            457,
            286,
            445,
            829,
            341,
            294,
            27503,
            26039,
            51,
            293,
            309,
            2732,
            534,
            731,
            13,
            50804
          ],
          "temperature": 0.0,
          "avg_logprob": -0.20245257939133687,
          "compression_ratio": 1.753968253968254,
          "no_speech_prob": 0.00017129501793533564
        },
        {
          "id": 7,
          "seek": 3000,
          "start": 39.44,
          "end": 45.44,
          "text": " So last night I put all these super complex descriptions of reviews of cameras in Chat",
          "tokens": [
            50836,
            407,
            1036,
            1818,
            286,
            829,
            439,
            613,
            1687,
            3997,
            24406,
            295,
            10229,
            295,
            8622,
            294,
            27503,
            51136
          ],
          "temperature": 0.0,
          "avg_logprob": -0.20245257939133687,
          "compression_ratio": 1.753968253968254,
          "no_speech_prob": 0.00017129501793533564
        },
        {
          "id": 8,
          "seek": 3000,
          "start": 45.44,
          "end": 50.56,
          "text": " GPT and it did an amazing job of saying what was being compared to what. But I still say that it",
          "tokens": [
            51136,
            26039,
            51,
            293,
            309,
            630,
            364,
            2243,
            1691,
            295,
            1566,
            437,
            390,
            885,
            5347,
            281,
            437,
            13,
            583,
            286,
            920,
            584,
            300,
            309,
            51392
          ],
          "temperature": 0.0,
          "avg_logprob": -0.20245257939133687,
          "compression_ratio": 1.753968253968254,
          "no_speech_prob": 0.00017129501793533564
        },
        {
          "id": 9,
          "seek": 3000,
          "start": 50.56,
          "end": 54.400000000000006,
          "text": " would be very hard to write an algorithm to process the language to do that.",
          "tokens": [
            51392,
            576,
            312,
            588,
            1152,
            281,
            2464,
            364,
            9284,
            281,
            1399,
            264,
            2856,
            281,
            360,
            300,
            13,
            51584
          ],
          "temperature": 0.0,
          "avg_logprob": -0.20245257939133687,
          "compression_ratio": 1.753968253968254,
          "no_speech_prob": 0.00017129501793533564
        }
      ],
      "language": "en"
    },
    {
      "text": " Absolutely.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 0.84,
          "text": " Absolutely.",
          "tokens": [
            50364,
            7021,
            13,
            50406
          ],
          "temperature": 0.0,
          "avg_logprob": -0.5477873802185058,
          "compression_ratio": 0.5789473684210527,
          "no_speech_prob": 0.004217848181724548
        }
      ],
      "language": "en"
    },
    {
      "text": " It's a general purpose tool that does that as a side effect of what else it does.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 4.5600000000000005,
          "text": " It's a general purpose tool that does that as a side effect of what else it does.",
          "tokens": [
            50364,
            467,
            311,
            257,
            2674,
            4334,
            2290,
            300,
            775,
            300,
            382,
            257,
            1252,
            1802,
            295,
            437,
            1646,
            309,
            775,
            13,
            50592
          ],
          "temperature": 0.0,
          "avg_logprob": -0.26400730826637964,
          "compression_ratio": 1.1095890410958904,
          "no_speech_prob": 5.295280789141543e-05
        }
      ],
      "language": "en"
    },
    {
      "text": " Yeah, it's sort of an all-purpose reasoning machine.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 2.8000000000000003,
          "text": " Yeah, it's sort of an all-purpose reasoning machine.",
          "tokens": [
            50364,
            865,
            11,
            309,
            311,
            1333,
            295,
            364,
            439,
            12,
            42601,
            21577,
            3479,
            13,
            50504
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3689664602279663,
          "compression_ratio": 0.8666666666666667,
          "no_speech_prob": 0.0007594863418489695
        }
      ],
      "language": "en"
    },
    {
      "text": " It's something. I don't know what it is.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 1.0,
          "text": " It's something.",
          "tokens": [
            50364,
            467,
            311,
            746,
            13,
            50414
          ],
          "temperature": 0.0,
          "avg_logprob": -0.42869194816140566,
          "compression_ratio": 0.8695652173913043,
          "no_speech_prob": 0.0010261954739689827
        },
        {
          "id": 1,
          "seek": 0,
          "start": 1.0,
          "end": 3.52,
          "text": " I don't know what it is.",
          "tokens": [
            50414,
            286,
            500,
            380,
            458,
            437,
            309,
            307,
            13,
            50540
          ],
          "temperature": 0.0,
          "avg_logprob": -0.42869194816140566,
          "compression_ratio": 0.8695652173913043,
          "no_speech_prob": 0.0010261954739689827
        }
      ],
      "language": "en"
    },
    {
      "text": " So I watched your keynote and found it really, really remarkable. And something that was gestating in my mind, as I watched you walk through all the latest research that you could dig up on the human computer interface and also language and the visual component of people trying to understand complex topics was that we're probably soon heading into a world where you can essentially go to a whiteboard with a model like Chat GPT. So at work, when I need to understand something really complicated or communicate something really complicated or collaborate with someone on a really complicated problem, we go to the whiteboard. That's sort of the best environment to do this. And what that means is you have all the affordances of language, just speaking one-on-one, and you also have this whiteboard next to you that you can diagram things, correct things, point things out visually. And so it's sort of maximum bandwidth and it feels like the most comfortable way to navigate really complicated things. I think that we've clearly gone way down the road of the chat side of this, the language side of this, and you can interact with Chat GPT and talk about really complicated things, maybe even solve problems together. But there isn't yet that whiteboard, but I think it's coming. And we saw a hint of it with the demonstration video of GPT-4. So it seems safe to say that we're headed towards AI whiteboards and you have been grappling with the nuts and bolts of how you communicate both visually and with language and how the two play off each other, sometimes synergistically. Love to pick your brain just on what it's going to mean heading into a world of AI whiteboards. And of course it goes way beyond whiteboards. It could show you arbitrary images, videos it generates, things it finds from the internet and actually points things out and illustrates it.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 4.24,
          "text": " So I watched your keynote and found it really, really remarkable.",
          "tokens": [
            50364,
            407,
            286,
            6337,
            428,
            33896,
            293,
            1352,
            309,
            534,
            11,
            534,
            12802,
            13,
            50576
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2578412270059391,
          "compression_ratio": 1.628787878787879,
          "no_speech_prob": 0.07788333296775818
        },
        {
          "id": 1,
          "seek": 0,
          "start": 4.3,
          "end": 9.3,
          "text": " And something that was gestating in my mind, as I watched you walk through all",
          "tokens": [
            50579,
            400,
            746,
            300,
            390,
            7219,
            990,
            294,
            452,
            1575,
            11,
            382,
            286,
            6337,
            291,
            1792,
            807,
            439,
            50829
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2578412270059391,
          "compression_ratio": 1.628787878787879,
          "no_speech_prob": 0.07788333296775818
        },
        {
          "id": 2,
          "seek": 0,
          "start": 9.3,
          "end": 14.700000000000001,
          "text": " the latest research that you could dig up on the human computer interface and",
          "tokens": [
            50829,
            264,
            6792,
            2132,
            300,
            291,
            727,
            2528,
            493,
            322,
            264,
            1952,
            3820,
            9226,
            293,
            51099
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2578412270059391,
          "compression_ratio": 1.628787878787879,
          "no_speech_prob": 0.07788333296775818
        },
        {
          "id": 3,
          "seek": 0,
          "start": 14.700000000000001,
          "end": 19.02,
          "text": " also language and the visual component of people trying to understand complex",
          "tokens": [
            51099,
            611,
            2856,
            293,
            264,
            5056,
            6542,
            295,
            561,
            1382,
            281,
            1223,
            3997,
            51315
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2578412270059391,
          "compression_ratio": 1.628787878787879,
          "no_speech_prob": 0.07788333296775818
        },
        {
          "id": 4,
          "seek": 0,
          "start": 19.02,
          "end": 23.48,
          "text": " topics was that we're probably soon heading into a world where you can",
          "tokens": [
            51315,
            8378,
            390,
            300,
            321,
            434,
            1391,
            2321,
            9864,
            666,
            257,
            1002,
            689,
            291,
            393,
            51538
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2578412270059391,
          "compression_ratio": 1.628787878787879,
          "no_speech_prob": 0.07788333296775818
        },
        {
          "id": 5,
          "seek": 0,
          "start": 23.48,
          "end": 27.240000000000002,
          "text": " essentially go to a whiteboard with a model like Chat GPT.",
          "tokens": [
            51538,
            4476,
            352,
            281,
            257,
            2418,
            3787,
            365,
            257,
            2316,
            411,
            27503,
            26039,
            51,
            13,
            51726
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2578412270059391,
          "compression_ratio": 1.628787878787879,
          "no_speech_prob": 0.07788333296775818
        },
        {
          "id": 6,
          "seek": 2724,
          "start": 27.52,
          "end": 32.28,
          "text": " So at work, when I need to understand something really complicated or",
          "tokens": [
            50378,
            407,
            412,
            589,
            11,
            562,
            286,
            643,
            281,
            1223,
            746,
            534,
            6179,
            420,
            50616
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2727710354712702,
          "compression_ratio": 1.8275862068965518,
          "no_speech_prob": 0.026753854006528854
        },
        {
          "id": 7,
          "seek": 2724,
          "start": 32.28,
          "end": 36.36,
          "text": " communicate something really complicated or collaborate with someone on a really",
          "tokens": [
            50616,
            7890,
            746,
            534,
            6179,
            420,
            18338,
            365,
            1580,
            322,
            257,
            534,
            50820
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2727710354712702,
          "compression_ratio": 1.8275862068965518,
          "no_speech_prob": 0.026753854006528854
        },
        {
          "id": 8,
          "seek": 2724,
          "start": 36.44,
          "end": 38.44,
          "text": " complicated problem, we go to the whiteboard.",
          "tokens": [
            50824,
            6179,
            1154,
            11,
            321,
            352,
            281,
            264,
            2418,
            3787,
            13,
            50924
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2727710354712702,
          "compression_ratio": 1.8275862068965518,
          "no_speech_prob": 0.026753854006528854
        },
        {
          "id": 9,
          "seek": 2724,
          "start": 38.879999999999995,
          "end": 40.879999999999995,
          "text": " That's sort of the best environment to do this.",
          "tokens": [
            50946,
            663,
            311,
            1333,
            295,
            264,
            1151,
            2823,
            281,
            360,
            341,
            13,
            51046
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2727710354712702,
          "compression_ratio": 1.8275862068965518,
          "no_speech_prob": 0.026753854006528854
        },
        {
          "id": 10,
          "seek": 2724,
          "start": 41.08,
          "end": 44.519999999999996,
          "text": " And what that means is you have all the affordances of language, just speaking",
          "tokens": [
            51056,
            400,
            437,
            300,
            1355,
            307,
            291,
            362,
            439,
            264,
            6157,
            2676,
            295,
            2856,
            11,
            445,
            4124,
            51228
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2727710354712702,
          "compression_ratio": 1.8275862068965518,
          "no_speech_prob": 0.026753854006528854
        },
        {
          "id": 11,
          "seek": 2724,
          "start": 44.56,
          "end": 47.72,
          "text": " one-on-one, and you also have this whiteboard next to you that you can",
          "tokens": [
            51230,
            472,
            12,
            266,
            12,
            546,
            11,
            293,
            291,
            611,
            362,
            341,
            2418,
            3787,
            958,
            281,
            291,
            300,
            291,
            393,
            51388
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2727710354712702,
          "compression_ratio": 1.8275862068965518,
          "no_speech_prob": 0.026753854006528854
        },
        {
          "id": 12,
          "seek": 2724,
          "start": 47.78,
          "end": 51.239999999999995,
          "text": " diagram things, correct things, point things out visually.",
          "tokens": [
            51391,
            10686,
            721,
            11,
            3006,
            721,
            11,
            935,
            721,
            484,
            19622,
            13,
            51564
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2727710354712702,
          "compression_ratio": 1.8275862068965518,
          "no_speech_prob": 0.026753854006528854
        },
        {
          "id": 13,
          "seek": 2724,
          "start": 51.76,
          "end": 55.28,
          "text": " And so it's sort of maximum bandwidth and it feels like the most comfortable",
          "tokens": [
            51590,
            400,
            370,
            309,
            311,
            1333,
            295,
            6674,
            23647,
            293,
            309,
            3417,
            411,
            264,
            881,
            4619,
            51766
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2727710354712702,
          "compression_ratio": 1.8275862068965518,
          "no_speech_prob": 0.026753854006528854
        },
        {
          "id": 14,
          "seek": 5528,
          "start": 55.28,
          "end": 58.28,
          "text": " way to navigate really complicated things.",
          "tokens": [
            50364,
            636,
            281,
            12350,
            534,
            6179,
            721,
            13,
            50514
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2620212971663275,
          "compression_ratio": 1.7007299270072993,
          "no_speech_prob": 0.027582570910453796
        },
        {
          "id": 15,
          "seek": 5528,
          "start": 58.6,
          "end": 63.68,
          "text": " I think that we've clearly gone way down the road of the chat side of this, the",
          "tokens": [
            50530,
            286,
            519,
            300,
            321,
            600,
            4448,
            2780,
            636,
            760,
            264,
            3060,
            295,
            264,
            5081,
            1252,
            295,
            341,
            11,
            264,
            50784
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2620212971663275,
          "compression_ratio": 1.7007299270072993,
          "no_speech_prob": 0.027582570910453796
        },
        {
          "id": 16,
          "seek": 5528,
          "start": 63.68,
          "end": 67.52,
          "text": " language side of this, and you can interact with Chat GPT and talk about",
          "tokens": [
            50784,
            2856,
            1252,
            295,
            341,
            11,
            293,
            291,
            393,
            4648,
            365,
            27503,
            26039,
            51,
            293,
            751,
            466,
            50976
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2620212971663275,
          "compression_ratio": 1.7007299270072993,
          "no_speech_prob": 0.027582570910453796
        },
        {
          "id": 17,
          "seek": 5528,
          "start": 67.68,
          "end": 70.44,
          "text": " really complicated things, maybe even solve problems together.",
          "tokens": [
            50984,
            534,
            6179,
            721,
            11,
            1310,
            754,
            5039,
            2740,
            1214,
            13,
            51122
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2620212971663275,
          "compression_ratio": 1.7007299270072993,
          "no_speech_prob": 0.027582570910453796
        },
        {
          "id": 18,
          "seek": 5528,
          "start": 70.76,
          "end": 72.8,
          "text": " But there isn't yet that whiteboard, but I think it's coming.",
          "tokens": [
            51138,
            583,
            456,
            1943,
            380,
            1939,
            300,
            2418,
            3787,
            11,
            457,
            286,
            519,
            309,
            311,
            1348,
            13,
            51240
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2620212971663275,
          "compression_ratio": 1.7007299270072993,
          "no_speech_prob": 0.027582570910453796
        },
        {
          "id": 19,
          "seek": 5528,
          "start": 72.8,
          "end": 76.52000000000001,
          "text": " And we saw a hint of it with the demonstration video of GPT-4.",
          "tokens": [
            51240,
            400,
            321,
            1866,
            257,
            12075,
            295,
            309,
            365,
            264,
            16520,
            960,
            295,
            26039,
            51,
            12,
            19,
            13,
            51426
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2620212971663275,
          "compression_ratio": 1.7007299270072993,
          "no_speech_prob": 0.027582570910453796
        },
        {
          "id": 20,
          "seek": 5528,
          "start": 76.88,
          "end": 82.6,
          "text": " So it seems safe to say that we're headed towards AI whiteboards and you have been",
          "tokens": [
            51444,
            407,
            309,
            2544,
            3273,
            281,
            584,
            300,
            321,
            434,
            12798,
            3030,
            7318,
            2418,
            17228,
            293,
            291,
            362,
            668,
            51730
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2620212971663275,
          "compression_ratio": 1.7007299270072993,
          "no_speech_prob": 0.027582570910453796
        },
        {
          "id": 21,
          "seek": 8260,
          "start": 82.72,
          "end": 89.44,
          "text": " grappling with the nuts and bolts of how you communicate both visually and with",
          "tokens": [
            50370,
            50086,
            365,
            264,
            10483,
            293,
            18127,
            295,
            577,
            291,
            7890,
            1293,
            19622,
            293,
            365,
            50706
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2585201835632324,
          "compression_ratio": 1.6452830188679246,
          "no_speech_prob": 0.00020024104742333293
        },
        {
          "id": 22,
          "seek": 8260,
          "start": 89.44,
          "end": 94.44,
          "text": " language and how the two play off each other, sometimes synergistically.",
          "tokens": [
            50706,
            2856,
            293,
            577,
            264,
            732,
            862,
            766,
            1184,
            661,
            11,
            2171,
            33781,
            70,
            20458,
            13,
            50956
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2585201835632324,
          "compression_ratio": 1.6452830188679246,
          "no_speech_prob": 0.00020024104742333293
        },
        {
          "id": 23,
          "seek": 8260,
          "start": 94.64,
          "end": 98.47999999999999,
          "text": " Love to pick your brain just on what it's going to mean heading into a world of AI",
          "tokens": [
            50966,
            5956,
            281,
            1888,
            428,
            3567,
            445,
            322,
            437,
            309,
            311,
            516,
            281,
            914,
            9864,
            666,
            257,
            1002,
            295,
            7318,
            51158
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2585201835632324,
          "compression_ratio": 1.6452830188679246,
          "no_speech_prob": 0.00020024104742333293
        },
        {
          "id": 24,
          "seek": 8260,
          "start": 98.47999999999999,
          "end": 101.32,
          "text": " whiteboards. And of course it goes way beyond whiteboards.",
          "tokens": [
            51158,
            2418,
            17228,
            13,
            400,
            295,
            1164,
            309,
            1709,
            636,
            4399,
            2418,
            17228,
            13,
            51300
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2585201835632324,
          "compression_ratio": 1.6452830188679246,
          "no_speech_prob": 0.00020024104742333293
        },
        {
          "id": 25,
          "seek": 8260,
          "start": 101.32,
          "end": 105.91999999999999,
          "text": " It could show you arbitrary images, videos it generates, things it finds from the",
          "tokens": [
            51300,
            467,
            727,
            855,
            291,
            23211,
            5267,
            11,
            2145,
            309,
            23815,
            11,
            721,
            309,
            10704,
            490,
            264,
            51530
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2585201835632324,
          "compression_ratio": 1.6452830188679246,
          "no_speech_prob": 0.00020024104742333293
        },
        {
          "id": 26,
          "seek": 8260,
          "start": 105.91999999999999,
          "end": 109.32,
          "text": " internet and actually points things out and illustrates it.",
          "tokens": [
            51530,
            4705,
            293,
            767,
            2793,
            721,
            484,
            293,
            41718,
            309,
            13,
            51700
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2585201835632324,
          "compression_ratio": 1.6452830188679246,
          "no_speech_prob": 0.00020024104742333293
        }
      ],
      "language": "en"
    },
    {
      "text": " Yeah, I think that there's a lot of potential for these tools, these large language model-based tools to be collaborators in thinking. I think that's what you mean by the whiteboard. But after I'd done my keynote, I did actually ask Chat GPT to make an outline of a talk on the subject that I had selected. And it was not very creative. It said things that made sense, but it would have been, I guess, somebody who kind of knew the field, but was not innovating, was not seeing the future. And so I don't know that it's capable of doing that. Yet, I listened to the interview with Sergey and he, here at Berkeley, Sergey Levin on reinforcement learning, and he kind of pointed out that it's not using technology to kind of do future sequencing, but they're working on it, I guess. Or they might work on it.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 4.5600000000000005,
          "text": " Yeah, I think that there's a lot of potential for these tools, these large",
          "tokens": [
            50364,
            865,
            11,
            286,
            519,
            300,
            456,
            311,
            257,
            688,
            295,
            3995,
            337,
            613,
            3873,
            11,
            613,
            2416,
            50592
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24894362005568643,
          "compression_ratio": 1.6464646464646464,
          "no_speech_prob": 0.018809888511896133
        },
        {
          "id": 1,
          "seek": 0,
          "start": 4.5600000000000005,
          "end": 8.56,
          "text": " language model-based tools to be collaborators in thinking.",
          "tokens": [
            50592,
            2856,
            2316,
            12,
            6032,
            3873,
            281,
            312,
            39789,
            294,
            1953,
            13,
            50792
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24894362005568643,
          "compression_ratio": 1.6464646464646464,
          "no_speech_prob": 0.018809888511896133
        },
        {
          "id": 2,
          "seek": 0,
          "start": 8.88,
          "end": 10.72,
          "text": " I think that's what you mean by the whiteboard.",
          "tokens": [
            50808,
            286,
            519,
            300,
            311,
            437,
            291,
            914,
            538,
            264,
            2418,
            3787,
            13,
            50900
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24894362005568643,
          "compression_ratio": 1.6464646464646464,
          "no_speech_prob": 0.018809888511896133
        },
        {
          "id": 3,
          "seek": 0,
          "start": 11.200000000000001,
          "end": 16.32,
          "text": " But after I'd done my keynote, I did actually ask Chat GPT to make an outline",
          "tokens": [
            50924,
            583,
            934,
            286,
            1116,
            1096,
            452,
            33896,
            11,
            286,
            630,
            767,
            1029,
            27503,
            26039,
            51,
            281,
            652,
            364,
            16387,
            51180
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24894362005568643,
          "compression_ratio": 1.6464646464646464,
          "no_speech_prob": 0.018809888511896133
        },
        {
          "id": 4,
          "seek": 0,
          "start": 16.32,
          "end": 18.76,
          "text": " of a talk on the subject that I had selected.",
          "tokens": [
            51180,
            295,
            257,
            751,
            322,
            264,
            3983,
            300,
            286,
            632,
            8209,
            13,
            51302
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24894362005568643,
          "compression_ratio": 1.6464646464646464,
          "no_speech_prob": 0.018809888511896133
        },
        {
          "id": 5,
          "seek": 0,
          "start": 18.96,
          "end": 20.52,
          "text": " And it was not very creative.",
          "tokens": [
            51312,
            400,
            309,
            390,
            406,
            588,
            5880,
            13,
            51390
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24894362005568643,
          "compression_ratio": 1.6464646464646464,
          "no_speech_prob": 0.018809888511896133
        },
        {
          "id": 6,
          "seek": 0,
          "start": 20.52,
          "end": 24.400000000000002,
          "text": " It said things that made sense, but it would have been, I guess, somebody",
          "tokens": [
            51390,
            467,
            848,
            721,
            300,
            1027,
            2020,
            11,
            457,
            309,
            576,
            362,
            668,
            11,
            286,
            2041,
            11,
            2618,
            51584
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24894362005568643,
          "compression_ratio": 1.6464646464646464,
          "no_speech_prob": 0.018809888511896133
        },
        {
          "id": 7,
          "seek": 0,
          "start": 24.400000000000002,
          "end": 29.44,
          "text": " who kind of knew the field, but was not innovating, was not seeing the future.",
          "tokens": [
            51584,
            567,
            733,
            295,
            2586,
            264,
            2519,
            11,
            457,
            390,
            406,
            5083,
            990,
            11,
            390,
            406,
            2577,
            264,
            2027,
            13,
            51836
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24894362005568643,
          "compression_ratio": 1.6464646464646464,
          "no_speech_prob": 0.018809888511896133
        },
        {
          "id": 8,
          "seek": 2944,
          "start": 29.44,
          "end": 31.8,
          "text": " And so I don't know that it's capable of doing that.",
          "tokens": [
            50364,
            400,
            370,
            286,
            500,
            380,
            458,
            300,
            309,
            311,
            8189,
            295,
            884,
            300,
            13,
            50482
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25192381086803617,
          "compression_ratio": 1.5339805825242718,
          "no_speech_prob": 7.839030877221376e-05
        },
        {
          "id": 9,
          "seek": 2944,
          "start": 32.120000000000005,
          "end": 36.92,
          "text": " Yet, I listened to the interview with Sergey and he, here at Berkeley, Sergey",
          "tokens": [
            50498,
            10890,
            11,
            286,
            13207,
            281,
            264,
            4049,
            365,
            49238,
            293,
            415,
            11,
            510,
            412,
            23684,
            11,
            49238,
            50738
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25192381086803617,
          "compression_ratio": 1.5339805825242718,
          "no_speech_prob": 7.839030877221376e-05
        },
        {
          "id": 10,
          "seek": 2944,
          "start": 36.92,
          "end": 41.24,
          "text": " Levin on reinforcement learning, and he kind of pointed out that it's not using",
          "tokens": [
            50738,
            1456,
            4796,
            322,
            29280,
            2539,
            11,
            293,
            415,
            733,
            295,
            10932,
            484,
            300,
            309,
            311,
            406,
            1228,
            50954
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25192381086803617,
          "compression_ratio": 1.5339805825242718,
          "no_speech_prob": 7.839030877221376e-05
        },
        {
          "id": 11,
          "seek": 2944,
          "start": 41.24,
          "end": 45.96,
          "text": " technology to kind of do future sequencing, but they're working on it, I guess.",
          "tokens": [
            50954,
            2899,
            281,
            733,
            295,
            360,
            2027,
            32693,
            11,
            457,
            436,
            434,
            1364,
            322,
            309,
            11,
            286,
            2041,
            13,
            51190
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25192381086803617,
          "compression_ratio": 1.5339805825242718,
          "no_speech_prob": 7.839030877221376e-05
        },
        {
          "id": 12,
          "seek": 2944,
          "start": 45.96,
          "end": 46.760000000000005,
          "text": " Or they might work on it.",
          "tokens": [
            51190,
            1610,
            436,
            1062,
            589,
            322,
            309,
            13,
            51230
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25192381086803617,
          "compression_ratio": 1.5339805825242718,
          "no_speech_prob": 7.839030877221376e-05
        }
      ],
      "language": "en"
    },
    {
      "text": " Yeah.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 0.5,
          "text": " Yeah.",
          "tokens": [
            50364,
            865,
            13,
            50389
          ],
          "temperature": 0.0,
          "avg_logprob": -0.4355937957763672,
          "compression_ratio": 0.38461538461538464,
          "no_speech_prob": 0.10878219455480576
        }
      ],
      "language": "en"
    },
    {
      "text": " Yeah, no doubt the human is going to have to do most of the intellectual heavy lifting in the beginning. I mean, what is it going to mean for information sharing and explaining when we can use something as powerful as Chat GPT in the language regime, also in the visual regime?",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 4.64,
          "text": " Yeah, no doubt the human is going to have to do most of the intellectual heavy lifting in the beginning.",
          "tokens": [
            50364,
            865,
            11,
            572,
            6385,
            264,
            1952,
            307,
            516,
            281,
            362,
            281,
            360,
            881,
            295,
            264,
            12576,
            4676,
            15798,
            294,
            264,
            2863,
            13,
            50596
          ],
          "temperature": 0.0,
          "avg_logprob": -0.28654588552621696,
          "compression_ratio": 1.5136612021857923,
          "no_speech_prob": 0.0027400709223002195
        },
        {
          "id": 1,
          "seek": 0,
          "start": 4.64,
          "end": 10.96,
          "text": " I mean, what is it going to mean for information sharing and explaining when we can use something",
          "tokens": [
            50596,
            286,
            914,
            11,
            437,
            307,
            309,
            516,
            281,
            914,
            337,
            1589,
            5414,
            293,
            13468,
            562,
            321,
            393,
            764,
            746,
            50912
          ],
          "temperature": 0.0,
          "avg_logprob": -0.28654588552621696,
          "compression_ratio": 1.5136612021857923,
          "no_speech_prob": 0.0027400709223002195
        },
        {
          "id": 2,
          "seek": 0,
          "start": 10.96,
          "end": 14.64,
          "text": " as powerful as Chat GPT in the language regime, also in the visual regime?",
          "tokens": [
            50912,
            382,
            4005,
            382,
            27503,
            26039,
            51,
            294,
            264,
            2856,
            13120,
            11,
            611,
            294,
            264,
            5056,
            13120,
            30,
            51096
          ],
          "temperature": 0.0,
          "avg_logprob": -0.28654588552621696,
          "compression_ratio": 1.5136612021857923,
          "no_speech_prob": 0.0027400709223002195
        }
      ],
      "language": "en"
    },
    {
      "text": " Yeah, so, and referring back to that keynote a bit, the topic is the intersection of language and visualization, because the information visualization community focuses reasonably on how to visualize data, how to visualize information, and there's been less of a focus of how does language or text overlay on that or interact with that. And I mentioned this in our earlier conversation with John, that for many semesters or many years, I was teaching natural language processing in the fall and information visualization in the spring, and thinking about what sort of information can be represented in each modality, and can you convert one to the other directly? And I think the answer is no, they show or they explain different things, visuals explain different things than text. And if you think about the movie versus the book, that's like the best example. There are some books written to be made into movies. You think about the Harry Potter series, for example, and they're very true to the original, I think, but there's a lot that don't transfer so well. And a lot of it is about interiority and mood that mood is expressed differently with words than with images. And they complement each other, of course, which is why the soundtrack is so important for the film. When you become a grownup, you don't have pictures in your novels anymore.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 1.96,
          "text": " Yeah, so, and referring back to that keynote a bit,",
          "tokens": [
            50364,
            865,
            11,
            370,
            11,
            293,
            13761,
            646,
            281,
            300,
            33896,
            257,
            857,
            11,
            50462
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2317275390625,
          "compression_ratio": 1.8971631205673758,
          "no_speech_prob": 0.02436479553580284
        },
        {
          "id": 1,
          "seek": 0,
          "start": 1.96,
          "end": 6.04,
          "text": " the topic is the intersection of language and visualization,",
          "tokens": [
            50462,
            264,
            4829,
            307,
            264,
            15236,
            295,
            2856,
            293,
            25801,
            11,
            50666
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2317275390625,
          "compression_ratio": 1.8971631205673758,
          "no_speech_prob": 0.02436479553580284
        },
        {
          "id": 2,
          "seek": 0,
          "start": 6.04,
          "end": 8.16,
          "text": " because the information visualization community",
          "tokens": [
            50666,
            570,
            264,
            1589,
            25801,
            1768,
            50772
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2317275390625,
          "compression_ratio": 1.8971631205673758,
          "no_speech_prob": 0.02436479553580284
        },
        {
          "id": 3,
          "seek": 0,
          "start": 8.16,
          "end": 11.16,
          "text": " focuses reasonably on how to visualize data,",
          "tokens": [
            50772,
            16109,
            23551,
            322,
            577,
            281,
            23273,
            1412,
            11,
            50922
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2317275390625,
          "compression_ratio": 1.8971631205673758,
          "no_speech_prob": 0.02436479553580284
        },
        {
          "id": 4,
          "seek": 0,
          "start": 11.16,
          "end": 12.68,
          "text": " how to visualize information,",
          "tokens": [
            50922,
            577,
            281,
            23273,
            1589,
            11,
            50998
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2317275390625,
          "compression_ratio": 1.8971631205673758,
          "no_speech_prob": 0.02436479553580284
        },
        {
          "id": 5,
          "seek": 0,
          "start": 12.68,
          "end": 13.8,
          "text": " and there's been less of a focus",
          "tokens": [
            50998,
            293,
            456,
            311,
            668,
            1570,
            295,
            257,
            1879,
            51054
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2317275390625,
          "compression_ratio": 1.8971631205673758,
          "no_speech_prob": 0.02436479553580284
        },
        {
          "id": 6,
          "seek": 0,
          "start": 13.8,
          "end": 16.8,
          "text": " of how does language or text overlay on that",
          "tokens": [
            51054,
            295,
            577,
            775,
            2856,
            420,
            2487,
            31741,
            322,
            300,
            51204
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2317275390625,
          "compression_ratio": 1.8971631205673758,
          "no_speech_prob": 0.02436479553580284
        },
        {
          "id": 7,
          "seek": 0,
          "start": 16.8,
          "end": 17.96,
          "text": " or interact with that.",
          "tokens": [
            51204,
            420,
            4648,
            365,
            300,
            13,
            51262
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2317275390625,
          "compression_ratio": 1.8971631205673758,
          "no_speech_prob": 0.02436479553580284
        },
        {
          "id": 8,
          "seek": 0,
          "start": 17.96,
          "end": 21.0,
          "text": " And I mentioned this in our earlier conversation with John,",
          "tokens": [
            51262,
            400,
            286,
            2835,
            341,
            294,
            527,
            3071,
            3761,
            365,
            2619,
            11,
            51414
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2317275390625,
          "compression_ratio": 1.8971631205673758,
          "no_speech_prob": 0.02436479553580284
        },
        {
          "id": 9,
          "seek": 0,
          "start": 21.0,
          "end": 23.240000000000002,
          "text": " that for many semesters or many years,",
          "tokens": [
            51414,
            300,
            337,
            867,
            4361,
            38561,
            420,
            867,
            924,
            11,
            51526
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2317275390625,
          "compression_ratio": 1.8971631205673758,
          "no_speech_prob": 0.02436479553580284
        },
        {
          "id": 10,
          "seek": 0,
          "start": 23.240000000000002,
          "end": 26.64,
          "text": " I was teaching natural language processing in the fall",
          "tokens": [
            51526,
            286,
            390,
            4571,
            3303,
            2856,
            9007,
            294,
            264,
            2100,
            51696
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2317275390625,
          "compression_ratio": 1.8971631205673758,
          "no_speech_prob": 0.02436479553580284
        },
        {
          "id": 11,
          "seek": 0,
          "start": 26.64,
          "end": 28.8,
          "text": " and information visualization in the spring,",
          "tokens": [
            51696,
            293,
            1589,
            25801,
            294,
            264,
            5587,
            11,
            51804
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2317275390625,
          "compression_ratio": 1.8971631205673758,
          "no_speech_prob": 0.02436479553580284
        },
        {
          "id": 12,
          "seek": 2880,
          "start": 28.8,
          "end": 31.0,
          "text": " and thinking about what sort of information",
          "tokens": [
            50364,
            293,
            1953,
            466,
            437,
            1333,
            295,
            1589,
            50474
          ],
          "temperature": 0.0,
          "avg_logprob": -0.18266211756017825,
          "compression_ratio": 1.8132911392405062,
          "no_speech_prob": 0.0008293993887491524
        },
        {
          "id": 13,
          "seek": 2880,
          "start": 31.0,
          "end": 33.120000000000005,
          "text": " can be represented in each modality,",
          "tokens": [
            50474,
            393,
            312,
            10379,
            294,
            1184,
            1072,
            1860,
            11,
            50580
          ],
          "temperature": 0.0,
          "avg_logprob": -0.18266211756017825,
          "compression_ratio": 1.8132911392405062,
          "no_speech_prob": 0.0008293993887491524
        },
        {
          "id": 14,
          "seek": 2880,
          "start": 33.120000000000005,
          "end": 35.96,
          "text": " and can you convert one to the other directly?",
          "tokens": [
            50580,
            293,
            393,
            291,
            7620,
            472,
            281,
            264,
            661,
            3838,
            30,
            50722
          ],
          "temperature": 0.0,
          "avg_logprob": -0.18266211756017825,
          "compression_ratio": 1.8132911392405062,
          "no_speech_prob": 0.0008293993887491524
        },
        {
          "id": 15,
          "seek": 2880,
          "start": 35.96,
          "end": 37.4,
          "text": " And I think the answer is no,",
          "tokens": [
            50722,
            400,
            286,
            519,
            264,
            1867,
            307,
            572,
            11,
            50794
          ],
          "temperature": 0.0,
          "avg_logprob": -0.18266211756017825,
          "compression_ratio": 1.8132911392405062,
          "no_speech_prob": 0.0008293993887491524
        },
        {
          "id": 16,
          "seek": 2880,
          "start": 37.4,
          "end": 39.28,
          "text": " they show or they explain different things,",
          "tokens": [
            50794,
            436,
            855,
            420,
            436,
            2903,
            819,
            721,
            11,
            50888
          ],
          "temperature": 0.0,
          "avg_logprob": -0.18266211756017825,
          "compression_ratio": 1.8132911392405062,
          "no_speech_prob": 0.0008293993887491524
        },
        {
          "id": 17,
          "seek": 2880,
          "start": 39.28,
          "end": 41.84,
          "text": " visuals explain different things than text.",
          "tokens": [
            50888,
            26035,
            2903,
            819,
            721,
            813,
            2487,
            13,
            51016
          ],
          "temperature": 0.0,
          "avg_logprob": -0.18266211756017825,
          "compression_ratio": 1.8132911392405062,
          "no_speech_prob": 0.0008293993887491524
        },
        {
          "id": 18,
          "seek": 2880,
          "start": 41.84,
          "end": 44.04,
          "text": " And if you think about the movie versus the book,",
          "tokens": [
            51016,
            400,
            498,
            291,
            519,
            466,
            264,
            3169,
            5717,
            264,
            1446,
            11,
            51126
          ],
          "temperature": 0.0,
          "avg_logprob": -0.18266211756017825,
          "compression_ratio": 1.8132911392405062,
          "no_speech_prob": 0.0008293993887491524
        },
        {
          "id": 19,
          "seek": 2880,
          "start": 44.04,
          "end": 45.8,
          "text": " that's like the best example.",
          "tokens": [
            51126,
            300,
            311,
            411,
            264,
            1151,
            1365,
            13,
            51214
          ],
          "temperature": 0.0,
          "avg_logprob": -0.18266211756017825,
          "compression_ratio": 1.8132911392405062,
          "no_speech_prob": 0.0008293993887491524
        },
        {
          "id": 20,
          "seek": 2880,
          "start": 45.8,
          "end": 48.2,
          "text": " There are some books written to be made into movies.",
          "tokens": [
            51214,
            821,
            366,
            512,
            3642,
            3720,
            281,
            312,
            1027,
            666,
            6233,
            13,
            51334
          ],
          "temperature": 0.0,
          "avg_logprob": -0.18266211756017825,
          "compression_ratio": 1.8132911392405062,
          "no_speech_prob": 0.0008293993887491524
        },
        {
          "id": 21,
          "seek": 2880,
          "start": 48.2,
          "end": 50.480000000000004,
          "text": " You think about the Harry Potter series, for example,",
          "tokens": [
            51334,
            509,
            519,
            466,
            264,
            9378,
            18115,
            2638,
            11,
            337,
            1365,
            11,
            51448
          ],
          "temperature": 0.0,
          "avg_logprob": -0.18266211756017825,
          "compression_ratio": 1.8132911392405062,
          "no_speech_prob": 0.0008293993887491524
        },
        {
          "id": 22,
          "seek": 2880,
          "start": 50.480000000000004,
          "end": 52.64,
          "text": " and they're very true to the original, I think,",
          "tokens": [
            51448,
            293,
            436,
            434,
            588,
            2074,
            281,
            264,
            3380,
            11,
            286,
            519,
            11,
            51556
          ],
          "temperature": 0.0,
          "avg_logprob": -0.18266211756017825,
          "compression_ratio": 1.8132911392405062,
          "no_speech_prob": 0.0008293993887491524
        },
        {
          "id": 23,
          "seek": 2880,
          "start": 52.64,
          "end": 55.6,
          "text": " but there's a lot that don't transfer so well.",
          "tokens": [
            51556,
            457,
            456,
            311,
            257,
            688,
            300,
            500,
            380,
            5003,
            370,
            731,
            13,
            51704
          ],
          "temperature": 0.0,
          "avg_logprob": -0.18266211756017825,
          "compression_ratio": 1.8132911392405062,
          "no_speech_prob": 0.0008293993887491524
        },
        {
          "id": 24,
          "seek": 2880,
          "start": 55.6,
          "end": 58.72,
          "text": " And a lot of it is about interiority and mood",
          "tokens": [
            51704,
            400,
            257,
            688,
            295,
            309,
            307,
            466,
            10636,
            507,
            293,
            9268,
            51860
          ],
          "temperature": 0.0,
          "avg_logprob": -0.18266211756017825,
          "compression_ratio": 1.8132911392405062,
          "no_speech_prob": 0.0008293993887491524
        },
        {
          "id": 25,
          "seek": 5872,
          "start": 59.64,
          "end": 61.64,
          "text": " that mood is expressed differently with words",
          "tokens": [
            50410,
            300,
            9268,
            307,
            12675,
            7614,
            365,
            2283,
            50510
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24118163508753623,
          "compression_ratio": 1.4226190476190477,
          "no_speech_prob": 0.0006981667829677463
        },
        {
          "id": 26,
          "seek": 5872,
          "start": 61.64,
          "end": 62.6,
          "text": " than with images.",
          "tokens": [
            50510,
            813,
            365,
            5267,
            13,
            50558
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24118163508753623,
          "compression_ratio": 1.4226190476190477,
          "no_speech_prob": 0.0006981667829677463
        },
        {
          "id": 27,
          "seek": 5872,
          "start": 62.6,
          "end": 63.92,
          "text": " And they complement each other, of course,",
          "tokens": [
            50558,
            400,
            436,
            17103,
            1184,
            661,
            11,
            295,
            1164,
            11,
            50624
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24118163508753623,
          "compression_ratio": 1.4226190476190477,
          "no_speech_prob": 0.0006981667829677463
        },
        {
          "id": 28,
          "seek": 5872,
          "start": 63.92,
          "end": 66.4,
          "text": " which is why the soundtrack is so important for the film.",
          "tokens": [
            50624,
            597,
            307,
            983,
            264,
            27029,
            307,
            370,
            1021,
            337,
            264,
            2007,
            13,
            50748
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24118163508753623,
          "compression_ratio": 1.4226190476190477,
          "no_speech_prob": 0.0006981667829677463
        },
        {
          "id": 29,
          "seek": 5872,
          "start": 66.4,
          "end": 67.4,
          "text": " When you become a grownup,",
          "tokens": [
            50748,
            1133,
            291,
            1813,
            257,
            7709,
            1010,
            11,
            50798
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24118163508753623,
          "compression_ratio": 1.4226190476190477,
          "no_speech_prob": 0.0006981667829677463
        },
        {
          "id": 30,
          "seek": 5872,
          "start": 67.4,
          "end": 69.76,
          "text": " you don't have pictures in your novels anymore.",
          "tokens": [
            50798,
            291,
            500,
            380,
            362,
            5242,
            294,
            428,
            24574,
            3602,
            13,
            50916
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24118163508753623,
          "compression_ratio": 1.4226190476190477,
          "no_speech_prob": 0.0006981667829677463
        }
      ],
      "language": "en"
    },
    {
      "text": " Except you pointed out in your keynote that really lovely classic book by Scott McCloud on how comic books work. You pointed out that there's a method to it. There's a kind of balance between the visual and the language. And sometimes one can do most of the work and sometimes the other. Couldn't a model learn to do that?",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 3.96,
          "text": " Except you pointed out in your keynote that really lovely classic book by Scott",
          "tokens": [
            50364,
            16192,
            291,
            10932,
            484,
            294,
            428,
            33896,
            300,
            534,
            7496,
            7230,
            1446,
            538,
            6659,
            50562
          ],
          "temperature": 0.0,
          "avg_logprob": -0.30054224991216894,
          "compression_ratio": 1.5707317073170732,
          "no_speech_prob": 0.020864618942141533
        },
        {
          "id": 1,
          "seek": 0,
          "start": 3.96,
          "end": 6.5200000000000005,
          "text": " McCloud on how comic books work.",
          "tokens": [
            50562,
            4050,
            32787,
            322,
            577,
            13900,
            3642,
            589,
            13,
            50690
          ],
          "temperature": 0.0,
          "avg_logprob": -0.30054224991216894,
          "compression_ratio": 1.5707317073170732,
          "no_speech_prob": 0.020864618942141533
        },
        {
          "id": 2,
          "seek": 0,
          "start": 6.8,
          "end": 9.08,
          "text": " You pointed out that there's a method to it.",
          "tokens": [
            50704,
            509,
            10932,
            484,
            300,
            456,
            311,
            257,
            3170,
            281,
            309,
            13,
            50818
          ],
          "temperature": 0.0,
          "avg_logprob": -0.30054224991216894,
          "compression_ratio": 1.5707317073170732,
          "no_speech_prob": 0.020864618942141533
        },
        {
          "id": 3,
          "seek": 0,
          "start": 9.56,
          "end": 12.96,
          "text": " There's a kind of balance between the visual and the language.",
          "tokens": [
            50842,
            821,
            311,
            257,
            733,
            295,
            4772,
            1296,
            264,
            5056,
            293,
            264,
            2856,
            13,
            51012
          ],
          "temperature": 0.0,
          "avg_logprob": -0.30054224991216894,
          "compression_ratio": 1.5707317073170732,
          "no_speech_prob": 0.020864618942141533
        },
        {
          "id": 4,
          "seek": 0,
          "start": 13.120000000000001,
          "end": 15.6,
          "text": " And sometimes one can do most of the work and sometimes the other.",
          "tokens": [
            51020,
            400,
            2171,
            472,
            393,
            360,
            881,
            295,
            264,
            589,
            293,
            2171,
            264,
            661,
            13,
            51144
          ],
          "temperature": 0.0,
          "avg_logprob": -0.30054224991216894,
          "compression_ratio": 1.5707317073170732,
          "no_speech_prob": 0.020864618942141533
        },
        {
          "id": 5,
          "seek": 0,
          "start": 15.76,
          "end": 17.04,
          "text": " Couldn't a model learn to do that?",
          "tokens": [
            51152,
            35800,
            380,
            257,
            2316,
            1466,
            281,
            360,
            300,
            30,
            51216
          ],
          "temperature": 0.0,
          "avg_logprob": -0.30054224991216894,
          "compression_ratio": 1.5707317073170732,
          "no_speech_prob": 0.020864618942141533
        }
      ],
      "language": "en"
    },
    {
      "text": " Oh, well, I could model learn to do that. I mean, I think you could give it instructions to learn to do that. I think, you know, right now what I'm interested in is how do people understand these things and then how best to express information so that you promote understanding and you don't promote misinformation or you try to combat misinformation. I think it's really important that we understand how, and this is the human computer interaction, the HCI side of the AI HCI coin as I think about them, understanding how people understand things so that we know what to tell the computers to do. Right now we have people designing visualizations and they don't necessarily know how to put the language on the design and neither will probably the computer or if the computer does know we at least need to know how to assess if it did a good job or not, which I think we need to do more work on.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 1.6400000000000001,
          "text": " Oh, well, I could model learn to do that.",
          "tokens": [
            50364,
            876,
            11,
            731,
            11,
            286,
            727,
            2316,
            1466,
            281,
            360,
            300,
            13,
            50446
          ],
          "temperature": 0.0,
          "avg_logprob": -0.26711025834083557,
          "compression_ratio": 1.9494584837545126,
          "no_speech_prob": 0.009258093312382698
        },
        {
          "id": 1,
          "seek": 0,
          "start": 1.6400000000000001,
          "end": 4.5,
          "text": " I mean, I think you could give it instructions to learn to do that.",
          "tokens": [
            50446,
            286,
            914,
            11,
            286,
            519,
            291,
            727,
            976,
            309,
            9415,
            281,
            1466,
            281,
            360,
            300,
            13,
            50589
          ],
          "temperature": 0.0,
          "avg_logprob": -0.26711025834083557,
          "compression_ratio": 1.9494584837545126,
          "no_speech_prob": 0.009258093312382698
        },
        {
          "id": 2,
          "seek": 0,
          "start": 4.5,
          "end": 8.48,
          "text": " I think, you know, right now what I'm interested in is how do people understand these things",
          "tokens": [
            50589,
            286,
            519,
            11,
            291,
            458,
            11,
            558,
            586,
            437,
            286,
            478,
            3102,
            294,
            307,
            577,
            360,
            561,
            1223,
            613,
            721,
            50788
          ],
          "temperature": 0.0,
          "avg_logprob": -0.26711025834083557,
          "compression_ratio": 1.9494584837545126,
          "no_speech_prob": 0.009258093312382698
        },
        {
          "id": 3,
          "seek": 0,
          "start": 8.48,
          "end": 14.72,
          "text": " and then how best to express information so that you promote understanding and you don't",
          "tokens": [
            50788,
            293,
            550,
            577,
            1151,
            281,
            5109,
            1589,
            370,
            300,
            291,
            9773,
            3701,
            293,
            291,
            500,
            380,
            51100
          ],
          "temperature": 0.0,
          "avg_logprob": -0.26711025834083557,
          "compression_ratio": 1.9494584837545126,
          "no_speech_prob": 0.009258093312382698
        },
        {
          "id": 4,
          "seek": 0,
          "start": 14.72,
          "end": 18.18,
          "text": " promote misinformation or you try to combat misinformation.",
          "tokens": [
            51100,
            9773,
            34238,
            420,
            291,
            853,
            281,
            8361,
            34238,
            13,
            51273
          ],
          "temperature": 0.0,
          "avg_logprob": -0.26711025834083557,
          "compression_ratio": 1.9494584837545126,
          "no_speech_prob": 0.009258093312382698
        },
        {
          "id": 5,
          "seek": 0,
          "start": 18.18,
          "end": 22.240000000000002,
          "text": " I think it's really important that we understand how, and this is the human computer interaction,",
          "tokens": [
            51273,
            286,
            519,
            309,
            311,
            534,
            1021,
            300,
            321,
            1223,
            577,
            11,
            293,
            341,
            307,
            264,
            1952,
            3820,
            9285,
            11,
            51476
          ],
          "temperature": 0.0,
          "avg_logprob": -0.26711025834083557,
          "compression_ratio": 1.9494584837545126,
          "no_speech_prob": 0.009258093312382698
        },
        {
          "id": 6,
          "seek": 0,
          "start": 22.240000000000002,
          "end": 28.080000000000002,
          "text": " the HCI side of the AI HCI coin as I think about them, understanding how people understand",
          "tokens": [
            51476,
            264,
            389,
            25240,
            1252,
            295,
            264,
            7318,
            389,
            25240,
            11464,
            382,
            286,
            519,
            466,
            552,
            11,
            3701,
            577,
            561,
            1223,
            51768
          ],
          "temperature": 0.0,
          "avg_logprob": -0.26711025834083557,
          "compression_ratio": 1.9494584837545126,
          "no_speech_prob": 0.009258093312382698
        },
        {
          "id": 7,
          "seek": 2808,
          "start": 28.08,
          "end": 31.36,
          "text": " things so that we know what to tell the computers to do.",
          "tokens": [
            50364,
            721,
            370,
            300,
            321,
            458,
            437,
            281,
            980,
            264,
            10807,
            281,
            360,
            13,
            50528
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24673564954735766,
          "compression_ratio": 1.6777251184834123,
          "no_speech_prob": 0.007230106741189957
        },
        {
          "id": 8,
          "seek": 2808,
          "start": 31.36,
          "end": 35.44,
          "text": " Right now we have people designing visualizations and they don't necessarily know how to put",
          "tokens": [
            50528,
            1779,
            586,
            321,
            362,
            561,
            14685,
            5056,
            14455,
            293,
            436,
            500,
            380,
            4725,
            458,
            577,
            281,
            829,
            50732
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24673564954735766,
          "compression_ratio": 1.6777251184834123,
          "no_speech_prob": 0.007230106741189957
        },
        {
          "id": 9,
          "seek": 2808,
          "start": 35.44,
          "end": 40.44,
          "text": " the language on the design and neither will probably the computer or if the computer does",
          "tokens": [
            50732,
            264,
            2856,
            322,
            264,
            1715,
            293,
            9662,
            486,
            1391,
            264,
            3820,
            420,
            498,
            264,
            3820,
            775,
            50982
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24673564954735766,
          "compression_ratio": 1.6777251184834123,
          "no_speech_prob": 0.007230106741189957
        },
        {
          "id": 10,
          "seek": 2808,
          "start": 40.44,
          "end": 44.16,
          "text": " know we at least need to know how to assess if it did a good job or not, which I think",
          "tokens": [
            50982,
            458,
            321,
            412,
            1935,
            643,
            281,
            458,
            577,
            281,
            5877,
            498,
            309,
            630,
            257,
            665,
            1691,
            420,
            406,
            11,
            597,
            286,
            519,
            51168
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24673564954735766,
          "compression_ratio": 1.6777251184834123,
          "no_speech_prob": 0.007230106741189957
        },
        {
          "id": 11,
          "seek": 2808,
          "start": 44.16,
          "end": 45.16,
          "text": " we need to do more work on.",
          "tokens": [
            51168,
            321,
            643,
            281,
            360,
            544,
            589,
            322,
            13,
            51218
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24673564954735766,
          "compression_ratio": 1.6777251184834123,
          "no_speech_prob": 0.007230106741189957
        }
      ],
      "language": "en"
    },
    {
      "text": " Yeah, but just to go out one step out onto the limb, I know you're very wary of speculation, but this one feels like a safe speculation. I think that there are going to be emergent capabilities with multimodal models that can deal both with the visual and the language side. And we don't know exactly what they'll be, but if we follow the trend with GPT-3 solely on the language side, I wonder what kind of capabilities even are there to acquire on the visual side. Something that comes to my mind is simplifying something visually. Sometimes as simple as underlining something can make something salient that helps explain the whole. You have a project called Scholar-PHY with Andrew Head at Berkeley. Is he a student of yours?",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 5.12,
          "text": " Yeah, but just to go out one step out onto the limb, I know you're very wary of speculation,",
          "tokens": [
            50364,
            865,
            11,
            457,
            445,
            281,
            352,
            484,
            472,
            1823,
            484,
            3911,
            264,
            30390,
            11,
            286,
            458,
            291,
            434,
            588,
            46585,
            295,
            27696,
            11,
            50620
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2013559834710483,
          "compression_ratio": 1.7222222222222223,
          "no_speech_prob": 0.35821014642715454
        },
        {
          "id": 1,
          "seek": 0,
          "start": 5.12,
          "end": 10.16,
          "text": " but this one feels like a safe speculation. I think that there are going to be emergent",
          "tokens": [
            50620,
            457,
            341,
            472,
            3417,
            411,
            257,
            3273,
            27696,
            13,
            286,
            519,
            300,
            456,
            366,
            516,
            281,
            312,
            4345,
            6930,
            50872
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2013559834710483,
          "compression_ratio": 1.7222222222222223,
          "no_speech_prob": 0.35821014642715454
        },
        {
          "id": 2,
          "seek": 0,
          "start": 10.16,
          "end": 16.080000000000002,
          "text": " capabilities with multimodal models that can deal both with the visual and the language side.",
          "tokens": [
            50872,
            10862,
            365,
            32972,
            378,
            304,
            5245,
            300,
            393,
            2028,
            1293,
            365,
            264,
            5056,
            293,
            264,
            2856,
            1252,
            13,
            51168
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2013559834710483,
          "compression_ratio": 1.7222222222222223,
          "no_speech_prob": 0.35821014642715454
        },
        {
          "id": 3,
          "seek": 0,
          "start": 16.080000000000002,
          "end": 21.52,
          "text": " And we don't know exactly what they'll be, but if we follow the trend with GPT-3 solely on the",
          "tokens": [
            51168,
            400,
            321,
            500,
            380,
            458,
            2293,
            437,
            436,
            603,
            312,
            11,
            457,
            498,
            321,
            1524,
            264,
            6028,
            365,
            26039,
            51,
            12,
            18,
            23309,
            322,
            264,
            51440
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2013559834710483,
          "compression_ratio": 1.7222222222222223,
          "no_speech_prob": 0.35821014642715454
        },
        {
          "id": 4,
          "seek": 0,
          "start": 21.52,
          "end": 27.76,
          "text": " language side, I wonder what kind of capabilities even are there to acquire on the visual side.",
          "tokens": [
            51440,
            2856,
            1252,
            11,
            286,
            2441,
            437,
            733,
            295,
            10862,
            754,
            366,
            456,
            281,
            20001,
            322,
            264,
            5056,
            1252,
            13,
            51752
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2013559834710483,
          "compression_ratio": 1.7222222222222223,
          "no_speech_prob": 0.35821014642715454
        },
        {
          "id": 5,
          "seek": 2776,
          "start": 27.76,
          "end": 33.120000000000005,
          "text": " Something that comes to my mind is simplifying something visually. Sometimes as simple as",
          "tokens": [
            50364,
            6595,
            300,
            1487,
            281,
            452,
            1575,
            307,
            6883,
            5489,
            746,
            19622,
            13,
            4803,
            382,
            2199,
            382,
            50632
          ],
          "temperature": 0.0,
          "avg_logprob": -0.27142969767252606,
          "compression_ratio": 1.4719101123595506,
          "no_speech_prob": 0.002590164775028825
        },
        {
          "id": 6,
          "seek": 2776,
          "start": 33.120000000000005,
          "end": 38.32,
          "text": " underlining something can make something salient that helps explain the whole.",
          "tokens": [
            50632,
            833,
            31079,
            746,
            393,
            652,
            746,
            1845,
            1196,
            300,
            3665,
            2903,
            264,
            1379,
            13,
            50892
          ],
          "temperature": 0.0,
          "avg_logprob": -0.27142969767252606,
          "compression_ratio": 1.4719101123595506,
          "no_speech_prob": 0.002590164775028825
        },
        {
          "id": 7,
          "seek": 2776,
          "start": 38.32,
          "end": 43.44,
          "text": " You have a project called Scholar-PHY with Andrew Head at Berkeley. Is he a student of yours?",
          "tokens": [
            50892,
            509,
            362,
            257,
            1716,
            1219,
            2065,
            15276,
            12,
            21904,
            56,
            365,
            10110,
            11398,
            412,
            23684,
            13,
            1119,
            415,
            257,
            3107,
            295,
            6342,
            30,
            51148
          ],
          "temperature": 0.0,
          "avg_logprob": -0.27142969767252606,
          "compression_ratio": 1.4719101123595506,
          "no_speech_prob": 0.002590164775028825
        }
      ],
      "language": "en"
    },
    {
      "text": " He was a student and a postdoc and now he's a professor at UPenn. And it was also in collaboration with people at AI, too, you know, hence the Oren reference, too.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 3.12,
          "text": " He was a student and a postdoc and now he's a professor at UPenn.",
          "tokens": [
            50364,
            634,
            390,
            257,
            3107,
            293,
            257,
            2183,
            39966,
            293,
            586,
            415,
            311,
            257,
            8304,
            412,
            20074,
            1857,
            13,
            50520
          ],
          "temperature": 0.0,
          "avg_logprob": -0.4204062603889628,
          "compression_ratio": 1.2936507936507937,
          "no_speech_prob": 0.0005250902031548321
        },
        {
          "id": 1,
          "seek": 0,
          "start": 3.12,
          "end": 8.32,
          "text": " And it was also in collaboration with people at AI, too, you know, hence the Oren reference, too.",
          "tokens": [
            50520,
            400,
            309,
            390,
            611,
            294,
            9363,
            365,
            561,
            412,
            7318,
            11,
            886,
            11,
            291,
            458,
            11,
            16678,
            264,
            422,
            1095,
            6408,
            11,
            886,
            13,
            50780
          ],
          "temperature": 0.0,
          "avg_logprob": -0.4204062603889628,
          "compression_ratio": 1.2936507936507937,
          "no_speech_prob": 0.0005250902031548321
        }
      ],
      "language": "en"
    },
    {
      "text": " Oh, wow. Yeah.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 1.0,
          "text": " Oh, wow.",
          "tokens": [
            50364,
            876,
            11,
            6076,
            13,
            50414
          ],
          "temperature": 0.0,
          "avg_logprob": -0.6155293146769206,
          "compression_ratio": 0.9090909090909091,
          "no_speech_prob": 0.024283427745103836
        },
        {
          "id": 1,
          "seek": 0,
          "start": 1.0,
          "end": 2.0,
          "text": " Yeah.",
          "tokens": [
            50414,
            865,
            13,
            50464
          ],
          "temperature": 0.0,
          "avg_logprob": -0.6155293146769206,
          "compression_ratio": 0.9090909090909091,
          "no_speech_prob": 0.024283427745103836
        },
        {
          "id": 2,
          "seek": 0,
          "start": 2.0,
          "end": 2.0,
          "text": "",
          "tokens": [],
          "temperature": 0.0,
          "avg_logprob": -0.6155293146769206,
          "compression_ratio": 0.9090909090909091,
          "no_speech_prob": 0.024283427745103836,
          "words": []
        }
      ],
      "language": "en"
    },
    {
      "text": " Yeah, I saw a breakdown of the project. It's so neat. And one of the really neat insights is when you read something that's got a lot of complicated mathematics in it, your brain is doing a ton of work behind the scenes. And if you had a better interface, for example, click on a variable in a formula, and just have it automatically pop out and say, this is what that represents. So you offload some of that cognitive work you have to do. I wonder if those kind of skills could be learned.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 26.080000000000002,
          "text": " Yeah, I saw a breakdown of the project. It's so neat. And one of the really neat insights is when you read something that's got a lot of complicated mathematics in it, your brain is doing a ton of work behind the scenes. And if you had a better interface, for example, click on a variable in a formula, and just have it automatically pop out and say, this is what that represents. So you offload some of that cognitive work you have to do. I wonder if those kind of skills could be learned.",
          "tokens": [
            50364,
            865,
            11,
            286,
            1866,
            257,
            18188,
            295,
            264,
            1716,
            13,
            467,
            311,
            370,
            10654,
            13,
            400,
            472,
            295,
            264,
            534,
            10654,
            14310,
            307,
            562,
            291,
            1401,
            746,
            300,
            311,
            658,
            257,
            688,
            295,
            6179,
            18666,
            294,
            309,
            11,
            428,
            3567,
            307,
            884,
            257,
            2952,
            295,
            589,
            2261,
            264,
            8026,
            13,
            400,
            498,
            291,
            632,
            257,
            1101,
            9226,
            11,
            337,
            1365,
            11,
            2052,
            322,
            257,
            7006,
            294,
            257,
            8513,
            11,
            293,
            445,
            362,
            309,
            6772,
            1665,
            484,
            293,
            584,
            11,
            341,
            307,
            437,
            300,
            8855,
            13,
            407,
            291,
            766,
            2907,
            512,
            295,
            300,
            15605,
            589,
            291,
            362,
            281,
            360,
            13,
            286,
            2441,
            498,
            729,
            733,
            295,
            3942,
            727,
            312,
            3264,
            13,
            51668
          ],
          "temperature": 0.0,
          "avg_logprob": -0.20076147433930794,
          "compression_ratio": 1.6666666666666667,
          "no_speech_prob": 9.603745274944231e-05
        }
      ],
      "language": "en"
    },
    {
      "text": " I hope so. And you mean the skills of visually showing the information? Yeah.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 3.68,
          "text": " I hope so. And you mean the skills of visually showing the information?",
          "tokens": [
            50364,
            286,
            1454,
            370,
            13,
            400,
            291,
            914,
            264,
            3942,
            295,
            19622,
            4099,
            264,
            1589,
            30,
            50548
          ],
          "temperature": 0.0,
          "avg_logprob": -0.46317286924882367,
          "compression_ratio": 0.9871794871794872,
          "no_speech_prob": 0.00020942614355590194
        },
        {
          "id": 1,
          "seek": 0,
          "start": 3.68,
          "end": 4.18,
          "text": " Yeah.",
          "tokens": [
            50548,
            865,
            13,
            50573
          ],
          "temperature": 0.0,
          "avg_logprob": -0.46317286924882367,
          "compression_ratio": 0.9871794871794872,
          "no_speech_prob": 0.00020942614355590194
        }
      ],
      "language": "en"
    },
    {
      "text": " Yeah, all those tricks that a good visual explainer just knows how to do.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 4.48,
          "text": " Yeah, all those tricks that a good visual explainer just knows how to do.",
          "tokens": [
            50364,
            865,
            11,
            439,
            729,
            11733,
            300,
            257,
            665,
            5056,
            2903,
            260,
            445,
            3255,
            577,
            281,
            360,
            13,
            50588
          ],
          "temperature": 0.0,
          "avg_logprob": -0.28529973030090333,
          "compression_ratio": 1.0138888888888888,
          "no_speech_prob": 0.0002816125052049756
        }
      ],
      "language": "en"
    },
    {
      "text": " Well, I am optimistic that these new models will make that automation task that we had more effective. We worked on algorithms to do it automatically, but PDFs are really tricky to process if you're looking at the image level. And it's very hard to find definitions within a scientific paper because not everything is defined in a crisp way. And so really what you want to do is generate your own text, but you want it to be accurate. It's based on the text of the paper. So we are actually looking to see if the latest models can help with the automation of that task. But going back to a point you made earlier about creativity or new synthesis with these models, I think someone who was hosted earlier on this podcast pointed out just even the avocado sofa is a synergy of image. A human had to ask the query, but then the system was able to blend these images together into something new, although it doesn't blend well if they don't go well together.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 5.28,
          "text": " Well, I am optimistic that these new models will make that automation task that we had",
          "tokens": [
            50364,
            1042,
            11,
            286,
            669,
            19397,
            300,
            613,
            777,
            5245,
            486,
            652,
            300,
            17769,
            5633,
            300,
            321,
            632,
            50628
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21653844308162082,
          "compression_ratio": 1.7484472049689441,
          "no_speech_prob": 0.005726130213588476
        },
        {
          "id": 1,
          "seek": 0,
          "start": 5.28,
          "end": 6.28,
          "text": " more effective.",
          "tokens": [
            50628,
            544,
            4942,
            13,
            50678
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21653844308162082,
          "compression_ratio": 1.7484472049689441,
          "no_speech_prob": 0.005726130213588476
        },
        {
          "id": 2,
          "seek": 0,
          "start": 6.28,
          "end": 11.9,
          "text": " We worked on algorithms to do it automatically, but PDFs are really tricky to process if you're",
          "tokens": [
            50678,
            492,
            2732,
            322,
            14642,
            281,
            360,
            309,
            6772,
            11,
            457,
            17752,
            82,
            366,
            534,
            12414,
            281,
            1399,
            498,
            291,
            434,
            50959
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21653844308162082,
          "compression_ratio": 1.7484472049689441,
          "no_speech_prob": 0.005726130213588476
        },
        {
          "id": 3,
          "seek": 0,
          "start": 11.9,
          "end": 13.4,
          "text": " looking at the image level.",
          "tokens": [
            50959,
            1237,
            412,
            264,
            3256,
            1496,
            13,
            51034
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21653844308162082,
          "compression_ratio": 1.7484472049689441,
          "no_speech_prob": 0.005726130213588476
        },
        {
          "id": 4,
          "seek": 0,
          "start": 13.4,
          "end": 17.68,
          "text": " And it's very hard to find definitions within a scientific paper because not everything",
          "tokens": [
            51034,
            400,
            309,
            311,
            588,
            1152,
            281,
            915,
            21988,
            1951,
            257,
            8134,
            3035,
            570,
            406,
            1203,
            51248
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21653844308162082,
          "compression_ratio": 1.7484472049689441,
          "no_speech_prob": 0.005726130213588476
        },
        {
          "id": 5,
          "seek": 0,
          "start": 17.68,
          "end": 19.240000000000002,
          "text": " is defined in a crisp way.",
          "tokens": [
            51248,
            307,
            7642,
            294,
            257,
            22952,
            636,
            13,
            51326
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21653844308162082,
          "compression_ratio": 1.7484472049689441,
          "no_speech_prob": 0.005726130213588476
        },
        {
          "id": 6,
          "seek": 0,
          "start": 19.240000000000002,
          "end": 23.92,
          "text": " And so really what you want to do is generate your own text, but you want it to be accurate.",
          "tokens": [
            51326,
            400,
            370,
            534,
            437,
            291,
            528,
            281,
            360,
            307,
            8460,
            428,
            1065,
            2487,
            11,
            457,
            291,
            528,
            309,
            281,
            312,
            8559,
            13,
            51560
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21653844308162082,
          "compression_ratio": 1.7484472049689441,
          "no_speech_prob": 0.005726130213588476
        },
        {
          "id": 7,
          "seek": 0,
          "start": 23.92,
          "end": 25.7,
          "text": " It's based on the text of the paper.",
          "tokens": [
            51560,
            467,
            311,
            2361,
            322,
            264,
            2487,
            295,
            264,
            3035,
            13,
            51649
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21653844308162082,
          "compression_ratio": 1.7484472049689441,
          "no_speech_prob": 0.005726130213588476
        },
        {
          "id": 8,
          "seek": 0,
          "start": 25.7,
          "end": 29.7,
          "text": " So we are actually looking to see if the latest models can help with the automation of that",
          "tokens": [
            51649,
            407,
            321,
            366,
            767,
            1237,
            281,
            536,
            498,
            264,
            6792,
            5245,
            393,
            854,
            365,
            264,
            17769,
            295,
            300,
            51849
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21653844308162082,
          "compression_ratio": 1.7484472049689441,
          "no_speech_prob": 0.005726130213588476
        },
        {
          "id": 9,
          "seek": 2970,
          "start": 29.7,
          "end": 30.7,
          "text": " task.",
          "tokens": [
            50364,
            5633,
            13,
            50414
          ],
          "temperature": 0.0,
          "avg_logprob": -0.26125397220734625,
          "compression_ratio": 1.6567796610169492,
          "no_speech_prob": 0.00013550359290093184
        },
        {
          "id": 10,
          "seek": 2970,
          "start": 30.7,
          "end": 35.18,
          "text": " But going back to a point you made earlier about creativity or new synthesis with these",
          "tokens": [
            50414,
            583,
            516,
            646,
            281,
            257,
            935,
            291,
            1027,
            3071,
            466,
            12915,
            420,
            777,
            30252,
            365,
            613,
            50638
          ],
          "temperature": 0.0,
          "avg_logprob": -0.26125397220734625,
          "compression_ratio": 1.6567796610169492,
          "no_speech_prob": 0.00013550359290093184
        },
        {
          "id": 11,
          "seek": 2970,
          "start": 35.18,
          "end": 39.62,
          "text": " models, I think someone who was hosted earlier on this podcast pointed out just even the",
          "tokens": [
            50638,
            5245,
            11,
            286,
            519,
            1580,
            567,
            390,
            19204,
            3071,
            322,
            341,
            7367,
            10932,
            484,
            445,
            754,
            264,
            50860
          ],
          "temperature": 0.0,
          "avg_logprob": -0.26125397220734625,
          "compression_ratio": 1.6567796610169492,
          "no_speech_prob": 0.00013550359290093184
        },
        {
          "id": 12,
          "seek": 2970,
          "start": 39.62,
          "end": 43.3,
          "text": " avocado sofa is a synergy of image.",
          "tokens": [
            50860,
            27041,
            28668,
            307,
            257,
            50163,
            295,
            3256,
            13,
            51044
          ],
          "temperature": 0.0,
          "avg_logprob": -0.26125397220734625,
          "compression_ratio": 1.6567796610169492,
          "no_speech_prob": 0.00013550359290093184
        },
        {
          "id": 13,
          "seek": 2970,
          "start": 43.3,
          "end": 48.82,
          "text": " A human had to ask the query, but then the system was able to blend these images together",
          "tokens": [
            51044,
            316,
            1952,
            632,
            281,
            1029,
            264,
            14581,
            11,
            457,
            550,
            264,
            1185,
            390,
            1075,
            281,
            10628,
            613,
            5267,
            1214,
            51320
          ],
          "temperature": 0.0,
          "avg_logprob": -0.26125397220734625,
          "compression_ratio": 1.6567796610169492,
          "no_speech_prob": 0.00013550359290093184
        },
        {
          "id": 14,
          "seek": 2970,
          "start": 48.82,
          "end": 52.94,
          "text": " into something new, although it doesn't blend well if they don't go well together.",
          "tokens": [
            51320,
            666,
            746,
            777,
            11,
            4878,
            309,
            1177,
            380,
            10628,
            731,
            498,
            436,
            500,
            380,
            352,
            731,
            1214,
            13,
            51526
          ],
          "temperature": 0.0,
          "avg_logprob": -0.26125397220734625,
          "compression_ratio": 1.6567796610169492,
          "no_speech_prob": 0.00013550359290093184
        }
      ],
      "language": "en"
    },
    {
      "text": " In case anyone listening doesn't know what the avocado chair is, this was the sort of amazing DALI moment. So the DALI model came with a paper and in that paper, they had some images as examples of what it could do. And one of them was make a chair made of an avocado, something like that. And it was sort of amazingly convincingly good. It really was.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 6.2,
          "text": " In case anyone listening doesn't know what the avocado chair is, this was the sort of amazing DALI moment.",
          "tokens": [
            50364,
            682,
            1389,
            2878,
            4764,
            1177,
            380,
            458,
            437,
            264,
            27041,
            6090,
            307,
            11,
            341,
            390,
            264,
            1333,
            295,
            2243,
            413,
            11566,
            1623,
            13,
            50674
          ],
          "temperature": 0.0,
          "avg_logprob": -0.325049075451526,
          "compression_ratio": 1.614678899082569,
          "no_speech_prob": 0.0015960743185132742
        },
        {
          "id": 1,
          "seek": 0,
          "start": 6.2,
          "end": 12.0,
          "text": " So the DALI model came with a paper and in that paper, they had some images as examples of what it could do.",
          "tokens": [
            50674,
            407,
            264,
            413,
            11566,
            2316,
            1361,
            365,
            257,
            3035,
            293,
            294,
            300,
            3035,
            11,
            436,
            632,
            512,
            5267,
            382,
            5110,
            295,
            437,
            309,
            727,
            360,
            13,
            50964
          ],
          "temperature": 0.0,
          "avg_logprob": -0.325049075451526,
          "compression_ratio": 1.614678899082569,
          "no_speech_prob": 0.0015960743185132742
        },
        {
          "id": 2,
          "seek": 0,
          "start": 12.36,
          "end": 15.84,
          "text": " And one of them was make a chair made of an avocado, something like that.",
          "tokens": [
            50982,
            400,
            472,
            295,
            552,
            390,
            652,
            257,
            6090,
            1027,
            295,
            364,
            27041,
            11,
            746,
            411,
            300,
            13,
            51156
          ],
          "temperature": 0.0,
          "avg_logprob": -0.325049075451526,
          "compression_ratio": 1.614678899082569,
          "no_speech_prob": 0.0015960743185132742
        },
        {
          "id": 3,
          "seek": 0,
          "start": 16.36,
          "end": 19.2,
          "text": " And it was sort of amazingly convincingly good.",
          "tokens": [
            51182,
            400,
            309,
            390,
            1333,
            295,
            31762,
            24823,
            356,
            665,
            13,
            51324
          ],
          "temperature": 0.0,
          "avg_logprob": -0.325049075451526,
          "compression_ratio": 1.614678899082569,
          "no_speech_prob": 0.0015960743185132742
        },
        {
          "id": 4,
          "seek": 0,
          "start": 19.36,
          "end": 20.16,
          "text": " It really was.",
          "tokens": [
            51332,
            467,
            534,
            390,
            13,
            51372
          ],
          "temperature": 0.0,
          "avg_logprob": -0.325049075451526,
          "compression_ratio": 1.614678899082569,
          "no_speech_prob": 0.0015960743185132742
        }
      ],
      "language": "en"
    },
    {
      "text": " Although they are a little cherry picked because if you try to combine two things that don't often go well together or don't appear together, it doesn't work, or at least it didn't work when I was playing.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 4.32,
          "text": " Although they are a little cherry picked because if you try to combine two things that don't",
          "tokens": [
            50364,
            5780,
            436,
            366,
            257,
            707,
            20164,
            6183,
            570,
            498,
            291,
            853,
            281,
            10432,
            732,
            721,
            300,
            500,
            380,
            50580
          ],
          "temperature": 0.0,
          "avg_logprob": -0.289571450306819,
          "compression_ratio": 1.4335664335664335,
          "no_speech_prob": 0.03288073465228081
        },
        {
          "id": 1,
          "seek": 0,
          "start": 4.32,
          "end": 8.2,
          "text": " often go well together or don't appear together, it doesn't work, or at least it didn't work",
          "tokens": [
            50580,
            2049,
            352,
            731,
            1214,
            420,
            500,
            380,
            4204,
            1214,
            11,
            309,
            1177,
            380,
            589,
            11,
            420,
            412,
            1935,
            309,
            994,
            380,
            589,
            50774
          ],
          "temperature": 0.0,
          "avg_logprob": -0.289571450306819,
          "compression_ratio": 1.4335664335664335,
          "no_speech_prob": 0.03288073465228081
        },
        {
          "id": 2,
          "seek": 0,
          "start": 8.2,
          "end": 8.92,
          "text": " when I was playing.",
          "tokens": [
            50774,
            562,
            286,
            390,
            2433,
            13,
            50810
          ],
          "temperature": 0.0,
          "avg_logprob": -0.289571450306819,
          "compression_ratio": 1.4335664335664335,
          "no_speech_prob": 0.03288073465228081
        }
      ],
      "language": "en"
    },
    {
      "text": " It'll flood that.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 0.84,
          "text": " It'll flood that.",
          "tokens": [
            50364,
            467,
            603,
            10481,
            300,
            13,
            50406
          ],
          "temperature": 0.0,
          "avg_logprob": -0.4831730127334595,
          "compression_ratio": 0.68,
          "no_speech_prob": 0.022575750946998596
        }
      ],
      "language": "en"
    },
    {
      "text": " Yeah, but still, it's a great example, you know, of synergy with these tools. And what I noted in the keynote was that Copilot, these systems that aid in programming, rather than, you know, there's been a long debate in HCI about when you're developing, say, a user interface or doing data analysis, should it be a command line or should it be a graphical user interface, a GUI? And of course the answer is neither works perfectly and people who are practitioners use a blend of both. But it seems now, as I said about Ask Jeeves, what people really want to do is just use language to say, do this, do that, and have the program get written. And then point and use gestures and the interface to tweak it a bit. This multi-modality. And again, there are tools to do that, but they're just not perfect. And the more that the algorithms improve, like with Chat GPT, the more effectively we'll be able to help people design visualizations where they don't have to do a lot of coding. It's again, because it works, this general purpose tool that we were talking about as a side effect of being, you know, produce the next word, it's able to do all these other things that I think we don't understand why, but that includes writing code or, you know, being smart about adding things into code and so on. It wasn't designed for that, but it seems like it will be very effective at making it easier to design visualizations. The problem is, will it design good visualizations? And, you know, that's where we still have the human component.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 4.0,
          "text": " Yeah, but still, it's a great example, you know, of synergy with these tools.",
          "tokens": [
            50364,
            865,
            11,
            457,
            920,
            11,
            309,
            311,
            257,
            869,
            1365,
            11,
            291,
            458,
            11,
            295,
            50163,
            365,
            613,
            3873,
            13,
            50564
          ],
          "temperature": 0.0,
          "avg_logprob": -0.28378753662109374,
          "compression_ratio": 1.6632302405498283,
          "no_speech_prob": 0.1538633406162262
        },
        {
          "id": 1,
          "seek": 0,
          "start": 4.08,
          "end": 8.84,
          "text": " And what I noted in the keynote was that Copilot, these systems that aid in",
          "tokens": [
            50568,
            400,
            437,
            286,
            12964,
            294,
            264,
            33896,
            390,
            300,
            11579,
            31516,
            11,
            613,
            3652,
            300,
            9418,
            294,
            50806
          ],
          "temperature": 0.0,
          "avg_logprob": -0.28378753662109374,
          "compression_ratio": 1.6632302405498283,
          "no_speech_prob": 0.1538633406162262
        },
        {
          "id": 2,
          "seek": 0,
          "start": 8.84,
          "end": 13.18,
          "text": " programming, rather than, you know, there's been a long debate in HCI about",
          "tokens": [
            50806,
            9410,
            11,
            2831,
            813,
            11,
            291,
            458,
            11,
            456,
            311,
            668,
            257,
            938,
            7958,
            294,
            389,
            25240,
            466,
            51023
          ],
          "temperature": 0.0,
          "avg_logprob": -0.28378753662109374,
          "compression_ratio": 1.6632302405498283,
          "no_speech_prob": 0.1538633406162262
        },
        {
          "id": 3,
          "seek": 0,
          "start": 13.44,
          "end": 17.26,
          "text": " when you're developing, say, a user interface or doing data analysis, should",
          "tokens": [
            51036,
            562,
            291,
            434,
            6416,
            11,
            584,
            11,
            257,
            4195,
            9226,
            420,
            884,
            1412,
            5215,
            11,
            820,
            51227
          ],
          "temperature": 0.0,
          "avg_logprob": -0.28378753662109374,
          "compression_ratio": 1.6632302405498283,
          "no_speech_prob": 0.1538633406162262
        },
        {
          "id": 4,
          "seek": 0,
          "start": 17.26,
          "end": 20.6,
          "text": " it be a command line or should it be a graphical user interface, a GUI?",
          "tokens": [
            51227,
            309,
            312,
            257,
            5622,
            1622,
            420,
            820,
            309,
            312,
            257,
            35942,
            4195,
            9226,
            11,
            257,
            17917,
            40,
            30,
            51394
          ],
          "temperature": 0.0,
          "avg_logprob": -0.28378753662109374,
          "compression_ratio": 1.6632302405498283,
          "no_speech_prob": 0.1538633406162262
        },
        {
          "id": 5,
          "seek": 0,
          "start": 20.94,
          "end": 24.6,
          "text": " And of course the answer is neither works perfectly and people who are",
          "tokens": [
            51411,
            400,
            295,
            1164,
            264,
            1867,
            307,
            9662,
            1985,
            6239,
            293,
            561,
            567,
            366,
            51594
          ],
          "temperature": 0.0,
          "avg_logprob": -0.28378753662109374,
          "compression_ratio": 1.6632302405498283,
          "no_speech_prob": 0.1538633406162262
        },
        {
          "id": 6,
          "seek": 0,
          "start": 24.6,
          "end": 26.36,
          "text": " practitioners use a blend of both.",
          "tokens": [
            51594,
            25742,
            764,
            257,
            10628,
            295,
            1293,
            13,
            51682
          ],
          "temperature": 0.0,
          "avg_logprob": -0.28378753662109374,
          "compression_ratio": 1.6632302405498283,
          "no_speech_prob": 0.1538633406162262
        },
        {
          "id": 7,
          "seek": 2636,
          "start": 26.52,
          "end": 30.84,
          "text": " But it seems now, as I said about Ask Jeeves, what people really want to do is",
          "tokens": [
            50372,
            583,
            309,
            2544,
            586,
            11,
            382,
            286,
            848,
            466,
            12320,
            508,
            1653,
            977,
            11,
            437,
            561,
            534,
            528,
            281,
            360,
            307,
            50588
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2862339770700049,
          "compression_ratio": 1.6458333333333333,
          "no_speech_prob": 0.05031372234225273
        },
        {
          "id": 8,
          "seek": 2636,
          "start": 30.84,
          "end": 34.34,
          "text": " just use language to say, do this, do that, and have the program get written.",
          "tokens": [
            50588,
            445,
            764,
            2856,
            281,
            584,
            11,
            360,
            341,
            11,
            360,
            300,
            11,
            293,
            362,
            264,
            1461,
            483,
            3720,
            13,
            50763
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2862339770700049,
          "compression_ratio": 1.6458333333333333,
          "no_speech_prob": 0.05031372234225273
        },
        {
          "id": 9,
          "seek": 2636,
          "start": 34.480000000000004,
          "end": 38.54,
          "text": " And then point and use gestures and the interface to tweak it a bit.",
          "tokens": [
            50770,
            400,
            550,
            935,
            293,
            764,
            28475,
            293,
            264,
            9226,
            281,
            29879,
            309,
            257,
            857,
            13,
            50973
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2862339770700049,
          "compression_ratio": 1.6458333333333333,
          "no_speech_prob": 0.05031372234225273
        },
        {
          "id": 10,
          "seek": 2636,
          "start": 38.72,
          "end": 40.04,
          "text": " This multi-modality.",
          "tokens": [
            50982,
            639,
            4825,
            12,
            8014,
            1860,
            13,
            51048
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2862339770700049,
          "compression_ratio": 1.6458333333333333,
          "no_speech_prob": 0.05031372234225273
        },
        {
          "id": 11,
          "seek": 2636,
          "start": 40.42,
          "end": 45.379999999999995,
          "text": " And again, there are tools to do that, but they're just not perfect.",
          "tokens": [
            51067,
            400,
            797,
            11,
            456,
            366,
            3873,
            281,
            360,
            300,
            11,
            457,
            436,
            434,
            445,
            406,
            2176,
            13,
            51315
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2862339770700049,
          "compression_ratio": 1.6458333333333333,
          "no_speech_prob": 0.05031372234225273
        },
        {
          "id": 12,
          "seek": 2636,
          "start": 45.620000000000005,
          "end": 51.379999999999995,
          "text": " And the more that the algorithms improve, like with Chat GPT, the more effectively",
          "tokens": [
            51327,
            400,
            264,
            544,
            300,
            264,
            14642,
            3470,
            11,
            411,
            365,
            27503,
            26039,
            51,
            11,
            264,
            544,
            8659,
            51615
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2862339770700049,
          "compression_ratio": 1.6458333333333333,
          "no_speech_prob": 0.05031372234225273
        },
        {
          "id": 13,
          "seek": 2636,
          "start": 51.379999999999995,
          "end": 55.58,
          "text": " we'll be able to help people design visualizations where they don't have to",
          "tokens": [
            51615,
            321,
            603,
            312,
            1075,
            281,
            854,
            561,
            1715,
            5056,
            14455,
            689,
            436,
            500,
            380,
            362,
            281,
            51825
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2862339770700049,
          "compression_ratio": 1.6458333333333333,
          "no_speech_prob": 0.05031372234225273
        },
        {
          "id": 14,
          "seek": 5558,
          "start": 55.58,
          "end": 56.739999999999995,
          "text": " do a lot of coding.",
          "tokens": [
            50364,
            360,
            257,
            688,
            295,
            17720,
            13,
            50422
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25971786848461353,
          "compression_ratio": 1.727891156462585,
          "no_speech_prob": 0.001674340688623488
        },
        {
          "id": 15,
          "seek": 5558,
          "start": 56.98,
          "end": 61.06,
          "text": " It's again, because it works, this general purpose tool that we were talking",
          "tokens": [
            50434,
            467,
            311,
            797,
            11,
            570,
            309,
            1985,
            11,
            341,
            2674,
            4334,
            2290,
            300,
            321,
            645,
            1417,
            50638
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25971786848461353,
          "compression_ratio": 1.727891156462585,
          "no_speech_prob": 0.001674340688623488
        },
        {
          "id": 16,
          "seek": 5558,
          "start": 61.06,
          "end": 65.98,
          "text": " about as a side effect of being, you know, produce the next word, it's able to do",
          "tokens": [
            50638,
            466,
            382,
            257,
            1252,
            1802,
            295,
            885,
            11,
            291,
            458,
            11,
            5258,
            264,
            958,
            1349,
            11,
            309,
            311,
            1075,
            281,
            360,
            50884
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25971786848461353,
          "compression_ratio": 1.727891156462585,
          "no_speech_prob": 0.001674340688623488
        },
        {
          "id": 17,
          "seek": 5558,
          "start": 65.98,
          "end": 69.34,
          "text": " all these other things that I think we don't understand why, but that includes",
          "tokens": [
            50884,
            439,
            613,
            661,
            721,
            300,
            286,
            519,
            321,
            500,
            380,
            1223,
            983,
            11,
            457,
            300,
            5974,
            51052
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25971786848461353,
          "compression_ratio": 1.727891156462585,
          "no_speech_prob": 0.001674340688623488
        },
        {
          "id": 18,
          "seek": 5558,
          "start": 69.42,
          "end": 74.24,
          "text": " writing code or, you know, being smart about adding things into code and so on.",
          "tokens": [
            51056,
            3579,
            3089,
            420,
            11,
            291,
            458,
            11,
            885,
            4069,
            466,
            5127,
            721,
            666,
            3089,
            293,
            370,
            322,
            13,
            51297
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25971786848461353,
          "compression_ratio": 1.727891156462585,
          "no_speech_prob": 0.001674340688623488
        },
        {
          "id": 19,
          "seek": 5558,
          "start": 74.42,
          "end": 79.48,
          "text": " It wasn't designed for that, but it seems like it will be very effective at making",
          "tokens": [
            51306,
            467,
            2067,
            380,
            4761,
            337,
            300,
            11,
            457,
            309,
            2544,
            411,
            309,
            486,
            312,
            588,
            4942,
            412,
            1455,
            51559
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25971786848461353,
          "compression_ratio": 1.727891156462585,
          "no_speech_prob": 0.001674340688623488
        },
        {
          "id": 20,
          "seek": 5558,
          "start": 79.48,
          "end": 81.34,
          "text": " it easier to design visualizations.",
          "tokens": [
            51559,
            309,
            3571,
            281,
            1715,
            5056,
            14455,
            13,
            51652
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25971786848461353,
          "compression_ratio": 1.727891156462585,
          "no_speech_prob": 0.001674340688623488
        },
        {
          "id": 21,
          "seek": 5558,
          "start": 81.58,
          "end": 83.72,
          "text": " The problem is, will it design good visualizations?",
          "tokens": [
            51664,
            440,
            1154,
            307,
            11,
            486,
            309,
            1715,
            665,
            5056,
            14455,
            30,
            51771
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25971786848461353,
          "compression_ratio": 1.727891156462585,
          "no_speech_prob": 0.001674340688623488
        },
        {
          "id": 22,
          "seek": 8372,
          "start": 83.72,
          "end": 86.64,
          "text": " And, you know, that's where we still have the human component.",
          "tokens": [
            50368,
            400,
            11,
            291,
            458,
            11,
            300,
            311,
            689,
            321,
            920,
            362,
            264,
            1952,
            6542,
            13,
            50510
          ],
          "temperature": 0.0,
          "avg_logprob": -0.408288664287991,
          "compression_ratio": 0.9117647058823529,
          "no_speech_prob": 0.0022159982472658157
        }
      ],
      "language": "en"
    },
    {
      "text": " Well, I think the safe way to use these things is to generate first drafts and iterate, but that you have to be the human editor who makes the final call and do the driving.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 4.96,
          "text": " Well, I think the safe way to use these things is to generate first drafts and iterate, but",
          "tokens": [
            50364,
            1042,
            11,
            286,
            519,
            264,
            3273,
            636,
            281,
            764,
            613,
            721,
            307,
            281,
            8460,
            700,
            11206,
            82,
            293,
            44497,
            11,
            457,
            50612
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25624795393510297,
          "compression_ratio": 1.3951612903225807,
          "no_speech_prob": 0.0018833858193829656
        },
        {
          "id": 1,
          "seek": 0,
          "start": 4.96,
          "end": 8.88,
          "text": " that you have to be the human editor who makes the final call and do the driving.",
          "tokens": [
            50612,
            300,
            291,
            362,
            281,
            312,
            264,
            1952,
            9839,
            567,
            1669,
            264,
            2572,
            818,
            293,
            360,
            264,
            4840,
            13,
            50808
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25624795393510297,
          "compression_ratio": 1.3951612903225807,
          "no_speech_prob": 0.0018833858193829656
        }
      ],
      "language": "en"
    },
    {
      "text": " Yeah, I agree. The work that we all do in the viz field can help determine what makes a good design, help give guidelines. We do research, empirical research, and then we produce guidelines for practitioners to follow.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 7.4,
          "text": " Yeah, I agree. The work that we all do in the viz field can help determine what makes a good design, help give guidelines.",
          "tokens": [
            50364,
            865,
            11,
            286,
            3986,
            13,
            440,
            589,
            300,
            321,
            439,
            360,
            294,
            264,
            371,
            590,
            2519,
            393,
            854,
            6997,
            437,
            1669,
            257,
            665,
            1715,
            11,
            854,
            976,
            12470,
            13,
            50734
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3130341698141659,
          "compression_ratio": 1.472972972972973,
          "no_speech_prob": 2.4274622774100862e-05
        },
        {
          "id": 1,
          "seek": 0,
          "start": 7.4,
          "end": 12.200000000000001,
          "text": " We do research, empirical research, and then we produce guidelines for practitioners to follow.",
          "tokens": [
            50734,
            492,
            360,
            2132,
            11,
            31886,
            2132,
            11,
            293,
            550,
            321,
            5258,
            12470,
            337,
            25742,
            281,
            1524,
            13,
            50974
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3130341698141659,
          "compression_ratio": 1.472972972972973,
          "no_speech_prob": 2.4274622774100862e-05
        }
      ],
      "language": "en"
    },
    {
      "text": " So bringing this all back to this moment, you're a natural language processing practitioner. You've spent years trying to teach machines to do useful things with language. And here we are suddenly in a moment where, I don't know about you, but I feel like, wow, a lot of the things we solved, you don't have to worry about anymore. Just sort of more and more and more of all that hard algorithmic hand-rolled feature engineering world is getting eaten up by large language models that can simply speak. And they seem to have cognitive abilities that we would never have dreamed would be in a machine.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 2.8000000000000003,
          "text": " So bringing this all back to this moment,",
          "tokens": [
            50364,
            407,
            5062,
            341,
            439,
            646,
            281,
            341,
            1623,
            11,
            50504
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19538781662617832,
          "compression_ratio": 1.6509090909090909,
          "no_speech_prob": 0.03404862806200981
        },
        {
          "id": 1,
          "seek": 0,
          "start": 2.8000000000000003,
          "end": 5.5600000000000005,
          "text": " you're a natural language processing practitioner.",
          "tokens": [
            50504,
            291,
            434,
            257,
            3303,
            2856,
            9007,
            32125,
            13,
            50642
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19538781662617832,
          "compression_ratio": 1.6509090909090909,
          "no_speech_prob": 0.03404862806200981
        },
        {
          "id": 2,
          "seek": 0,
          "start": 5.5600000000000005,
          "end": 7.92,
          "text": " You've spent years trying to teach machines",
          "tokens": [
            50642,
            509,
            600,
            4418,
            924,
            1382,
            281,
            2924,
            8379,
            50760
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19538781662617832,
          "compression_ratio": 1.6509090909090909,
          "no_speech_prob": 0.03404862806200981
        },
        {
          "id": 3,
          "seek": 0,
          "start": 7.92,
          "end": 10.200000000000001,
          "text": " to do useful things with language.",
          "tokens": [
            50760,
            281,
            360,
            4420,
            721,
            365,
            2856,
            13,
            50874
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19538781662617832,
          "compression_ratio": 1.6509090909090909,
          "no_speech_prob": 0.03404862806200981
        },
        {
          "id": 4,
          "seek": 0,
          "start": 10.200000000000001,
          "end": 12.52,
          "text": " And here we are suddenly in a moment where,",
          "tokens": [
            50874,
            400,
            510,
            321,
            366,
            5800,
            294,
            257,
            1623,
            689,
            11,
            50990
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19538781662617832,
          "compression_ratio": 1.6509090909090909,
          "no_speech_prob": 0.03404862806200981
        },
        {
          "id": 5,
          "seek": 0,
          "start": 12.52,
          "end": 14.6,
          "text": " I don't know about you, but I feel like, wow,",
          "tokens": [
            50990,
            286,
            500,
            380,
            458,
            466,
            291,
            11,
            457,
            286,
            841,
            411,
            11,
            6076,
            11,
            51094
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19538781662617832,
          "compression_ratio": 1.6509090909090909,
          "no_speech_prob": 0.03404862806200981
        },
        {
          "id": 6,
          "seek": 0,
          "start": 14.6,
          "end": 17.0,
          "text": " a lot of the things we solved,",
          "tokens": [
            51094,
            257,
            688,
            295,
            264,
            721,
            321,
            13041,
            11,
            51214
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19538781662617832,
          "compression_ratio": 1.6509090909090909,
          "no_speech_prob": 0.03404862806200981
        },
        {
          "id": 7,
          "seek": 0,
          "start": 17.0,
          "end": 19.12,
          "text": " you don't have to worry about anymore.",
          "tokens": [
            51214,
            291,
            500,
            380,
            362,
            281,
            3292,
            466,
            3602,
            13,
            51320
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19538781662617832,
          "compression_ratio": 1.6509090909090909,
          "no_speech_prob": 0.03404862806200981
        },
        {
          "id": 8,
          "seek": 0,
          "start": 19.12,
          "end": 21.240000000000002,
          "text": " Just sort of more and more and more",
          "tokens": [
            51320,
            1449,
            1333,
            295,
            544,
            293,
            544,
            293,
            544,
            51426
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19538781662617832,
          "compression_ratio": 1.6509090909090909,
          "no_speech_prob": 0.03404862806200981
        },
        {
          "id": 9,
          "seek": 0,
          "start": 21.240000000000002,
          "end": 24.64,
          "text": " of all that hard algorithmic hand-rolled",
          "tokens": [
            51426,
            295,
            439,
            300,
            1152,
            9284,
            299,
            1011,
            12,
            28850,
            51596
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19538781662617832,
          "compression_ratio": 1.6509090909090909,
          "no_speech_prob": 0.03404862806200981
        },
        {
          "id": 10,
          "seek": 0,
          "start": 24.64,
          "end": 28.060000000000002,
          "text": " feature engineering world is getting eaten up",
          "tokens": [
            51596,
            4111,
            7043,
            1002,
            307,
            1242,
            12158,
            493,
            51767
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19538781662617832,
          "compression_ratio": 1.6509090909090909,
          "no_speech_prob": 0.03404862806200981
        },
        {
          "id": 11,
          "seek": 2806,
          "start": 28.06,
          "end": 32.78,
          "text": " by large language models that can simply speak.",
          "tokens": [
            50364,
            538,
            2416,
            2856,
            5245,
            300,
            393,
            2935,
            1710,
            13,
            50600
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2331385748726981,
          "compression_ratio": 1.3425925925925926,
          "no_speech_prob": 0.0020181278232485056
        },
        {
          "id": 12,
          "seek": 2806,
          "start": 32.78,
          "end": 35.06,
          "text": " And they seem to have cognitive abilities",
          "tokens": [
            50600,
            400,
            436,
            1643,
            281,
            362,
            15605,
            11582,
            50714
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2331385748726981,
          "compression_ratio": 1.3425925925925926,
          "no_speech_prob": 0.0020181278232485056
        },
        {
          "id": 13,
          "seek": 2806,
          "start": 35.06,
          "end": 38.379999999999995,
          "text": " that we would never have dreamed would be in a machine.",
          "tokens": [
            50714,
            300,
            321,
            576,
            1128,
            362,
            26726,
            576,
            312,
            294,
            257,
            3479,
            13,
            50880
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2331385748726981,
          "compression_ratio": 1.3425925925925926,
          "no_speech_prob": 0.0020181278232485056
        }
      ],
      "language": "en"
    },
    {
      "text": " Well, I'm not going there with you on the cognitive abilities that I'm very cautious and skeptical about.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 2.8000000000000003,
          "text": " Well, I'm not going there with you on the cognitive abilities",
          "tokens": [
            50364,
            1042,
            11,
            286,
            478,
            406,
            516,
            456,
            365,
            291,
            322,
            264,
            15605,
            11582,
            50504
          ],
          "temperature": 0.0,
          "avg_logprob": -0.4306594354135019,
          "compression_ratio": 1.1290322580645162,
          "no_speech_prob": 0.009349077939987183
        },
        {
          "id": 1,
          "seek": 0,
          "start": 2.8000000000000003,
          "end": 5.2,
          "text": " that I'm very cautious and skeptical about.",
          "tokens": [
            50504,
            300,
            286,
            478,
            588,
            25278,
            293,
            28601,
            466,
            13,
            50624
          ],
          "temperature": 0.0,
          "avg_logprob": -0.4306594354135019,
          "compression_ratio": 1.1290322580645162,
          "no_speech_prob": 0.009349077939987183
        }
      ],
      "language": "en"
    },
    {
      "text": " What should we call them? Behaviors?",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 1.0,
          "text": " What should we call them?",
          "tokens": [
            50364,
            708,
            820,
            321,
            818,
            552,
            30,
            50414
          ],
          "temperature": 0.0,
          "avg_logprob": -0.4654730796813965,
          "compression_ratio": 0.8181818181818182,
          "no_speech_prob": 0.0008008375880308449
        },
        {
          "id": 1,
          "seek": 0,
          "start": 1.0,
          "end": 2.8000000000000003,
          "text": " Behaviors?",
          "tokens": [
            50414,
            13068,
            706,
            9337,
            30,
            50504
          ],
          "temperature": 0.0,
          "avg_logprob": -0.4654730796813965,
          "compression_ratio": 0.8181818181818182,
          "no_speech_prob": 0.0008008375880308449
        }
      ],
      "language": "en"
    },
    {
      "text": " I guess I don't have my favorite word for it yet, capabilities. It works a lot better than it used to work. There's a lot of people looking into, you know, why does it work? But you know, each time people start to make some progress on that, then a new model comes out that's even harder to understand because the scale is so much larger and we're not good at thinking at very large scale. So I think it's going to take years before we understand what's going on. I don't think it's cognition. I'm very skeptical about that. It's really, I mean, you know, we get into philosophy and the Chinese room, that's an old John Searle thought experiment. I mean, it's unfortunate, I guess, the use of Chinese in that particular example, but the idea being if you replace each piece of your brain with a little like component, electronic component, and you eventually replace every piece, is it still a brain? You know, are you still thinking, you know, it's philosophy thought experiments. You might want to say, oh, well, this model that's basically just a bunch of numbers, a bunch of weights that have been trained is thinking, because you can say that about the brain, but you know, I'm not convinced. I think there's a lot more going on in the brain than is going on in these models. I agree with you. They're very good at mimicking, you know, at producing language and because language is distinctly human, it feels, you know, to a lot of people like it's human. When people are driving in their cars, they name their car, even old cars that had no electronic components. They would name their cars, they would anthropomorphize their cars, they feel a part of their cars. This is what we do with technology. People are going to get used to it and then it's going to become old news. And I think it's great that we don't have to write all these tokenizers. The LP pipeline didn't work. It was a mess. And there's always new problems and new questions to investigate from a research perspective. Researchers will not be out of business. Of course, it does raise even more societal issues and dangers because of the ability to fake information, to spread misinformation, and for people to not know what's real and what's true. So we're living through a very chaotic moment right now. I think we're going to look back 10 years from now and we're going to go, wow, that was a chaotic time in technology. That was a chaotic time politically. And hopefully we'll be able to look back and say, thank goodness we made it through. Okay. I'm optimistic we will.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 3.44,
          "text": " I guess I don't have my favorite word for it yet, capabilities.",
          "tokens": [
            50364,
            286,
            2041,
            286,
            500,
            380,
            362,
            452,
            2954,
            1349,
            337,
            309,
            1939,
            11,
            10862,
            13,
            50536
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2173656977660267,
          "compression_ratio": 1.7583892617449663,
          "no_speech_prob": 0.013818478211760521
        },
        {
          "id": 1,
          "seek": 0,
          "start": 3.44,
          "end": 5.68,
          "text": " It works a lot better than it used to work.",
          "tokens": [
            50536,
            467,
            1985,
            257,
            688,
            1101,
            813,
            309,
            1143,
            281,
            589,
            13,
            50648
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2173656977660267,
          "compression_ratio": 1.7583892617449663,
          "no_speech_prob": 0.013818478211760521
        },
        {
          "id": 2,
          "seek": 0,
          "start": 5.68,
          "end": 8.52,
          "text": " There's a lot of people looking into, you know, why does it work?",
          "tokens": [
            50648,
            821,
            311,
            257,
            688,
            295,
            561,
            1237,
            666,
            11,
            291,
            458,
            11,
            983,
            775,
            309,
            589,
            30,
            50790
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2173656977660267,
          "compression_ratio": 1.7583892617449663,
          "no_speech_prob": 0.013818478211760521
        },
        {
          "id": 3,
          "seek": 0,
          "start": 8.52,
          "end": 12.44,
          "text": " But you know, each time people start to make some progress on that, then a new model comes",
          "tokens": [
            50790,
            583,
            291,
            458,
            11,
            1184,
            565,
            561,
            722,
            281,
            652,
            512,
            4205,
            322,
            300,
            11,
            550,
            257,
            777,
            2316,
            1487,
            50986
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2173656977660267,
          "compression_ratio": 1.7583892617449663,
          "no_speech_prob": 0.013818478211760521
        },
        {
          "id": 4,
          "seek": 0,
          "start": 12.44,
          "end": 16.52,
          "text": " out that's even harder to understand because the scale is so much larger and we're not",
          "tokens": [
            50986,
            484,
            300,
            311,
            754,
            6081,
            281,
            1223,
            570,
            264,
            4373,
            307,
            370,
            709,
            4833,
            293,
            321,
            434,
            406,
            51190
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2173656977660267,
          "compression_ratio": 1.7583892617449663,
          "no_speech_prob": 0.013818478211760521
        },
        {
          "id": 5,
          "seek": 0,
          "start": 16.52,
          "end": 18.8,
          "text": " good at thinking at very large scale.",
          "tokens": [
            51190,
            665,
            412,
            1953,
            412,
            588,
            2416,
            4373,
            13,
            51304
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2173656977660267,
          "compression_ratio": 1.7583892617449663,
          "no_speech_prob": 0.013818478211760521
        },
        {
          "id": 6,
          "seek": 0,
          "start": 18.8,
          "end": 22.44,
          "text": " So I think it's going to take years before we understand what's going on.",
          "tokens": [
            51304,
            407,
            286,
            519,
            309,
            311,
            516,
            281,
            747,
            924,
            949,
            321,
            1223,
            437,
            311,
            516,
            322,
            13,
            51486
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2173656977660267,
          "compression_ratio": 1.7583892617449663,
          "no_speech_prob": 0.013818478211760521
        },
        {
          "id": 7,
          "seek": 0,
          "start": 22.44,
          "end": 23.68,
          "text": " I don't think it's cognition.",
          "tokens": [
            51486,
            286,
            500,
            380,
            519,
            309,
            311,
            46905,
            13,
            51548
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2173656977660267,
          "compression_ratio": 1.7583892617449663,
          "no_speech_prob": 0.013818478211760521
        },
        {
          "id": 8,
          "seek": 0,
          "start": 23.68,
          "end": 25.52,
          "text": " I'm very skeptical about that.",
          "tokens": [
            51548,
            286,
            478,
            588,
            28601,
            466,
            300,
            13,
            51640
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2173656977660267,
          "compression_ratio": 1.7583892617449663,
          "no_speech_prob": 0.013818478211760521
        },
        {
          "id": 9,
          "seek": 2552,
          "start": 25.52,
          "end": 30.92,
          "text": " It's really, I mean, you know, we get into philosophy and the Chinese room, that's an",
          "tokens": [
            50364,
            467,
            311,
            534,
            11,
            286,
            914,
            11,
            291,
            458,
            11,
            321,
            483,
            666,
            10675,
            293,
            264,
            4649,
            1808,
            11,
            300,
            311,
            364,
            50634
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3068850741666906,
          "compression_ratio": 1.777049180327869,
          "no_speech_prob": 0.7275023460388184
        },
        {
          "id": 10,
          "seek": 2552,
          "start": 30.92,
          "end": 33.64,
          "text": " old John Searle thought experiment.",
          "tokens": [
            50634,
            1331,
            2619,
            1100,
            36153,
            1194,
            5120,
            13,
            50770
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3068850741666906,
          "compression_ratio": 1.777049180327869,
          "no_speech_prob": 0.7275023460388184
        },
        {
          "id": 11,
          "seek": 2552,
          "start": 33.64,
          "end": 38.28,
          "text": " I mean, it's unfortunate, I guess, the use of Chinese in that particular example, but",
          "tokens": [
            50770,
            286,
            914,
            11,
            309,
            311,
            17843,
            11,
            286,
            2041,
            11,
            264,
            764,
            295,
            4649,
            294,
            300,
            1729,
            1365,
            11,
            457,
            51002
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3068850741666906,
          "compression_ratio": 1.777049180327869,
          "no_speech_prob": 0.7275023460388184
        },
        {
          "id": 12,
          "seek": 2552,
          "start": 38.28,
          "end": 44.04,
          "text": " the idea being if you replace each piece of your brain with a little like component, electronic",
          "tokens": [
            51002,
            264,
            1558,
            885,
            498,
            291,
            7406,
            1184,
            2522,
            295,
            428,
            3567,
            365,
            257,
            707,
            411,
            6542,
            11,
            10092,
            51290
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3068850741666906,
          "compression_ratio": 1.777049180327869,
          "no_speech_prob": 0.7275023460388184
        },
        {
          "id": 13,
          "seek": 2552,
          "start": 44.04,
          "end": 47.04,
          "text": " component, and you eventually replace every piece, is it still a brain?",
          "tokens": [
            51290,
            6542,
            11,
            293,
            291,
            4728,
            7406,
            633,
            2522,
            11,
            307,
            309,
            920,
            257,
            3567,
            30,
            51440
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3068850741666906,
          "compression_ratio": 1.777049180327869,
          "no_speech_prob": 0.7275023460388184
        },
        {
          "id": 14,
          "seek": 2552,
          "start": 47.04,
          "end": 50.36,
          "text": " You know, are you still thinking, you know, it's philosophy thought experiments.",
          "tokens": [
            51440,
            509,
            458,
            11,
            366,
            291,
            920,
            1953,
            11,
            291,
            458,
            11,
            309,
            311,
            10675,
            1194,
            12050,
            13,
            51606
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3068850741666906,
          "compression_ratio": 1.777049180327869,
          "no_speech_prob": 0.7275023460388184
        },
        {
          "id": 15,
          "seek": 2552,
          "start": 50.36,
          "end": 55.16,
          "text": " You might want to say, oh, well, this model that's basically just a bunch of numbers,",
          "tokens": [
            51606,
            509,
            1062,
            528,
            281,
            584,
            11,
            1954,
            11,
            731,
            11,
            341,
            2316,
            300,
            311,
            1936,
            445,
            257,
            3840,
            295,
            3547,
            11,
            51846
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3068850741666906,
          "compression_ratio": 1.777049180327869,
          "no_speech_prob": 0.7275023460388184
        },
        {
          "id": 16,
          "seek": 5516,
          "start": 55.16,
          "end": 58.63999999999999,
          "text": " a bunch of weights that have been trained is thinking, because you can say that about",
          "tokens": [
            50364,
            257,
            3840,
            295,
            17443,
            300,
            362,
            668,
            8895,
            307,
            1953,
            11,
            570,
            291,
            393,
            584,
            300,
            466,
            50538
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21718020611498728,
          "compression_ratio": 1.912912912912913,
          "no_speech_prob": 0.10227648913860321
        },
        {
          "id": 17,
          "seek": 5516,
          "start": 58.63999999999999,
          "end": 60.919999999999995,
          "text": " the brain, but you know, I'm not convinced.",
          "tokens": [
            50538,
            264,
            3567,
            11,
            457,
            291,
            458,
            11,
            286,
            478,
            406,
            12561,
            13,
            50652
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21718020611498728,
          "compression_ratio": 1.912912912912913,
          "no_speech_prob": 0.10227648913860321
        },
        {
          "id": 18,
          "seek": 5516,
          "start": 60.919999999999995,
          "end": 64.39999999999999,
          "text": " I think there's a lot more going on in the brain than is going on in these models.",
          "tokens": [
            50652,
            286,
            519,
            456,
            311,
            257,
            688,
            544,
            516,
            322,
            294,
            264,
            3567,
            813,
            307,
            516,
            322,
            294,
            613,
            5245,
            13,
            50826
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21718020611498728,
          "compression_ratio": 1.912912912912913,
          "no_speech_prob": 0.10227648913860321
        },
        {
          "id": 19,
          "seek": 5516,
          "start": 64.39999999999999,
          "end": 65.39999999999999,
          "text": " I agree with you.",
          "tokens": [
            50826,
            286,
            3986,
            365,
            291,
            13,
            50876
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21718020611498728,
          "compression_ratio": 1.912912912912913,
          "no_speech_prob": 0.10227648913860321
        },
        {
          "id": 20,
          "seek": 5516,
          "start": 65.39999999999999,
          "end": 68.92,
          "text": " They're very good at mimicking, you know, at producing language and because language",
          "tokens": [
            50876,
            814,
            434,
            588,
            665,
            412,
            12247,
            10401,
            11,
            291,
            458,
            11,
            412,
            10501,
            2856,
            293,
            570,
            2856,
            51052
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21718020611498728,
          "compression_ratio": 1.912912912912913,
          "no_speech_prob": 0.10227648913860321
        },
        {
          "id": 21,
          "seek": 5516,
          "start": 68.92,
          "end": 73.44,
          "text": " is distinctly human, it feels, you know, to a lot of people like it's human.",
          "tokens": [
            51052,
            307,
            10644,
            356,
            1952,
            11,
            309,
            3417,
            11,
            291,
            458,
            11,
            281,
            257,
            688,
            295,
            561,
            411,
            309,
            311,
            1952,
            13,
            51278
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21718020611498728,
          "compression_ratio": 1.912912912912913,
          "no_speech_prob": 0.10227648913860321
        },
        {
          "id": 22,
          "seek": 5516,
          "start": 73.44,
          "end": 77.12,
          "text": " When people are driving in their cars, they name their car, even old cars that had no",
          "tokens": [
            51278,
            1133,
            561,
            366,
            4840,
            294,
            641,
            5163,
            11,
            436,
            1315,
            641,
            1032,
            11,
            754,
            1331,
            5163,
            300,
            632,
            572,
            51462
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21718020611498728,
          "compression_ratio": 1.912912912912913,
          "no_speech_prob": 0.10227648913860321
        },
        {
          "id": 23,
          "seek": 5516,
          "start": 77.12,
          "end": 78.32,
          "text": " electronic components.",
          "tokens": [
            51462,
            10092,
            6677,
            13,
            51522
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21718020611498728,
          "compression_ratio": 1.912912912912913,
          "no_speech_prob": 0.10227648913860321
        },
        {
          "id": 24,
          "seek": 5516,
          "start": 78.32,
          "end": 82.4,
          "text": " They would name their cars, they would anthropomorphize their cars, they feel a part of their cars.",
          "tokens": [
            51522,
            814,
            576,
            1315,
            641,
            5163,
            11,
            436,
            576,
            22727,
            32702,
            1125,
            641,
            5163,
            11,
            436,
            841,
            257,
            644,
            295,
            641,
            5163,
            13,
            51726
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21718020611498728,
          "compression_ratio": 1.912912912912913,
          "no_speech_prob": 0.10227648913860321
        },
        {
          "id": 25,
          "seek": 5516,
          "start": 82.4,
          "end": 84.4,
          "text": " This is what we do with technology.",
          "tokens": [
            51726,
            639,
            307,
            437,
            321,
            360,
            365,
            2899,
            13,
            51826
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21718020611498728,
          "compression_ratio": 1.912912912912913,
          "no_speech_prob": 0.10227648913860321
        },
        {
          "id": 26,
          "seek": 8440,
          "start": 84.4,
          "end": 87.72,
          "text": " People are going to get used to it and then it's going to become old news.",
          "tokens": [
            50364,
            3432,
            366,
            516,
            281,
            483,
            1143,
            281,
            309,
            293,
            550,
            309,
            311,
            516,
            281,
            1813,
            1331,
            2583,
            13,
            50530
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2613088754507212,
          "compression_ratio": 1.6666666666666667,
          "no_speech_prob": 0.5426866412162781
        },
        {
          "id": 27,
          "seek": 8440,
          "start": 87.72,
          "end": 90.80000000000001,
          "text": " And I think it's great that we don't have to write all these tokenizers.",
          "tokens": [
            50530,
            400,
            286,
            519,
            309,
            311,
            869,
            300,
            321,
            500,
            380,
            362,
            281,
            2464,
            439,
            613,
            14862,
            22525,
            13,
            50684
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2613088754507212,
          "compression_ratio": 1.6666666666666667,
          "no_speech_prob": 0.5426866412162781
        },
        {
          "id": 28,
          "seek": 8440,
          "start": 90.80000000000001,
          "end": 92.64,
          "text": " The LP pipeline didn't work.",
          "tokens": [
            50684,
            440,
            38095,
            15517,
            994,
            380,
            589,
            13,
            50776
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2613088754507212,
          "compression_ratio": 1.6666666666666667,
          "no_speech_prob": 0.5426866412162781
        },
        {
          "id": 29,
          "seek": 8440,
          "start": 92.64,
          "end": 94.08000000000001,
          "text": " It was a mess.",
          "tokens": [
            50776,
            467,
            390,
            257,
            2082,
            13,
            50848
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2613088754507212,
          "compression_ratio": 1.6666666666666667,
          "no_speech_prob": 0.5426866412162781
        },
        {
          "id": 30,
          "seek": 8440,
          "start": 94.08000000000001,
          "end": 99.12,
          "text": " And there's always new problems and new questions to investigate from a research perspective.",
          "tokens": [
            50848,
            400,
            456,
            311,
            1009,
            777,
            2740,
            293,
            777,
            1651,
            281,
            15013,
            490,
            257,
            2132,
            4585,
            13,
            51100
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2613088754507212,
          "compression_ratio": 1.6666666666666667,
          "no_speech_prob": 0.5426866412162781
        },
        {
          "id": 31,
          "seek": 8440,
          "start": 99.12,
          "end": 100.12,
          "text": " Researchers will not be out of business.",
          "tokens": [
            51100,
            43555,
            486,
            406,
            312,
            484,
            295,
            1606,
            13,
            51150
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2613088754507212,
          "compression_ratio": 1.6666666666666667,
          "no_speech_prob": 0.5426866412162781
        },
        {
          "id": 32,
          "seek": 8440,
          "start": 100.12,
          "end": 107.10000000000001,
          "text": " Of course, it does raise even more societal issues and dangers because of the ability",
          "tokens": [
            51150,
            2720,
            1164,
            11,
            309,
            775,
            5300,
            754,
            544,
            33472,
            2663,
            293,
            27701,
            570,
            295,
            264,
            3485,
            51499
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2613088754507212,
          "compression_ratio": 1.6666666666666667,
          "no_speech_prob": 0.5426866412162781
        },
        {
          "id": 33,
          "seek": 8440,
          "start": 107.10000000000001,
          "end": 112.7,
          "text": " to fake information, to spread misinformation, and for people to not know what's real and",
          "tokens": [
            51499,
            281,
            7592,
            1589,
            11,
            281,
            3974,
            34238,
            11,
            293,
            337,
            561,
            281,
            406,
            458,
            437,
            311,
            957,
            293,
            51779
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2613088754507212,
          "compression_ratio": 1.6666666666666667,
          "no_speech_prob": 0.5426866412162781
        },
        {
          "id": 34,
          "seek": 8440,
          "start": 112.7,
          "end": 113.7,
          "text": " what's true.",
          "tokens": [
            51779,
            437,
            311,
            2074,
            13,
            51829
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2613088754507212,
          "compression_ratio": 1.6666666666666667,
          "no_speech_prob": 0.5426866412162781
        },
        {
          "id": 35,
          "seek": 11370,
          "start": 113.7,
          "end": 116.22,
          "text": " So we're living through a very chaotic moment right now.",
          "tokens": [
            50364,
            407,
            321,
            434,
            2647,
            807,
            257,
            588,
            27013,
            1623,
            558,
            586,
            13,
            50490
          ],
          "temperature": 0.0,
          "avg_logprob": -0.27450606028238933,
          "compression_ratio": 1.6381909547738693,
          "no_speech_prob": 0.03356349468231201
        },
        {
          "id": 36,
          "seek": 11370,
          "start": 116.22,
          "end": 119.34,
          "text": " I think we're going to look back 10 years from now and we're going to go, wow, that",
          "tokens": [
            50490,
            286,
            519,
            321,
            434,
            516,
            281,
            574,
            646,
            1266,
            924,
            490,
            586,
            293,
            321,
            434,
            516,
            281,
            352,
            11,
            6076,
            11,
            300,
            50646
          ],
          "temperature": 0.0,
          "avg_logprob": -0.27450606028238933,
          "compression_ratio": 1.6381909547738693,
          "no_speech_prob": 0.03356349468231201
        },
        {
          "id": 37,
          "seek": 11370,
          "start": 119.34,
          "end": 120.82000000000001,
          "text": " was a chaotic time in technology.",
          "tokens": [
            50646,
            390,
            257,
            27013,
            565,
            294,
            2899,
            13,
            50720
          ],
          "temperature": 0.0,
          "avg_logprob": -0.27450606028238933,
          "compression_ratio": 1.6381909547738693,
          "no_speech_prob": 0.03356349468231201
        },
        {
          "id": 38,
          "seek": 11370,
          "start": 120.82000000000001,
          "end": 123.34,
          "text": " That was a chaotic time politically.",
          "tokens": [
            50720,
            663,
            390,
            257,
            27013,
            565,
            21154,
            13,
            50846
          ],
          "temperature": 0.0,
          "avg_logprob": -0.27450606028238933,
          "compression_ratio": 1.6381909547738693,
          "no_speech_prob": 0.03356349468231201
        },
        {
          "id": 39,
          "seek": 11370,
          "start": 123.34,
          "end": 126.5,
          "text": " And hopefully we'll be able to look back and say, thank goodness we made it through.",
          "tokens": [
            50846,
            400,
            4696,
            321,
            603,
            312,
            1075,
            281,
            574,
            646,
            293,
            584,
            11,
            1309,
            8387,
            321,
            1027,
            309,
            807,
            13,
            51004
          ],
          "temperature": 0.0,
          "avg_logprob": -0.27450606028238933,
          "compression_ratio": 1.6381909547738693,
          "no_speech_prob": 0.03356349468231201
        },
        {
          "id": 40,
          "seek": 11370,
          "start": 126.5,
          "end": 127.5,
          "text": " Okay.",
          "tokens": [
            51004,
            1033,
            13,
            51054
          ],
          "temperature": 0.0,
          "avg_logprob": -0.27450606028238933,
          "compression_ratio": 1.6381909547738693,
          "no_speech_prob": 0.03356349468231201
        },
        {
          "id": 41,
          "seek": 11370,
          "start": 127.5,
          "end": 128.66,
          "text": " I'm optimistic we will.",
          "tokens": [
            51054,
            286,
            478,
            19397,
            321,
            486,
            13,
            51112
          ],
          "temperature": 0.0,
          "avg_logprob": -0.27450606028238933,
          "compression_ratio": 1.6381909547738693,
          "no_speech_prob": 0.03356349468231201
        }
      ],
      "language": "en"
    },
    {
      "text": " I agree with you.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 0.84,
          "text": " I agree with you.",
          "tokens": [
            50364,
            286,
            3986,
            365,
            291,
            13,
            50406
          ],
          "temperature": 0.0,
          "avg_logprob": -0.36523571610450745,
          "compression_ratio": 0.68,
          "no_speech_prob": 0.0010037239408120513
        }
      ],
      "language": "en"
    },
    {
      "text": " Well, the curve you're describing is pretty smooth. It implies that there's going to be another side to this. But if things keep exponentially changing, there won't necessarily be that moment because it'll always feel like it does right now.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 3.2,
          "text": " Well, the curve you're describing is pretty smooth.",
          "tokens": [
            50364,
            1042,
            11,
            264,
            7605,
            291,
            434,
            16141,
            307,
            1238,
            5508,
            13,
            50524
          ],
          "temperature": 0.0,
          "avg_logprob": -0.29424029383166084,
          "compression_ratio": 1.4176470588235295,
          "no_speech_prob": 0.005507816560566425
        },
        {
          "id": 1,
          "seek": 0,
          "start": 3.54,
          "end": 6.5600000000000005,
          "text": " It implies that there's going to be another side to this.",
          "tokens": [
            50541,
            467,
            18779,
            300,
            456,
            311,
            516,
            281,
            312,
            1071,
            1252,
            281,
            341,
            13,
            50692
          ],
          "temperature": 0.0,
          "avg_logprob": -0.29424029383166084,
          "compression_ratio": 1.4176470588235295,
          "no_speech_prob": 0.005507816560566425
        },
        {
          "id": 2,
          "seek": 0,
          "start": 6.9,
          "end": 11.8,
          "text": " But if things keep exponentially changing, there won't necessarily be that moment",
          "tokens": [
            50709,
            583,
            498,
            721,
            1066,
            37330,
            4473,
            11,
            456,
            1582,
            380,
            4725,
            312,
            300,
            1623,
            50954
          ],
          "temperature": 0.0,
          "avg_logprob": -0.29424029383166084,
          "compression_ratio": 1.4176470588235295,
          "no_speech_prob": 0.005507816560566425
        },
        {
          "id": 3,
          "seek": 0,
          "start": 12.040000000000001,
          "end": 14.540000000000001,
          "text": " because it'll always feel like it does right now.",
          "tokens": [
            50966,
            570,
            309,
            603,
            1009,
            841,
            411,
            309,
            775,
            558,
            586,
            13,
            51091
          ],
          "temperature": 0.0,
          "avg_logprob": -0.29424029383166084,
          "compression_ratio": 1.4176470588235295,
          "no_speech_prob": 0.005507816560566425
        }
      ],
      "language": "en"
    },
    {
      "text": " Well, the technology that this breakthrough with these models and really with training on huge amounts of compute, huge amounts of data, I think it can only go so far, right? We don't know the limits of it, but it's not gonna be everything. If you look at people that are trying to study the brain, you know, it just, there's other things going on there, different kinds of structure and so on.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 3.12,
          "text": " Well, the technology that this breakthrough with these models",
          "tokens": [
            50364,
            1042,
            11,
            264,
            2899,
            300,
            341,
            22397,
            365,
            613,
            5245,
            50520
          ],
          "temperature": 0.0,
          "avg_logprob": -0.22071832929338728,
          "compression_ratio": 1.6348547717842323,
          "no_speech_prob": 8.211540261982009e-05
        },
        {
          "id": 1,
          "seek": 0,
          "start": 3.12,
          "end": 6.6000000000000005,
          "text": " and really with training on huge amounts of compute,",
          "tokens": [
            50520,
            293,
            534,
            365,
            3097,
            322,
            2603,
            11663,
            295,
            14722,
            11,
            50694
          ],
          "temperature": 0.0,
          "avg_logprob": -0.22071832929338728,
          "compression_ratio": 1.6348547717842323,
          "no_speech_prob": 8.211540261982009e-05
        },
        {
          "id": 2,
          "seek": 0,
          "start": 6.6000000000000005,
          "end": 9.88,
          "text": " huge amounts of data, I think it can only go so far, right?",
          "tokens": [
            50694,
            2603,
            11663,
            295,
            1412,
            11,
            286,
            519,
            309,
            393,
            787,
            352,
            370,
            1400,
            11,
            558,
            30,
            50858
          ],
          "temperature": 0.0,
          "avg_logprob": -0.22071832929338728,
          "compression_ratio": 1.6348547717842323,
          "no_speech_prob": 8.211540261982009e-05
        },
        {
          "id": 3,
          "seek": 0,
          "start": 9.88,
          "end": 11.4,
          "text": " We don't know the limits of it,",
          "tokens": [
            50858,
            492,
            500,
            380,
            458,
            264,
            10406,
            295,
            309,
            11,
            50934
          ],
          "temperature": 0.0,
          "avg_logprob": -0.22071832929338728,
          "compression_ratio": 1.6348547717842323,
          "no_speech_prob": 8.211540261982009e-05
        },
        {
          "id": 4,
          "seek": 0,
          "start": 11.4,
          "end": 13.08,
          "text": " but it's not gonna be everything.",
          "tokens": [
            50934,
            457,
            309,
            311,
            406,
            799,
            312,
            1203,
            13,
            51018
          ],
          "temperature": 0.0,
          "avg_logprob": -0.22071832929338728,
          "compression_ratio": 1.6348547717842323,
          "no_speech_prob": 8.211540261982009e-05
        },
        {
          "id": 5,
          "seek": 0,
          "start": 13.08,
          "end": 15.4,
          "text": " If you look at people that are trying to study the brain,",
          "tokens": [
            51018,
            759,
            291,
            574,
            412,
            561,
            300,
            366,
            1382,
            281,
            2979,
            264,
            3567,
            11,
            51134
          ],
          "temperature": 0.0,
          "avg_logprob": -0.22071832929338728,
          "compression_ratio": 1.6348547717842323,
          "no_speech_prob": 8.211540261982009e-05
        },
        {
          "id": 6,
          "seek": 0,
          "start": 15.4,
          "end": 17.88,
          "text": " you know, it just, there's other things going on there,",
          "tokens": [
            51134,
            291,
            458,
            11,
            309,
            445,
            11,
            456,
            311,
            661,
            721,
            516,
            322,
            456,
            11,
            51258
          ],
          "temperature": 0.0,
          "avg_logprob": -0.22071832929338728,
          "compression_ratio": 1.6348547717842323,
          "no_speech_prob": 8.211540261982009e-05
        },
        {
          "id": 7,
          "seek": 0,
          "start": 17.88,
          "end": 19.84,
          "text": " different kinds of structure and so on.",
          "tokens": [
            51258,
            819,
            3685,
            295,
            3877,
            293,
            370,
            322,
            13,
            51356
          ],
          "temperature": 0.0,
          "avg_logprob": -0.22071832929338728,
          "compression_ratio": 1.6348547717842323,
          "no_speech_prob": 8.211540261982009e-05
        }
      ],
      "language": "en"
    },
    {
      "text": " You think we're running out of data?",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 2.0,
          "text": " You think we're running out of data?",
          "tokens": [
            50364,
            509,
            519,
            321,
            434,
            2614,
            484,
            295,
            1412,
            30,
            50464
          ],
          "temperature": 0.0,
          "avg_logprob": -0.38443537553151447,
          "compression_ratio": 0.8181818181818182,
          "no_speech_prob": 0.003148743649944663
        }
      ],
      "language": "en"
    },
    {
      "text": " No, no, I don't think that's it. I think that the technique, it's a very specific technique. That alone, I don't think is going to be sufficient for being the same as humans. I'm not saying we could ever do it.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 1.32,
          "text": " No, no, I don't think that's it.",
          "tokens": [
            50364,
            883,
            11,
            572,
            11,
            286,
            500,
            380,
            519,
            300,
            311,
            309,
            13,
            50430
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19752905919001654,
          "compression_ratio": 1.4893617021276595,
          "no_speech_prob": 0.001254536909982562
        },
        {
          "id": 1,
          "seek": 0,
          "start": 1.32,
          "end": 5.88,
          "text": " I think that the technique, it's a very specific technique.",
          "tokens": [
            50430,
            286,
            519,
            300,
            264,
            6532,
            11,
            309,
            311,
            257,
            588,
            2685,
            6532,
            13,
            50658
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19752905919001654,
          "compression_ratio": 1.4893617021276595,
          "no_speech_prob": 0.001254536909982562
        },
        {
          "id": 2,
          "seek": 0,
          "start": 5.88,
          "end": 8.46,
          "text": " That alone, I don't think is going to be sufficient",
          "tokens": [
            50658,
            663,
            3312,
            11,
            286,
            500,
            380,
            519,
            307,
            516,
            281,
            312,
            11563,
            50787
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19752905919001654,
          "compression_ratio": 1.4893617021276595,
          "no_speech_prob": 0.001254536909982562
        },
        {
          "id": 3,
          "seek": 0,
          "start": 8.46,
          "end": 10.84,
          "text": " for being the same as humans.",
          "tokens": [
            50787,
            337,
            885,
            264,
            912,
            382,
            6255,
            13,
            50906
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19752905919001654,
          "compression_ratio": 1.4893617021276595,
          "no_speech_prob": 0.001254536909982562
        },
        {
          "id": 4,
          "seek": 0,
          "start": 10.84,
          "end": 12.6,
          "text": " I'm not saying we could ever do it.",
          "tokens": [
            50906,
            286,
            478,
            406,
            1566,
            321,
            727,
            1562,
            360,
            309,
            13,
            50994
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19752905919001654,
          "compression_ratio": 1.4893617021276595,
          "no_speech_prob": 0.001254536909982562
        }
      ],
      "language": "en"
    },
    {
      "text": " Some people do argue that sequence prediction, which is essentially what is driving this whole craze, might be all you need. What do you think about that?",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 5.4,
          "text": " Some people do argue that sequence prediction, which is essentially what is driving this whole craze,",
          "tokens": [
            50364,
            2188,
            561,
            360,
            9695,
            300,
            8310,
            17630,
            11,
            597,
            307,
            4476,
            437,
            307,
            4840,
            341,
            1379,
            2094,
            1381,
            11,
            50634
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3552599984246331,
          "compression_ratio": 1.2622950819672132,
          "no_speech_prob": 0.00022259584511630237
        },
        {
          "id": 1,
          "seek": 0,
          "start": 5.4,
          "end": 7.8,
          "text": " might be all you need. What do you think about that?",
          "tokens": [
            50634,
            1062,
            312,
            439,
            291,
            643,
            13,
            708,
            360,
            291,
            519,
            466,
            300,
            30,
            50754
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3552599984246331,
          "compression_ratio": 1.2622950819672132,
          "no_speech_prob": 0.00022259584511630237
        }
      ],
      "language": "en"
    },
    {
      "text": " Well, it's certainly all you need for certain tasks. We're seeing that now. It's really quite amazing. There is sometimes fine tuning on the other side, but again, who knows? I personally have been wrong about this particular technology. I think like a lot of people, I just didn't know how to think in terms of billions of parameters and we're just not good at that. There were some very ambitious people that just sort of went for it and surprised all of us. I admit it, I did not see this coming and I was surprised by it. And we have certainly in the research community, it's been developing gradually. So Word2Vec came along. So going back even farther, again, when I was doing early in the statistical NLP time, people were looking at SVDs, singular value decomposition and LSA, latent semantic analysis, which is similar in a lot of ways. It was putting words in a matrix, well, words by document matrices and trying to find similarities. Even before that, I was trying to solve the a thesaurus or the synonym problem to help with search. So in search, you look for cat and it's really feline and you don't find anything. Going back to the beginning of our conversation.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 1.8,
          "text": " Well, it's certainly all you need for certain tasks.",
          "tokens": [
            50364,
            1042,
            11,
            309,
            311,
            3297,
            439,
            291,
            643,
            337,
            1629,
            9608,
            13,
            50454
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19874281883239747,
          "compression_ratio": 1.7134328358208955,
          "no_speech_prob": 0.10952361673116684
        },
        {
          "id": 1,
          "seek": 0,
          "start": 1.8,
          "end": 2.72,
          "text": " We're seeing that now.",
          "tokens": [
            50454,
            492,
            434,
            2577,
            300,
            586,
            13,
            50500
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19874281883239747,
          "compression_ratio": 1.7134328358208955,
          "no_speech_prob": 0.10952361673116684
        },
        {
          "id": 2,
          "seek": 0,
          "start": 2.72,
          "end": 4.5200000000000005,
          "text": " It's really quite amazing.",
          "tokens": [
            50500,
            467,
            311,
            534,
            1596,
            2243,
            13,
            50590
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19874281883239747,
          "compression_ratio": 1.7134328358208955,
          "no_speech_prob": 0.10952361673116684
        },
        {
          "id": 3,
          "seek": 0,
          "start": 4.5200000000000005,
          "end": 6.76,
          "text": " There is sometimes fine tuning on the other side,",
          "tokens": [
            50590,
            821,
            307,
            2171,
            2489,
            15164,
            322,
            264,
            661,
            1252,
            11,
            50702
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19874281883239747,
          "compression_ratio": 1.7134328358208955,
          "no_speech_prob": 0.10952361673116684
        },
        {
          "id": 4,
          "seek": 0,
          "start": 6.76,
          "end": 8.620000000000001,
          "text": " but again, who knows?",
          "tokens": [
            50702,
            457,
            797,
            11,
            567,
            3255,
            30,
            50795
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19874281883239747,
          "compression_ratio": 1.7134328358208955,
          "no_speech_prob": 0.10952361673116684
        },
        {
          "id": 5,
          "seek": 0,
          "start": 8.620000000000001,
          "end": 9.66,
          "text": " I personally have been wrong",
          "tokens": [
            50795,
            286,
            5665,
            362,
            668,
            2085,
            50847
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19874281883239747,
          "compression_ratio": 1.7134328358208955,
          "no_speech_prob": 0.10952361673116684
        },
        {
          "id": 6,
          "seek": 0,
          "start": 9.66,
          "end": 11.68,
          "text": " about this particular technology.",
          "tokens": [
            50847,
            466,
            341,
            1729,
            2899,
            13,
            50948
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19874281883239747,
          "compression_ratio": 1.7134328358208955,
          "no_speech_prob": 0.10952361673116684
        },
        {
          "id": 7,
          "seek": 0,
          "start": 11.68,
          "end": 12.8,
          "text": " I think like a lot of people,",
          "tokens": [
            50948,
            286,
            519,
            411,
            257,
            688,
            295,
            561,
            11,
            51004
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19874281883239747,
          "compression_ratio": 1.7134328358208955,
          "no_speech_prob": 0.10952361673116684
        },
        {
          "id": 8,
          "seek": 0,
          "start": 12.8,
          "end": 14.0,
          "text": " I just didn't know how to think",
          "tokens": [
            51004,
            286,
            445,
            994,
            380,
            458,
            577,
            281,
            519,
            51064
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19874281883239747,
          "compression_ratio": 1.7134328358208955,
          "no_speech_prob": 0.10952361673116684
        },
        {
          "id": 9,
          "seek": 0,
          "start": 14.0,
          "end": 15.84,
          "text": " in terms of billions of parameters",
          "tokens": [
            51064,
            294,
            2115,
            295,
            17375,
            295,
            9834,
            51156
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19874281883239747,
          "compression_ratio": 1.7134328358208955,
          "no_speech_prob": 0.10952361673116684
        },
        {
          "id": 10,
          "seek": 0,
          "start": 15.84,
          "end": 17.240000000000002,
          "text": " and we're just not good at that.",
          "tokens": [
            51156,
            293,
            321,
            434,
            445,
            406,
            665,
            412,
            300,
            13,
            51226
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19874281883239747,
          "compression_ratio": 1.7134328358208955,
          "no_speech_prob": 0.10952361673116684
        },
        {
          "id": 11,
          "seek": 0,
          "start": 17.240000000000002,
          "end": 18.78,
          "text": " There were some very ambitious people",
          "tokens": [
            51226,
            821,
            645,
            512,
            588,
            20239,
            561,
            51303
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19874281883239747,
          "compression_ratio": 1.7134328358208955,
          "no_speech_prob": 0.10952361673116684
        },
        {
          "id": 12,
          "seek": 0,
          "start": 18.78,
          "end": 22.16,
          "text": " that just sort of went for it and surprised all of us.",
          "tokens": [
            51303,
            300,
            445,
            1333,
            295,
            1437,
            337,
            309,
            293,
            6100,
            439,
            295,
            505,
            13,
            51472
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19874281883239747,
          "compression_ratio": 1.7134328358208955,
          "no_speech_prob": 0.10952361673116684
        },
        {
          "id": 13,
          "seek": 0,
          "start": 22.16,
          "end": 24.32,
          "text": " I admit it, I did not see this coming",
          "tokens": [
            51472,
            286,
            9796,
            309,
            11,
            286,
            630,
            406,
            536,
            341,
            1348,
            51580
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19874281883239747,
          "compression_ratio": 1.7134328358208955,
          "no_speech_prob": 0.10952361673116684
        },
        {
          "id": 14,
          "seek": 0,
          "start": 24.32,
          "end": 26.080000000000002,
          "text": " and I was surprised by it.",
          "tokens": [
            51580,
            293,
            286,
            390,
            6100,
            538,
            309,
            13,
            51668
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19874281883239747,
          "compression_ratio": 1.7134328358208955,
          "no_speech_prob": 0.10952361673116684
        },
        {
          "id": 15,
          "seek": 0,
          "start": 26.080000000000002,
          "end": 28.48,
          "text": " And we have certainly in the research community,",
          "tokens": [
            51668,
            400,
            321,
            362,
            3297,
            294,
            264,
            2132,
            1768,
            11,
            51788
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19874281883239747,
          "compression_ratio": 1.7134328358208955,
          "no_speech_prob": 0.10952361673116684
        },
        {
          "id": 16,
          "seek": 2848,
          "start": 28.48,
          "end": 30.560000000000002,
          "text": " it's been developing gradually.",
          "tokens": [
            50364,
            309,
            311,
            668,
            6416,
            13145,
            13,
            50468
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2059900199665743,
          "compression_ratio": 1.5614617940199336,
          "no_speech_prob": 0.0004878329928033054
        },
        {
          "id": 17,
          "seek": 2848,
          "start": 30.560000000000002,
          "end": 32.480000000000004,
          "text": " So Word2Vec came along.",
          "tokens": [
            50468,
            407,
            8725,
            17,
            53,
            3045,
            1361,
            2051,
            13,
            50564
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2059900199665743,
          "compression_ratio": 1.5614617940199336,
          "no_speech_prob": 0.0004878329928033054
        },
        {
          "id": 18,
          "seek": 2848,
          "start": 32.480000000000004,
          "end": 33.8,
          "text": " So going back even farther,",
          "tokens": [
            50564,
            407,
            516,
            646,
            754,
            20344,
            11,
            50630
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2059900199665743,
          "compression_ratio": 1.5614617940199336,
          "no_speech_prob": 0.0004878329928033054
        },
        {
          "id": 19,
          "seek": 2848,
          "start": 33.8,
          "end": 37.96,
          "text": " again, when I was doing early in the statistical NLP time,",
          "tokens": [
            50630,
            797,
            11,
            562,
            286,
            390,
            884,
            2440,
            294,
            264,
            22820,
            426,
            45196,
            565,
            11,
            50838
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2059900199665743,
          "compression_ratio": 1.5614617940199336,
          "no_speech_prob": 0.0004878329928033054
        },
        {
          "id": 20,
          "seek": 2848,
          "start": 37.96,
          "end": 39.68,
          "text": " people were looking at SVDs,",
          "tokens": [
            50838,
            561,
            645,
            1237,
            412,
            31910,
            35,
            82,
            11,
            50924
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2059900199665743,
          "compression_ratio": 1.5614617940199336,
          "no_speech_prob": 0.0004878329928033054
        },
        {
          "id": 21,
          "seek": 2848,
          "start": 39.68,
          "end": 42.0,
          "text": " singular value decomposition and LSA,",
          "tokens": [
            50924,
            20010,
            2158,
            48356,
            293,
            441,
            8886,
            11,
            51040
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2059900199665743,
          "compression_ratio": 1.5614617940199336,
          "no_speech_prob": 0.0004878329928033054
        },
        {
          "id": 22,
          "seek": 2848,
          "start": 42.0,
          "end": 43.32,
          "text": " latent semantic analysis,",
          "tokens": [
            51040,
            48994,
            47982,
            5215,
            11,
            51106
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2059900199665743,
          "compression_ratio": 1.5614617940199336,
          "no_speech_prob": 0.0004878329928033054
        },
        {
          "id": 23,
          "seek": 2848,
          "start": 43.32,
          "end": 44.68,
          "text": " which is similar in a lot of ways.",
          "tokens": [
            51106,
            597,
            307,
            2531,
            294,
            257,
            688,
            295,
            2098,
            13,
            51174
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2059900199665743,
          "compression_ratio": 1.5614617940199336,
          "no_speech_prob": 0.0004878329928033054
        },
        {
          "id": 24,
          "seek": 2848,
          "start": 44.68,
          "end": 46.64,
          "text": " It was putting words in a matrix,",
          "tokens": [
            51174,
            467,
            390,
            3372,
            2283,
            294,
            257,
            8141,
            11,
            51272
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2059900199665743,
          "compression_ratio": 1.5614617940199336,
          "no_speech_prob": 0.0004878329928033054
        },
        {
          "id": 25,
          "seek": 2848,
          "start": 46.64,
          "end": 48.480000000000004,
          "text": " well, words by document matrices",
          "tokens": [
            51272,
            731,
            11,
            2283,
            538,
            4166,
            32284,
            51364
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2059900199665743,
          "compression_ratio": 1.5614617940199336,
          "no_speech_prob": 0.0004878329928033054
        },
        {
          "id": 26,
          "seek": 2848,
          "start": 48.480000000000004,
          "end": 50.28,
          "text": " and trying to find similarities.",
          "tokens": [
            51364,
            293,
            1382,
            281,
            915,
            24197,
            13,
            51454
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2059900199665743,
          "compression_ratio": 1.5614617940199336,
          "no_speech_prob": 0.0004878329928033054
        },
        {
          "id": 27,
          "seek": 2848,
          "start": 50.28,
          "end": 51.32,
          "text": " Even before that,",
          "tokens": [
            51454,
            2754,
            949,
            300,
            11,
            51506
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2059900199665743,
          "compression_ratio": 1.5614617940199336,
          "no_speech_prob": 0.0004878329928033054
        },
        {
          "id": 28,
          "seek": 2848,
          "start": 51.32,
          "end": 53.72,
          "text": " I was trying to solve the a thesaurus",
          "tokens": [
            51506,
            286,
            390,
            1382,
            281,
            5039,
            264,
            257,
            264,
            82,
            40913,
            51626
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2059900199665743,
          "compression_ratio": 1.5614617940199336,
          "no_speech_prob": 0.0004878329928033054
        },
        {
          "id": 29,
          "seek": 2848,
          "start": 53.72,
          "end": 56.24,
          "text": " or the synonym problem to help with search.",
          "tokens": [
            51626,
            420,
            264,
            5451,
            12732,
            1154,
            281,
            854,
            365,
            3164,
            13,
            51752
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2059900199665743,
          "compression_ratio": 1.5614617940199336,
          "no_speech_prob": 0.0004878329928033054
        },
        {
          "id": 30,
          "seek": 5624,
          "start": 56.24,
          "end": 60.56,
          "text": " So in search, you look for cat and it's really feline",
          "tokens": [
            50364,
            407,
            294,
            3164,
            11,
            291,
            574,
            337,
            3857,
            293,
            309,
            311,
            534,
            283,
            5440,
            50580
          ],
          "temperature": 0.0,
          "avg_logprob": -0.39520931243896484,
          "compression_ratio": 1.212962962962963,
          "no_speech_prob": 0.3034074306488037
        },
        {
          "id": 31,
          "seek": 5624,
          "start": 60.56,
          "end": 61.800000000000004,
          "text": " and you don't find anything.",
          "tokens": [
            50580,
            293,
            291,
            500,
            380,
            915,
            1340,
            13,
            50642
          ],
          "temperature": 0.0,
          "avg_logprob": -0.39520931243896484,
          "compression_ratio": 1.212962962962963,
          "no_speech_prob": 0.3034074306488037
        },
        {
          "id": 32,
          "seek": 5624,
          "start": 61.800000000000004,
          "end": 64.04,
          "text": " Going back to the beginning of our conversation.",
          "tokens": [
            50642,
            10963,
            646,
            281,
            264,
            2863,
            295,
            527,
            3761,
            13,
            50754
          ],
          "temperature": 0.0,
          "avg_logprob": -0.39520931243896484,
          "compression_ratio": 1.212962962962963,
          "no_speech_prob": 0.3034074306488037
        }
      ],
      "language": "en"
    },
    {
      "text": "",
      "segments": [],
      "language": "en"
    },
    {
      "text": " And you didn't want users to have to put in every synonym imaginable for a cat just to find text about cats.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 4.28,
          "text": " And you didn't want users to have to put in every synonym imaginable for a cat just to",
          "tokens": [
            50364,
            400,
            291,
            994,
            380,
            528,
            5022,
            281,
            362,
            281,
            829,
            294,
            633,
            5451,
            12732,
            23427,
            712,
            337,
            257,
            3857,
            445,
            281,
            50578
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2632817914409022,
          "compression_ratio": 1.173913043478261,
          "no_speech_prob": 0.00279032438993454
        },
        {
          "id": 1,
          "seek": 0,
          "start": 4.28,
          "end": 6.0,
          "text": " find text about cats.",
          "tokens": [
            50578,
            915,
            2487,
            466,
            11111,
            13,
            50664
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2632817914409022,
          "compression_ratio": 1.173913043478261,
          "no_speech_prob": 0.00279032438993454
        }
      ],
      "language": "en"
    },
    {
      "text": " Well, library catalogs had synonyms in the early days. They weren't that good. It weren't dynamic. They didn't handle new technology and they were hard to use. So WordNet came along and developed as a linguistic tool. And I was the first person to download it actually, when they had an FTP available. Did work on that. And it was like, Oh, we can have a thesaurus, but you know, it never worked. Whenever you had automatically recommended terms for a term, some of them were right and some were wrong. And that was true of SVD and LSA as well. They worked in some cases, they didn't work in other cases. And it wasn't until Word2Vec came along and then people actually then refined it to have different senses that it actually started to work. And so I was saying, wow, this actually works. And I've seen 20 years of this not working. And of course that kept being refined and being made more sophisticated, you know, with the transformers came along and now the really large things. So in the research community, it's been happening gradually. There were a lot of debates about counting versus probabilities and all this. So it's not out of the blue, but I do, again, I admit that in this last year between, you know, the combination of the image plus text generation and these language models where the input could be text, we never thought the input could be text and then the output would be all of these things, right? We thought we had to program things. And I don't think the people who developed these models expected that either. It was, I believe it was a surprise to them. So it is different now. I don't think everything's solved. I don't think it's AGI, but the tools are much more effective than they used to be.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 2.24,
          "text": " Well, library catalogs had synonyms in the early days.",
          "tokens": [
            50364,
            1042,
            11,
            6405,
            19746,
            82,
            632,
            5451,
            2526,
            2592,
            294,
            264,
            2440,
            1708,
            13,
            50476
          ],
          "temperature": 0.0,
          "avg_logprob": -0.27467204823213465,
          "compression_ratio": 1.682451253481894,
          "no_speech_prob": 0.004466638434678316
        },
        {
          "id": 1,
          "seek": 0,
          "start": 2.24,
          "end": 2.88,
          "text": " They weren't that good.",
          "tokens": [
            50476,
            814,
            4999,
            380,
            300,
            665,
            13,
            50508
          ],
          "temperature": 0.0,
          "avg_logprob": -0.27467204823213465,
          "compression_ratio": 1.682451253481894,
          "no_speech_prob": 0.004466638434678316
        },
        {
          "id": 2,
          "seek": 0,
          "start": 2.88,
          "end": 3.64,
          "text": " It weren't dynamic.",
          "tokens": [
            50508,
            467,
            4999,
            380,
            8546,
            13,
            50546
          ],
          "temperature": 0.0,
          "avg_logprob": -0.27467204823213465,
          "compression_ratio": 1.682451253481894,
          "no_speech_prob": 0.004466638434678316
        },
        {
          "id": 3,
          "seek": 0,
          "start": 3.64,
          "end": 5.5600000000000005,
          "text": " They didn't handle new technology and they were hard to use.",
          "tokens": [
            50546,
            814,
            994,
            380,
            4813,
            777,
            2899,
            293,
            436,
            645,
            1152,
            281,
            764,
            13,
            50642
          ],
          "temperature": 0.0,
          "avg_logprob": -0.27467204823213465,
          "compression_ratio": 1.682451253481894,
          "no_speech_prob": 0.004466638434678316
        },
        {
          "id": 4,
          "seek": 0,
          "start": 5.84,
          "end": 9.24,
          "text": " So WordNet came along and developed as a linguistic tool.",
          "tokens": [
            50656,
            407,
            8725,
            31890,
            1361,
            2051,
            293,
            4743,
            382,
            257,
            43002,
            2290,
            13,
            50826
          ],
          "temperature": 0.0,
          "avg_logprob": -0.27467204823213465,
          "compression_ratio": 1.682451253481894,
          "no_speech_prob": 0.004466638434678316
        },
        {
          "id": 5,
          "seek": 0,
          "start": 9.24,
          "end": 13.32,
          "text": " And I was the first person to download it actually, when they had an FTP available.",
          "tokens": [
            50826,
            400,
            286,
            390,
            264,
            700,
            954,
            281,
            5484,
            309,
            767,
            11,
            562,
            436,
            632,
            364,
            479,
            16804,
            2435,
            13,
            51030
          ],
          "temperature": 0.0,
          "avg_logprob": -0.27467204823213465,
          "compression_ratio": 1.682451253481894,
          "no_speech_prob": 0.004466638434678316
        },
        {
          "id": 6,
          "seek": 0,
          "start": 13.44,
          "end": 14.4,
          "text": " Did work on that.",
          "tokens": [
            51036,
            2589,
            589,
            322,
            300,
            13,
            51084
          ],
          "temperature": 0.0,
          "avg_logprob": -0.27467204823213465,
          "compression_ratio": 1.682451253481894,
          "no_speech_prob": 0.004466638434678316
        },
        {
          "id": 7,
          "seek": 0,
          "start": 14.52,
          "end": 17.44,
          "text": " And it was like, Oh, we can have a thesaurus, but you know, it never worked.",
          "tokens": [
            51090,
            400,
            309,
            390,
            411,
            11,
            876,
            11,
            321,
            393,
            362,
            257,
            264,
            82,
            40913,
            11,
            457,
            291,
            458,
            11,
            309,
            1128,
            2732,
            13,
            51236
          ],
          "temperature": 0.0,
          "avg_logprob": -0.27467204823213465,
          "compression_ratio": 1.682451253481894,
          "no_speech_prob": 0.004466638434678316
        },
        {
          "id": 8,
          "seek": 0,
          "start": 17.64,
          "end": 21.96,
          "text": " Whenever you had automatically recommended terms for a term, some of",
          "tokens": [
            51246,
            14159,
            291,
            632,
            6772,
            9628,
            2115,
            337,
            257,
            1433,
            11,
            512,
            295,
            51462
          ],
          "temperature": 0.0,
          "avg_logprob": -0.27467204823213465,
          "compression_ratio": 1.682451253481894,
          "no_speech_prob": 0.004466638434678316
        },
        {
          "id": 9,
          "seek": 0,
          "start": 21.96,
          "end": 23.32,
          "text": " them were right and some were wrong.",
          "tokens": [
            51462,
            552,
            645,
            558,
            293,
            512,
            645,
            2085,
            13,
            51530
          ],
          "temperature": 0.0,
          "avg_logprob": -0.27467204823213465,
          "compression_ratio": 1.682451253481894,
          "no_speech_prob": 0.004466638434678316
        },
        {
          "id": 10,
          "seek": 0,
          "start": 23.6,
          "end": 26.44,
          "text": " And that was true of SVD and LSA as well.",
          "tokens": [
            51544,
            400,
            300,
            390,
            2074,
            295,
            31910,
            35,
            293,
            441,
            8886,
            382,
            731,
            13,
            51686
          ],
          "temperature": 0.0,
          "avg_logprob": -0.27467204823213465,
          "compression_ratio": 1.682451253481894,
          "no_speech_prob": 0.004466638434678316
        },
        {
          "id": 11,
          "seek": 0,
          "start": 26.64,
          "end": 28.84,
          "text": " They worked in some cases, they didn't work in other cases.",
          "tokens": [
            51696,
            814,
            2732,
            294,
            512,
            3331,
            11,
            436,
            994,
            380,
            589,
            294,
            661,
            3331,
            13,
            51806
          ],
          "temperature": 0.0,
          "avg_logprob": -0.27467204823213465,
          "compression_ratio": 1.682451253481894,
          "no_speech_prob": 0.004466638434678316
        },
        {
          "id": 12,
          "seek": 2884,
          "start": 29.12,
          "end": 33.4,
          "text": " And it wasn't until Word2Vec came along and then people actually then refined it",
          "tokens": [
            50378,
            400,
            309,
            2067,
            380,
            1826,
            8725,
            17,
            53,
            3045,
            1361,
            2051,
            293,
            550,
            561,
            767,
            550,
            26201,
            309,
            50592
          ],
          "temperature": 0.0,
          "avg_logprob": -0.23944338989257813,
          "compression_ratio": 1.698360655737705,
          "no_speech_prob": 0.00293480115942657
        },
        {
          "id": 13,
          "seek": 2884,
          "start": 33.4,
          "end": 36.72,
          "text": " to have different senses that it actually started to work.",
          "tokens": [
            50592,
            281,
            362,
            819,
            17057,
            300,
            309,
            767,
            1409,
            281,
            589,
            13,
            50758
          ],
          "temperature": 0.0,
          "avg_logprob": -0.23944338989257813,
          "compression_ratio": 1.698360655737705,
          "no_speech_prob": 0.00293480115942657
        },
        {
          "id": 14,
          "seek": 2884,
          "start": 36.72,
          "end": 39.88,
          "text": " And so I was saying, wow, this actually works.",
          "tokens": [
            50758,
            400,
            370,
            286,
            390,
            1566,
            11,
            6076,
            11,
            341,
            767,
            1985,
            13,
            50916
          ],
          "temperature": 0.0,
          "avg_logprob": -0.23944338989257813,
          "compression_ratio": 1.698360655737705,
          "no_speech_prob": 0.00293480115942657
        },
        {
          "id": 15,
          "seek": 2884,
          "start": 40.12,
          "end": 42.44,
          "text": " And I've seen 20 years of this not working.",
          "tokens": [
            50928,
            400,
            286,
            600,
            1612,
            945,
            924,
            295,
            341,
            406,
            1364,
            13,
            51044
          ],
          "temperature": 0.0,
          "avg_logprob": -0.23944338989257813,
          "compression_ratio": 1.698360655737705,
          "no_speech_prob": 0.00293480115942657
        },
        {
          "id": 16,
          "seek": 2884,
          "start": 42.84,
          "end": 47.16,
          "text": " And of course that kept being refined and being made more sophisticated, you know,",
          "tokens": [
            51064,
            400,
            295,
            1164,
            300,
            4305,
            885,
            26201,
            293,
            885,
            1027,
            544,
            16950,
            11,
            291,
            458,
            11,
            51280
          ],
          "temperature": 0.0,
          "avg_logprob": -0.23944338989257813,
          "compression_ratio": 1.698360655737705,
          "no_speech_prob": 0.00293480115942657
        },
        {
          "id": 17,
          "seek": 2884,
          "start": 47.16,
          "end": 49.879999999999995,
          "text": " with the transformers came along and now the really large things.",
          "tokens": [
            51280,
            365,
            264,
            4088,
            433,
            1361,
            2051,
            293,
            586,
            264,
            534,
            2416,
            721,
            13,
            51416
          ],
          "temperature": 0.0,
          "avg_logprob": -0.23944338989257813,
          "compression_ratio": 1.698360655737705,
          "no_speech_prob": 0.00293480115942657
        },
        {
          "id": 18,
          "seek": 2884,
          "start": 49.879999999999995,
          "end": 53.44,
          "text": " So in the research community, it's been happening gradually.",
          "tokens": [
            51416,
            407,
            294,
            264,
            2132,
            1768,
            11,
            309,
            311,
            668,
            2737,
            13145,
            13,
            51594
          ],
          "temperature": 0.0,
          "avg_logprob": -0.23944338989257813,
          "compression_ratio": 1.698360655737705,
          "no_speech_prob": 0.00293480115942657
        },
        {
          "id": 19,
          "seek": 2884,
          "start": 53.44,
          "end": 57.519999999999996,
          "text": " There were a lot of debates about counting versus probabilities and all this.",
          "tokens": [
            51594,
            821,
            645,
            257,
            688,
            295,
            24203,
            466,
            13251,
            5717,
            33783,
            293,
            439,
            341,
            13,
            51798
          ],
          "temperature": 0.0,
          "avg_logprob": -0.23944338989257813,
          "compression_ratio": 1.698360655737705,
          "no_speech_prob": 0.00293480115942657
        },
        {
          "id": 20,
          "seek": 5752,
          "start": 57.92,
          "end": 63.92,
          "text": " So it's not out of the blue, but I do, again, I admit that in this last year",
          "tokens": [
            50384,
            407,
            309,
            311,
            406,
            484,
            295,
            264,
            3344,
            11,
            457,
            286,
            360,
            11,
            797,
            11,
            286,
            9796,
            300,
            294,
            341,
            1036,
            1064,
            50684
          ],
          "temperature": 0.0,
          "avg_logprob": -0.23098184080684886,
          "compression_ratio": 1.7713310580204777,
          "no_speech_prob": 0.0014324632938951254
        },
        {
          "id": 21,
          "seek": 5752,
          "start": 63.92,
          "end": 67.92,
          "text": " between, you know, the combination of the image plus text generation and these",
          "tokens": [
            50684,
            1296,
            11,
            291,
            458,
            11,
            264,
            6562,
            295,
            264,
            3256,
            1804,
            2487,
            5125,
            293,
            613,
            50884
          ],
          "temperature": 0.0,
          "avg_logprob": -0.23098184080684886,
          "compression_ratio": 1.7713310580204777,
          "no_speech_prob": 0.0014324632938951254
        },
        {
          "id": 22,
          "seek": 5752,
          "start": 67.92,
          "end": 71.48,
          "text": " language models where the input could be text, we never thought the input could be",
          "tokens": [
            50884,
            2856,
            5245,
            689,
            264,
            4846,
            727,
            312,
            2487,
            11,
            321,
            1128,
            1194,
            264,
            4846,
            727,
            312,
            51062
          ],
          "temperature": 0.0,
          "avg_logprob": -0.23098184080684886,
          "compression_ratio": 1.7713310580204777,
          "no_speech_prob": 0.0014324632938951254
        },
        {
          "id": 23,
          "seek": 5752,
          "start": 71.48,
          "end": 74.96000000000001,
          "text": " text and then the output would be all of these things, right?",
          "tokens": [
            51062,
            2487,
            293,
            550,
            264,
            5598,
            576,
            312,
            439,
            295,
            613,
            721,
            11,
            558,
            30,
            51236
          ],
          "temperature": 0.0,
          "avg_logprob": -0.23098184080684886,
          "compression_ratio": 1.7713310580204777,
          "no_speech_prob": 0.0014324632938951254
        },
        {
          "id": 24,
          "seek": 5752,
          "start": 74.96000000000001,
          "end": 76.32000000000001,
          "text": " We thought we had to program things.",
          "tokens": [
            51236,
            492,
            1194,
            321,
            632,
            281,
            1461,
            721,
            13,
            51304
          ],
          "temperature": 0.0,
          "avg_logprob": -0.23098184080684886,
          "compression_ratio": 1.7713310580204777,
          "no_speech_prob": 0.0014324632938951254
        },
        {
          "id": 25,
          "seek": 5752,
          "start": 76.44,
          "end": 79.2,
          "text": " And I don't think the people who developed these models expected that either.",
          "tokens": [
            51310,
            400,
            286,
            500,
            380,
            519,
            264,
            561,
            567,
            4743,
            613,
            5245,
            5176,
            300,
            2139,
            13,
            51448
          ],
          "temperature": 0.0,
          "avg_logprob": -0.23098184080684886,
          "compression_ratio": 1.7713310580204777,
          "no_speech_prob": 0.0014324632938951254
        },
        {
          "id": 26,
          "seek": 5752,
          "start": 79.2,
          "end": 81.44,
          "text": " It was, I believe it was a surprise to them.",
          "tokens": [
            51448,
            467,
            390,
            11,
            286,
            1697,
            309,
            390,
            257,
            6365,
            281,
            552,
            13,
            51560
          ],
          "temperature": 0.0,
          "avg_logprob": -0.23098184080684886,
          "compression_ratio": 1.7713310580204777,
          "no_speech_prob": 0.0014324632938951254
        },
        {
          "id": 27,
          "seek": 5752,
          "start": 81.68,
          "end": 83.88,
          "text": " So it is different now.",
          "tokens": [
            51572,
            407,
            309,
            307,
            819,
            586,
            13,
            51682
          ],
          "temperature": 0.0,
          "avg_logprob": -0.23098184080684886,
          "compression_ratio": 1.7713310580204777,
          "no_speech_prob": 0.0014324632938951254
        },
        {
          "id": 28,
          "seek": 5752,
          "start": 84.36,
          "end": 85.76,
          "text": " I don't think everything's solved.",
          "tokens": [
            51706,
            286,
            500,
            380,
            519,
            1203,
            311,
            13041,
            13,
            51776
          ],
          "temperature": 0.0,
          "avg_logprob": -0.23098184080684886,
          "compression_ratio": 1.7713310580204777,
          "no_speech_prob": 0.0014324632938951254
        },
        {
          "id": 29,
          "seek": 8576,
          "start": 85.76,
          "end": 91.32000000000001,
          "text": " I don't think it's AGI, but the tools are much more effective than they used to be.",
          "tokens": [
            50364,
            286,
            500,
            380,
            519,
            309,
            311,
            316,
            26252,
            11,
            457,
            264,
            3873,
            366,
            709,
            544,
            4942,
            813,
            436,
            1143,
            281,
            312,
            13,
            50642
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19837448120117188,
          "compression_ratio": 1.0246913580246915,
          "no_speech_prob": 0.001097700442187488
        }
      ],
      "language": "en"
    },
    {
      "text": " Yep.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 0.84,
          "text": " Yep.",
          "tokens": [
            50364,
            7010,
            13,
            50406
          ],
          "temperature": 0.0,
          "avg_logprob": -0.4158630847930908,
          "compression_ratio": 0.3333333333333333,
          "no_speech_prob": 0.8275853395462036
        }
      ],
      "language": "en"
    },
    {
      "text": " And I think.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 0.5,
          "text": " And I think.",
          "tokens": [
            50364,
            400,
            286,
            519,
            13,
            50389
          ],
          "temperature": 0.0,
          "avg_logprob": -0.6441888809204102,
          "compression_ratio": 0.6,
          "no_speech_prob": 0.514585018157959
        }
      ],
      "language": "en"
    },
    {
      "text": " Well, like you said, it's all about capabilities. And it turns out if you teach a very big neural network how to predict the next word on a huge amount of internet text, all these really neat emergent capabilities come into your hands. Couldn't have been predicted. In fact, no one really thought it would work as well as it does, I'm sure, but it does. I wonder what happens when you teach a model to predict the next image in every YouTube video. What capabilities emerge?",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 2.6,
          "text": " Well, like you said, it's all about capabilities.",
          "tokens": [
            50364,
            1042,
            11,
            411,
            291,
            848,
            11,
            309,
            311,
            439,
            466,
            10862,
            13,
            50494
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2481933624025375,
          "compression_ratio": 1.711191335740072,
          "no_speech_prob": 5.8209028793498874e-05
        },
        {
          "id": 1,
          "seek": 0,
          "start": 2.6,
          "end": 5.96,
          "text": " And it turns out if you teach a very big neural network",
          "tokens": [
            50494,
            400,
            309,
            4523,
            484,
            498,
            291,
            2924,
            257,
            588,
            955,
            18161,
            3209,
            50662
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2481933624025375,
          "compression_ratio": 1.711191335740072,
          "no_speech_prob": 5.8209028793498874e-05
        },
        {
          "id": 2,
          "seek": 0,
          "start": 5.96,
          "end": 9.52,
          "text": " how to predict the next word on a huge amount of internet text,",
          "tokens": [
            50662,
            577,
            281,
            6069,
            264,
            958,
            1349,
            322,
            257,
            2603,
            2372,
            295,
            4705,
            2487,
            11,
            50840
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2481933624025375,
          "compression_ratio": 1.711191335740072,
          "no_speech_prob": 5.8209028793498874e-05
        },
        {
          "id": 3,
          "seek": 0,
          "start": 9.52,
          "end": 12.4,
          "text": " all these really neat emergent capabilities",
          "tokens": [
            50840,
            439,
            613,
            534,
            10654,
            4345,
            6930,
            10862,
            50984
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2481933624025375,
          "compression_ratio": 1.711191335740072,
          "no_speech_prob": 5.8209028793498874e-05
        },
        {
          "id": 4,
          "seek": 0,
          "start": 12.4,
          "end": 13.52,
          "text": " come into your hands.",
          "tokens": [
            50984,
            808,
            666,
            428,
            2377,
            13,
            51040
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2481933624025375,
          "compression_ratio": 1.711191335740072,
          "no_speech_prob": 5.8209028793498874e-05
        },
        {
          "id": 5,
          "seek": 0,
          "start": 13.52,
          "end": 14.280000000000001,
          "text": " Couldn't have been predicted.",
          "tokens": [
            51040,
            35800,
            380,
            362,
            668,
            19147,
            13,
            51078
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2481933624025375,
          "compression_ratio": 1.711191335740072,
          "no_speech_prob": 5.8209028793498874e-05
        },
        {
          "id": 6,
          "seek": 0,
          "start": 14.280000000000001,
          "end": 17.92,
          "text": " In fact, no one really thought it would work as well as it does,",
          "tokens": [
            51078,
            682,
            1186,
            11,
            572,
            472,
            534,
            1194,
            309,
            576,
            589,
            382,
            731,
            382,
            309,
            775,
            11,
            51260
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2481933624025375,
          "compression_ratio": 1.711191335740072,
          "no_speech_prob": 5.8209028793498874e-05
        },
        {
          "id": 7,
          "seek": 0,
          "start": 17.92,
          "end": 19.64,
          "text": " I'm sure, but it does.",
          "tokens": [
            51260,
            286,
            478,
            988,
            11,
            457,
            309,
            775,
            13,
            51346
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2481933624025375,
          "compression_ratio": 1.711191335740072,
          "no_speech_prob": 5.8209028793498874e-05
        },
        {
          "id": 8,
          "seek": 0,
          "start": 19.64,
          "end": 22.68,
          "text": " I wonder what happens when you teach a model",
          "tokens": [
            51346,
            286,
            2441,
            437,
            2314,
            562,
            291,
            2924,
            257,
            2316,
            51498
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2481933624025375,
          "compression_ratio": 1.711191335740072,
          "no_speech_prob": 5.8209028793498874e-05
        },
        {
          "id": 9,
          "seek": 0,
          "start": 22.68,
          "end": 26.52,
          "text": " to predict the next image in every YouTube video.",
          "tokens": [
            51498,
            281,
            6069,
            264,
            958,
            3256,
            294,
            633,
            3088,
            960,
            13,
            51690
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2481933624025375,
          "compression_ratio": 1.711191335740072,
          "no_speech_prob": 5.8209028793498874e-05
        },
        {
          "id": 10,
          "seek": 0,
          "start": 26.52,
          "end": 28.0,
          "text": " What capabilities emerge?",
          "tokens": [
            51690,
            708,
            10862,
            21511,
            30,
            51764
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2481933624025375,
          "compression_ratio": 1.711191335740072,
          "no_speech_prob": 5.8209028793498874e-05
        }
      ],
      "language": "en"
    },
    {
      "text": " Yeah, it's going to be interesting. You know, it should be much better at generating video. I mean, I guess there's already work on generating videos.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 1.44,
          "text": " Yeah, it's going to be interesting.",
          "tokens": [
            50364,
            865,
            11,
            309,
            311,
            516,
            281,
            312,
            1880,
            13,
            50436
          ],
          "temperature": 0.0,
          "avg_logprob": -0.34509933285596894,
          "compression_ratio": 1.3274336283185841,
          "no_speech_prob": 6.088728332542814e-05
        },
        {
          "id": 1,
          "seek": 0,
          "start": 1.44,
          "end": 3.8000000000000003,
          "text": " You know, it should be much better at generating video.",
          "tokens": [
            50436,
            509,
            458,
            11,
            309,
            820,
            312,
            709,
            1101,
            412,
            17746,
            960,
            13,
            50554
          ],
          "temperature": 0.0,
          "avg_logprob": -0.34509933285596894,
          "compression_ratio": 1.3274336283185841,
          "no_speech_prob": 6.088728332542814e-05
        },
        {
          "id": 2,
          "seek": 0,
          "start": 3.8000000000000003,
          "end": 6.0,
          "text": " I mean, I guess there's already work on generating videos.",
          "tokens": [
            50554,
            286,
            914,
            11,
            286,
            2041,
            456,
            311,
            1217,
            589,
            322,
            17746,
            2145,
            13,
            50664
          ],
          "temperature": 0.0,
          "avg_logprob": -0.34509933285596894,
          "compression_ratio": 1.3274336283185841,
          "no_speech_prob": 6.088728332542814e-05
        }
      ],
      "language": "en"
    },
    {
      "text": " I feel like generating videos is kind of like that unicorn story moment. So you remember in the early days of GPT-3 when they were trying to show how great it was, they said, look, you can start the first sentence of a story about something that it definitely has never seen. It was something about unicorns and it could just write a story and it's coherent and it's a story. Well, I think there will be that video moment where you start with an image and you just say, Hey, finish this, make this a one minute video from this scene. And that'll happen. But just like with GPT-3, the thing that's going to blow us away are the things we can't predict it'll be able to do. It's going to have capabilities that just emerge.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 3.72,
          "text": " I feel like generating videos is kind of like that unicorn story moment.",
          "tokens": [
            50364,
            286,
            841,
            411,
            17746,
            2145,
            307,
            733,
            295,
            411,
            300,
            28122,
            1657,
            1623,
            13,
            50550
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24305513479413776,
          "compression_ratio": 1.7475409836065574,
          "no_speech_prob": 0.32687029242515564
        },
        {
          "id": 1,
          "seek": 0,
          "start": 3.72,
          "end": 7.96,
          "text": " So you remember in the early days of GPT-3 when they were trying to show how great it",
          "tokens": [
            50550,
            407,
            291,
            1604,
            294,
            264,
            2440,
            1708,
            295,
            26039,
            51,
            12,
            18,
            562,
            436,
            645,
            1382,
            281,
            855,
            577,
            869,
            309,
            50762
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24305513479413776,
          "compression_ratio": 1.7475409836065574,
          "no_speech_prob": 0.32687029242515564
        },
        {
          "id": 2,
          "seek": 0,
          "start": 7.96,
          "end": 12.14,
          "text": " was, they said, look, you can start the first sentence of a story about something that it",
          "tokens": [
            50762,
            390,
            11,
            436,
            848,
            11,
            574,
            11,
            291,
            393,
            722,
            264,
            700,
            8174,
            295,
            257,
            1657,
            466,
            746,
            300,
            309,
            50971
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24305513479413776,
          "compression_ratio": 1.7475409836065574,
          "no_speech_prob": 0.32687029242515564
        },
        {
          "id": 3,
          "seek": 0,
          "start": 12.14,
          "end": 13.58,
          "text": " definitely has never seen.",
          "tokens": [
            50971,
            2138,
            575,
            1128,
            1612,
            13,
            51043
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24305513479413776,
          "compression_ratio": 1.7475409836065574,
          "no_speech_prob": 0.32687029242515564
        },
        {
          "id": 4,
          "seek": 0,
          "start": 13.58,
          "end": 18.3,
          "text": " It was something about unicorns and it could just write a story and it's coherent and it's",
          "tokens": [
            51043,
            467,
            390,
            746,
            466,
            28122,
            82,
            293,
            309,
            727,
            445,
            2464,
            257,
            1657,
            293,
            309,
            311,
            36239,
            293,
            309,
            311,
            51279
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24305513479413776,
          "compression_ratio": 1.7475409836065574,
          "no_speech_prob": 0.32687029242515564
        },
        {
          "id": 5,
          "seek": 0,
          "start": 18.3,
          "end": 19.3,
          "text": " a story.",
          "tokens": [
            51279,
            257,
            1657,
            13,
            51329
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24305513479413776,
          "compression_ratio": 1.7475409836065574,
          "no_speech_prob": 0.32687029242515564
        },
        {
          "id": 6,
          "seek": 0,
          "start": 19.3,
          "end": 25.28,
          "text": " Well, I think there will be that video moment where you start with an image and you just",
          "tokens": [
            51329,
            1042,
            11,
            286,
            519,
            456,
            486,
            312,
            300,
            960,
            1623,
            689,
            291,
            722,
            365,
            364,
            3256,
            293,
            291,
            445,
            51628
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24305513479413776,
          "compression_ratio": 1.7475409836065574,
          "no_speech_prob": 0.32687029242515564
        },
        {
          "id": 7,
          "seek": 0,
          "start": 25.28,
          "end": 29.5,
          "text": " say, Hey, finish this, make this a one minute video from this scene.",
          "tokens": [
            51628,
            584,
            11,
            1911,
            11,
            2413,
            341,
            11,
            652,
            341,
            257,
            472,
            3456,
            960,
            490,
            341,
            4145,
            13,
            51839
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24305513479413776,
          "compression_ratio": 1.7475409836065574,
          "no_speech_prob": 0.32687029242515564
        },
        {
          "id": 8,
          "seek": 2950,
          "start": 29.5,
          "end": 30.58,
          "text": " And that'll happen.",
          "tokens": [
            50364,
            400,
            300,
            603,
            1051,
            13,
            50418
          ],
          "temperature": 0.0,
          "avg_logprob": -0.20772009236471994,
          "compression_ratio": 1.364963503649635,
          "no_speech_prob": 0.16447502374649048
        },
        {
          "id": 9,
          "seek": 2950,
          "start": 30.58,
          "end": 35.18,
          "text": " But just like with GPT-3, the thing that's going to blow us away are the things we can't",
          "tokens": [
            50418,
            583,
            445,
            411,
            365,
            26039,
            51,
            12,
            18,
            11,
            264,
            551,
            300,
            311,
            516,
            281,
            6327,
            505,
            1314,
            366,
            264,
            721,
            321,
            393,
            380,
            50648
          ],
          "temperature": 0.0,
          "avg_logprob": -0.20772009236471994,
          "compression_ratio": 1.364963503649635,
          "no_speech_prob": 0.16447502374649048
        },
        {
          "id": 10,
          "seek": 2950,
          "start": 35.18,
          "end": 36.78,
          "text": " predict it'll be able to do.",
          "tokens": [
            50648,
            6069,
            309,
            603,
            312,
            1075,
            281,
            360,
            13,
            50728
          ],
          "temperature": 0.0,
          "avg_logprob": -0.20772009236471994,
          "compression_ratio": 1.364963503649635,
          "no_speech_prob": 0.16447502374649048
        },
        {
          "id": 11,
          "seek": 2950,
          "start": 36.78,
          "end": 39.26,
          "text": " It's going to have capabilities that just emerge.",
          "tokens": [
            50728,
            467,
            311,
            516,
            281,
            362,
            10862,
            300,
            445,
            21511,
            13,
            50852
          ],
          "temperature": 0.0,
          "avg_logprob": -0.20772009236471994,
          "compression_ratio": 1.364963503649635,
          "no_speech_prob": 0.16447502374649048
        }
      ],
      "language": "en"
    },
    {
      "text": " Yeah, well, I have to admit that I was not at all impressed by the unicorn story. And in fact, that's why I was skeptical. I was like, this is clearly cherry picked and it's like, you know, from a fairy tale and you put anything else in.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 3.2,
          "text": " Yeah, well, I have to admit that I was not at all impressed by the unicorn story.",
          "tokens": [
            50364,
            865,
            11,
            731,
            11,
            286,
            362,
            281,
            9796,
            300,
            286,
            390,
            406,
            412,
            439,
            11679,
            538,
            264,
            28122,
            1657,
            13,
            50524
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3047746490029728,
          "compression_ratio": 1.4363636363636363,
          "no_speech_prob": 0.047859158366918564
        },
        {
          "id": 1,
          "seek": 0,
          "start": 3.2,
          "end": 4.8,
          "text": " And in fact, that's why I was skeptical.",
          "tokens": [
            50524,
            400,
            294,
            1186,
            11,
            300,
            311,
            983,
            286,
            390,
            28601,
            13,
            50604
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3047746490029728,
          "compression_ratio": 1.4363636363636363,
          "no_speech_prob": 0.047859158366918564
        },
        {
          "id": 2,
          "seek": 0,
          "start": 4.96,
          "end": 8.2,
          "text": " I was like, this is clearly cherry picked and it's like, you know, from a fairy",
          "tokens": [
            50612,
            286,
            390,
            411,
            11,
            341,
            307,
            4448,
            20164,
            6183,
            293,
            309,
            311,
            411,
            11,
            291,
            458,
            11,
            490,
            257,
            19104,
            50774
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3047746490029728,
          "compression_ratio": 1.4363636363636363,
          "no_speech_prob": 0.047859158366918564
        },
        {
          "id": 3,
          "seek": 0,
          "start": 8.2,
          "end": 9.36,
          "text": " tale and you put anything else in.",
          "tokens": [
            50774,
            17172,
            293,
            291,
            829,
            1340,
            1646,
            294,
            13,
            50832
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3047746490029728,
          "compression_ratio": 1.4363636363636363,
          "no_speech_prob": 0.047859158366918564
        }
      ],
      "language": "en"
    },
    {
      "text": " It's just not useful.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 2.0,
          "text": " It's just not useful.",
          "tokens": [
            50364,
            467,
            311,
            445,
            406,
            4420,
            13,
            50464
          ],
          "temperature": 0.0,
          "avg_logprob": -0.43248846795823837,
          "compression_ratio": 0.7241379310344828,
          "no_speech_prob": 0.001891060615889728
        }
      ],
      "language": "en"
    },
    {
      "text": " Well, when you do NLP, right, there's different kinds of tasks. Some tasks are easier to evaluate than others, like information extraction. Did you identify the right, that a company is an organization or is it a rock band or whatever? But if you are doing search, it's very hard to know if you have the best ranking in a lot of cases. Or if you're doing summarization, there are many legitimate ways to summarize a paper. And so it's really hard to evaluate summarization. And if you're generating a story, you can generate almost anything and it's a story. So this is why I was not at all impressed by the unicorn example, but it turned out that actually there was more behind it than the cherry picked example. Although GPT-3.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 2.36,
          "text": " Well, when you do NLP, right,",
          "tokens": [
            50364,
            1042,
            11,
            562,
            291,
            360,
            426,
            45196,
            11,
            558,
            11,
            50482
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19139962318616036,
          "compression_ratio": 1.7884615384615385,
          "no_speech_prob": 0.004068466834723949
        },
        {
          "id": 1,
          "seek": 0,
          "start": 2.36,
          "end": 3.56,
          "text": " there's different kinds of tasks.",
          "tokens": [
            50482,
            456,
            311,
            819,
            3685,
            295,
            9608,
            13,
            50542
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19139962318616036,
          "compression_ratio": 1.7884615384615385,
          "no_speech_prob": 0.004068466834723949
        },
        {
          "id": 2,
          "seek": 0,
          "start": 3.56,
          "end": 5.84,
          "text": " Some tasks are easier to evaluate than others,",
          "tokens": [
            50542,
            2188,
            9608,
            366,
            3571,
            281,
            13059,
            813,
            2357,
            11,
            50656
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19139962318616036,
          "compression_ratio": 1.7884615384615385,
          "no_speech_prob": 0.004068466834723949
        },
        {
          "id": 3,
          "seek": 0,
          "start": 5.84,
          "end": 7.12,
          "text": " like information extraction.",
          "tokens": [
            50656,
            411,
            1589,
            30197,
            13,
            50720
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19139962318616036,
          "compression_ratio": 1.7884615384615385,
          "no_speech_prob": 0.004068466834723949
        },
        {
          "id": 4,
          "seek": 0,
          "start": 7.12,
          "end": 8.76,
          "text": " Did you identify the right,",
          "tokens": [
            50720,
            2589,
            291,
            5876,
            264,
            558,
            11,
            50802
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19139962318616036,
          "compression_ratio": 1.7884615384615385,
          "no_speech_prob": 0.004068466834723949
        },
        {
          "id": 5,
          "seek": 0,
          "start": 8.76,
          "end": 10.4,
          "text": " that a company is an organization",
          "tokens": [
            50802,
            300,
            257,
            2237,
            307,
            364,
            4475,
            50884
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19139962318616036,
          "compression_ratio": 1.7884615384615385,
          "no_speech_prob": 0.004068466834723949
        },
        {
          "id": 6,
          "seek": 0,
          "start": 10.4,
          "end": 12.040000000000001,
          "text": " or is it a rock band or whatever?",
          "tokens": [
            50884,
            420,
            307,
            309,
            257,
            3727,
            4116,
            420,
            2035,
            30,
            50966
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19139962318616036,
          "compression_ratio": 1.7884615384615385,
          "no_speech_prob": 0.004068466834723949
        },
        {
          "id": 7,
          "seek": 0,
          "start": 12.040000000000001,
          "end": 14.16,
          "text": " But if you are doing search,",
          "tokens": [
            50966,
            583,
            498,
            291,
            366,
            884,
            3164,
            11,
            51072
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19139962318616036,
          "compression_ratio": 1.7884615384615385,
          "no_speech_prob": 0.004068466834723949
        },
        {
          "id": 8,
          "seek": 0,
          "start": 14.16,
          "end": 16.240000000000002,
          "text": " it's very hard to know if you have the best ranking",
          "tokens": [
            51072,
            309,
            311,
            588,
            1152,
            281,
            458,
            498,
            291,
            362,
            264,
            1151,
            17833,
            51176
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19139962318616036,
          "compression_ratio": 1.7884615384615385,
          "no_speech_prob": 0.004068466834723949
        },
        {
          "id": 9,
          "seek": 0,
          "start": 16.240000000000002,
          "end": 17.080000000000002,
          "text": " in a lot of cases.",
          "tokens": [
            51176,
            294,
            257,
            688,
            295,
            3331,
            13,
            51218
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19139962318616036,
          "compression_ratio": 1.7884615384615385,
          "no_speech_prob": 0.004068466834723949
        },
        {
          "id": 10,
          "seek": 0,
          "start": 17.080000000000002,
          "end": 18.56,
          "text": " Or if you're doing summarization,",
          "tokens": [
            51218,
            1610,
            498,
            291,
            434,
            884,
            14611,
            2144,
            11,
            51292
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19139962318616036,
          "compression_ratio": 1.7884615384615385,
          "no_speech_prob": 0.004068466834723949
        },
        {
          "id": 11,
          "seek": 0,
          "start": 18.56,
          "end": 21.56,
          "text": " there are many legitimate ways to summarize a paper.",
          "tokens": [
            51292,
            456,
            366,
            867,
            17956,
            2098,
            281,
            20858,
            257,
            3035,
            13,
            51442
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19139962318616036,
          "compression_ratio": 1.7884615384615385,
          "no_speech_prob": 0.004068466834723949
        },
        {
          "id": 12,
          "seek": 0,
          "start": 21.56,
          "end": 24.64,
          "text": " And so it's really hard to evaluate summarization.",
          "tokens": [
            51442,
            400,
            370,
            309,
            311,
            534,
            1152,
            281,
            13059,
            14611,
            2144,
            13,
            51596
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19139962318616036,
          "compression_ratio": 1.7884615384615385,
          "no_speech_prob": 0.004068466834723949
        },
        {
          "id": 13,
          "seek": 0,
          "start": 24.64,
          "end": 26.2,
          "text": " And if you're generating a story,",
          "tokens": [
            51596,
            400,
            498,
            291,
            434,
            17746,
            257,
            1657,
            11,
            51674
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19139962318616036,
          "compression_ratio": 1.7884615384615385,
          "no_speech_prob": 0.004068466834723949
        },
        {
          "id": 14,
          "seek": 0,
          "start": 26.2,
          "end": 28.8,
          "text": " you can generate almost anything and it's a story.",
          "tokens": [
            51674,
            291,
            393,
            8460,
            1920,
            1340,
            293,
            309,
            311,
            257,
            1657,
            13,
            51804
          ],
          "temperature": 0.0,
          "avg_logprob": -0.19139962318616036,
          "compression_ratio": 1.7884615384615385,
          "no_speech_prob": 0.004068466834723949
        },
        {
          "id": 15,
          "seek": 2880,
          "start": 28.84,
          "end": 30.92,
          "text": " So this is why I was not at all impressed",
          "tokens": [
            50366,
            407,
            341,
            307,
            983,
            286,
            390,
            406,
            412,
            439,
            11679,
            50470
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2823282747852559,
          "compression_ratio": 1.297709923664122,
          "no_speech_prob": 0.1365761011838913
        },
        {
          "id": 16,
          "seek": 2880,
          "start": 30.92,
          "end": 32.32,
          "text": " by the unicorn example,",
          "tokens": [
            50470,
            538,
            264,
            28122,
            1365,
            11,
            50540
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2823282747852559,
          "compression_ratio": 1.297709923664122,
          "no_speech_prob": 0.1365761011838913
        },
        {
          "id": 17,
          "seek": 2880,
          "start": 32.32,
          "end": 34.92,
          "text": " but it turned out that actually there was more behind it",
          "tokens": [
            50540,
            457,
            309,
            3574,
            484,
            300,
            767,
            456,
            390,
            544,
            2261,
            309,
            50670
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2823282747852559,
          "compression_ratio": 1.297709923664122,
          "no_speech_prob": 0.1365761011838913
        },
        {
          "id": 18,
          "seek": 2880,
          "start": 34.92,
          "end": 36.04,
          "text": " than the cherry picked example.",
          "tokens": [
            50670,
            813,
            264,
            20164,
            6183,
            1365,
            13,
            50726
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2823282747852559,
          "compression_ratio": 1.297709923664122,
          "no_speech_prob": 0.1365761011838913
        },
        {
          "id": 19,
          "seek": 2880,
          "start": 36.04,
          "end": 36.88,
          "text": " Although GPT-3.",
          "tokens": [
            50726,
            5780,
            26039,
            51,
            12,
            18,
            13,
            50768
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2823282747852559,
          "compression_ratio": 1.297709923664122,
          "no_speech_prob": 0.1365761011838913
        }
      ],
      "language": "en"
    },
    {
      "text": " I wasn't impressed with GPT-3 myself until the Instruct GPT version came out. And the thing actually did your bidding.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 4.68,
          "text": " I wasn't impressed with GPT-3 myself until the Instruct GPT version came out.",
          "tokens": [
            50364,
            286,
            2067,
            380,
            11679,
            365,
            26039,
            51,
            12,
            18,
            2059,
            1826,
            264,
            2730,
            1757,
            26039,
            51,
            3037,
            1361,
            484,
            13,
            50598
          ],
          "temperature": 0.0,
          "avg_logprob": -0.322757981040261,
          "compression_ratio": 1.1132075471698113,
          "no_speech_prob": 0.025615351274609566
        },
        {
          "id": 1,
          "seek": 0,
          "start": 4.68,
          "end": 6.2,
          "text": " And the thing actually did your bidding.",
          "tokens": [
            50598,
            400,
            264,
            551,
            767,
            630,
            428,
            39702,
            13,
            50674
          ],
          "temperature": 0.0,
          "avg_logprob": -0.322757981040261,
          "compression_ratio": 1.1132075471698113,
          "no_speech_prob": 0.025615351274609566
        }
      ],
      "language": "en"
    },
    {
      "text": " Yeah, well, they improved on it.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 2.8000000000000003,
          "text": " Yeah, well, they improved on it.",
          "tokens": [
            50364,
            865,
            11,
            731,
            11,
            436,
            9689,
            322,
            309,
            13,
            50504
          ],
          "temperature": 0.0,
          "avg_logprob": -0.4807928005854289,
          "compression_ratio": 0.8,
          "no_speech_prob": 0.00015242822701111436
        }
      ],
      "language": "en"
    },
    {
      "text": " Yeah, they really improved on it.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 1.6,
          "text": " Yeah, they really improved on it.",
          "tokens": [
            50364,
            865,
            11,
            436,
            534,
            9689,
            322,
            309,
            13,
            50444
          ],
          "temperature": 0.0,
          "avg_logprob": -0.4258688579906117,
          "compression_ratio": 0.8048780487804879,
          "no_speech_prob": 0.0003505077329464257
        }
      ],
      "language": "en"
    },
    {
      "text": " The problem is initially they were hyping it in ways that weren't helpful. And I know that now they're being more careful. I mean, open AI. So, or maybe they did have more behind the scene. They kind of said, oh, well, we know stuff that you don't know, and we can't share it. So you want to see, you want everyone to be able to test things. You know, that's what happened with the fake blood testing company and all that. It was clear from the beginning it was fraud. So you have to, if you're going to make big claims, you need to be able to show your cards.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 4.0,
          "text": " The problem is initially they were hyping it in ways that weren't helpful.",
          "tokens": [
            50364,
            440,
            1154,
            307,
            9105,
            436,
            645,
            2477,
            3381,
            309,
            294,
            2098,
            300,
            4999,
            380,
            4961,
            13,
            50564
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3086703862899389,
          "compression_ratio": 1.755485893416928,
          "no_speech_prob": 1.3624722669192124e-05
        },
        {
          "id": 1,
          "seek": 0,
          "start": 4.0,
          "end": 6.12,
          "text": " And I know that now they're being more careful.",
          "tokens": [
            50564,
            400,
            286,
            458,
            300,
            586,
            436,
            434,
            885,
            544,
            5026,
            13,
            50670
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3086703862899389,
          "compression_ratio": 1.755485893416928,
          "no_speech_prob": 1.3624722669192124e-05
        },
        {
          "id": 2,
          "seek": 0,
          "start": 6.12,
          "end": 7.24,
          "text": " I mean, open AI.",
          "tokens": [
            50670,
            286,
            914,
            11,
            1269,
            7318,
            13,
            50726
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3086703862899389,
          "compression_ratio": 1.755485893416928,
          "no_speech_prob": 1.3624722669192124e-05
        },
        {
          "id": 3,
          "seek": 0,
          "start": 7.24,
          "end": 9.64,
          "text": " So, or maybe they did have more behind the scene.",
          "tokens": [
            50726,
            407,
            11,
            420,
            1310,
            436,
            630,
            362,
            544,
            2261,
            264,
            4145,
            13,
            50846
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3086703862899389,
          "compression_ratio": 1.755485893416928,
          "no_speech_prob": 1.3624722669192124e-05
        },
        {
          "id": 4,
          "seek": 0,
          "start": 9.64,
          "end": 12.56,
          "text": " They kind of said, oh, well, we know stuff that you don't know, and we can't share it.",
          "tokens": [
            50846,
            814,
            733,
            295,
            848,
            11,
            1954,
            11,
            731,
            11,
            321,
            458,
            1507,
            300,
            291,
            500,
            380,
            458,
            11,
            293,
            321,
            393,
            380,
            2073,
            309,
            13,
            50992
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3086703862899389,
          "compression_ratio": 1.755485893416928,
          "no_speech_prob": 1.3624722669192124e-05
        },
        {
          "id": 5,
          "seek": 0,
          "start": 12.56,
          "end": 15.56,
          "text": " So you want to see, you want everyone to be able to test things.",
          "tokens": [
            50992,
            407,
            291,
            528,
            281,
            536,
            11,
            291,
            528,
            1518,
            281,
            312,
            1075,
            281,
            1500,
            721,
            13,
            51142
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3086703862899389,
          "compression_ratio": 1.755485893416928,
          "no_speech_prob": 1.3624722669192124e-05
        },
        {
          "id": 6,
          "seek": 0,
          "start": 15.56,
          "end": 20.080000000000002,
          "text": " You know, that's what happened with the fake blood testing company and all that.",
          "tokens": [
            51142,
            509,
            458,
            11,
            300,
            311,
            437,
            2011,
            365,
            264,
            7592,
            3390,
            4997,
            2237,
            293,
            439,
            300,
            13,
            51368
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3086703862899389,
          "compression_ratio": 1.755485893416928,
          "no_speech_prob": 1.3624722669192124e-05
        },
        {
          "id": 7,
          "seek": 0,
          "start": 20.080000000000002,
          "end": 21.88,
          "text": " It was clear from the beginning it was fraud.",
          "tokens": [
            51368,
            467,
            390,
            1850,
            490,
            264,
            2863,
            309,
            390,
            14560,
            13,
            51458
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3086703862899389,
          "compression_ratio": 1.755485893416928,
          "no_speech_prob": 1.3624722669192124e-05
        },
        {
          "id": 8,
          "seek": 0,
          "start": 21.88,
          "end": 26.400000000000002,
          "text": " So you have to, if you're going to make big claims, you need to be able to show your cards.",
          "tokens": [
            51458,
            407,
            291,
            362,
            281,
            11,
            498,
            291,
            434,
            516,
            281,
            652,
            955,
            9441,
            11,
            291,
            643,
            281,
            312,
            1075,
            281,
            855,
            428,
            5632,
            13,
            51684
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3086703862899389,
          "compression_ratio": 1.755485893416928,
          "no_speech_prob": 1.3624722669192124e-05
        }
      ],
      "language": "en"
    },
    {
      "text": " and all that.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 0.84,
          "text": " and all that.",
          "tokens": [
            50364,
            293,
            439,
            300,
            13,
            50406
          ],
          "temperature": 0.0,
          "avg_logprob": -0.6088647161211286,
          "compression_ratio": 0.6190476190476191,
          "no_speech_prob": 0.5583983659744263
        }
      ],
      "language": "en"
    },
    {
      "text": " Yep. All right. So zooming out a bit, what do you think is going to be the most exciting things to pay attention to on the research side of your fields? You really have more than one field, but I'd love to just hear your thought. What's what's in your mind these days, given this kind of big sea change as you describe it, which I agree.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 2.72,
          "text": " Yep. All right. So zooming out a bit,",
          "tokens": [
            50364,
            7010,
            13,
            1057,
            558,
            13,
            407,
            48226,
            484,
            257,
            857,
            11,
            50500
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2568112456280252,
          "compression_ratio": 1.5248868778280542,
          "no_speech_prob": 0.0035306205973029137
        },
        {
          "id": 1,
          "seek": 0,
          "start": 3.12,
          "end": 7.640000000000001,
          "text": " what do you think is going to be the most exciting things to pay attention",
          "tokens": [
            50520,
            437,
            360,
            291,
            519,
            307,
            516,
            281,
            312,
            264,
            881,
            4670,
            721,
            281,
            1689,
            3202,
            50746
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2568112456280252,
          "compression_ratio": 1.5248868778280542,
          "no_speech_prob": 0.0035306205973029137
        },
        {
          "id": 2,
          "seek": 0,
          "start": 7.640000000000001,
          "end": 11.48,
          "text": " to on the research side of your fields?",
          "tokens": [
            50746,
            281,
            322,
            264,
            2132,
            1252,
            295,
            428,
            7909,
            30,
            50938
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2568112456280252,
          "compression_ratio": 1.5248868778280542,
          "no_speech_prob": 0.0035306205973029137
        },
        {
          "id": 3,
          "seek": 0,
          "start": 11.8,
          "end": 14.56,
          "text": " You really have more than one field, but I'd love to just hear your thought.",
          "tokens": [
            50954,
            509,
            534,
            362,
            544,
            813,
            472,
            2519,
            11,
            457,
            286,
            1116,
            959,
            281,
            445,
            1568,
            428,
            1194,
            13,
            51092
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2568112456280252,
          "compression_ratio": 1.5248868778280542,
          "no_speech_prob": 0.0035306205973029137
        },
        {
          "id": 4,
          "seek": 0,
          "start": 14.56,
          "end": 16.36,
          "text": " What's what's in your mind these days,",
          "tokens": [
            51092,
            708,
            311,
            437,
            311,
            294,
            428,
            1575,
            613,
            1708,
            11,
            51182
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2568112456280252,
          "compression_ratio": 1.5248868778280542,
          "no_speech_prob": 0.0035306205973029137
        },
        {
          "id": 5,
          "seek": 0,
          "start": 16.44,
          "end": 20.68,
          "text": " given this kind of big sea change as you describe it, which I agree.",
          "tokens": [
            51186,
            2212,
            341,
            733,
            295,
            955,
            4158,
            1319,
            382,
            291,
            6786,
            309,
            11,
            597,
            286,
            3986,
            13,
            51398
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2568112456280252,
          "compression_ratio": 1.5248868778280542,
          "no_speech_prob": 0.0035306205973029137
        }
      ],
      "language": "en"
    },
    {
      "text": " Well, there's a lot of people doing a lot of stuff. So there's a lot of people really interested in AI safety and AI anti-bias, all very important. I think there's also a lot of people looking at the AI human interface, which is something I've been interested for a long time, and that's super important. People doing driving car, self-driving cars have a bit of a headstart, mainly on seeing how hard the problem is. Actually, I had a PhD student, Cecilia Aragon, who looked at projecting LiDAR visualizations for helicopter pilots on the screen, and how could we make that work and have them not crash? Because this could show them, if say a squall was ahead and they might potentially crash if they went into it. And we found that the simplest, most bare bones interface was the very best so that they weren't distracted. So I've always had questions about self-driving cars and that problem of the attention of the driver, and that's really not solved. And the studies I have seen on automatically generated language and interfaces, even some we've done in the Scholarfy, Semantic Scholar project, Semantic Reader project, we don't have good answers for that. People just start to rely on the automatically generated output. It's natural. And so that's a huge problem that needs to be solved.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 1.6400000000000001,
          "text": " Well, there's a lot of people doing a lot of stuff.",
          "tokens": [
            50364,
            1042,
            11,
            456,
            311,
            257,
            688,
            295,
            561,
            884,
            257,
            688,
            295,
            1507,
            13,
            50446
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2449994150797526,
          "compression_ratio": 1.7680250783699059,
          "no_speech_prob": 0.004750284366309643
        },
        {
          "id": 1,
          "seek": 0,
          "start": 1.6400000000000001,
          "end": 4.84,
          "text": " So there's a lot of people really interested in AI safety and AI",
          "tokens": [
            50446,
            407,
            456,
            311,
            257,
            688,
            295,
            561,
            534,
            3102,
            294,
            7318,
            4514,
            293,
            7318,
            50606
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2449994150797526,
          "compression_ratio": 1.7680250783699059,
          "no_speech_prob": 0.004750284366309643
        },
        {
          "id": 2,
          "seek": 0,
          "start": 5.08,
          "end": 7.0,
          "text": " anti-bias, all very important.",
          "tokens": [
            50618,
            6061,
            12,
            65,
            4609,
            11,
            439,
            588,
            1021,
            13,
            50714
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2449994150797526,
          "compression_ratio": 1.7680250783699059,
          "no_speech_prob": 0.004750284366309643
        },
        {
          "id": 3,
          "seek": 0,
          "start": 7.28,
          "end": 10.52,
          "text": " I think there's also a lot of people looking at the AI human interface, which",
          "tokens": [
            50728,
            286,
            519,
            456,
            311,
            611,
            257,
            688,
            295,
            561,
            1237,
            412,
            264,
            7318,
            1952,
            9226,
            11,
            597,
            50890
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2449994150797526,
          "compression_ratio": 1.7680250783699059,
          "no_speech_prob": 0.004750284366309643
        },
        {
          "id": 4,
          "seek": 0,
          "start": 10.52,
          "end": 13.92,
          "text": " is something I've been interested for a long time, and that's super important.",
          "tokens": [
            50890,
            307,
            746,
            286,
            600,
            668,
            3102,
            337,
            257,
            938,
            565,
            11,
            293,
            300,
            311,
            1687,
            1021,
            13,
            51060
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2449994150797526,
          "compression_ratio": 1.7680250783699059,
          "no_speech_prob": 0.004750284366309643
        },
        {
          "id": 5,
          "seek": 0,
          "start": 14.08,
          "end": 18.12,
          "text": " People doing driving car, self-driving cars have a bit of a headstart, mainly",
          "tokens": [
            51068,
            3432,
            884,
            4840,
            1032,
            11,
            2698,
            12,
            47094,
            5163,
            362,
            257,
            857,
            295,
            257,
            1378,
            24419,
            11,
            8704,
            51270
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2449994150797526,
          "compression_ratio": 1.7680250783699059,
          "no_speech_prob": 0.004750284366309643
        },
        {
          "id": 6,
          "seek": 0,
          "start": 18.12,
          "end": 19.68,
          "text": " on seeing how hard the problem is.",
          "tokens": [
            51270,
            322,
            2577,
            577,
            1152,
            264,
            1154,
            307,
            13,
            51348
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2449994150797526,
          "compression_ratio": 1.7680250783699059,
          "no_speech_prob": 0.004750284366309643
        },
        {
          "id": 7,
          "seek": 0,
          "start": 19.84,
          "end": 24.16,
          "text": " Actually, I had a PhD student, Cecilia Aragon, who looked at projecting",
          "tokens": [
            51356,
            5135,
            11,
            286,
            632,
            257,
            14476,
            3107,
            11,
            38807,
            24169,
            316,
            25997,
            11,
            567,
            2956,
            412,
            43001,
            51572
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2449994150797526,
          "compression_ratio": 1.7680250783699059,
          "no_speech_prob": 0.004750284366309643
        },
        {
          "id": 8,
          "seek": 0,
          "start": 24.16,
          "end": 28.32,
          "text": " LiDAR visualizations for helicopter pilots on the screen, and how could we",
          "tokens": [
            51572,
            8349,
            35,
            1899,
            5056,
            14455,
            337,
            19803,
            21506,
            322,
            264,
            2568,
            11,
            293,
            577,
            727,
            321,
            51780
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2449994150797526,
          "compression_ratio": 1.7680250783699059,
          "no_speech_prob": 0.004750284366309643
        },
        {
          "id": 9,
          "seek": 2832,
          "start": 28.32,
          "end": 30.48,
          "text": " make that work and have them not crash?",
          "tokens": [
            50364,
            652,
            300,
            589,
            293,
            362,
            552,
            406,
            8252,
            30,
            50472
          ],
          "temperature": 0.0,
          "avg_logprob": -0.30110068070261103,
          "compression_ratio": 1.7124600638977636,
          "no_speech_prob": 0.05663055554032326
        },
        {
          "id": 10,
          "seek": 2832,
          "start": 30.560000000000002,
          "end": 33.56,
          "text": " Because this could show them, if say a squall was ahead and they might",
          "tokens": [
            50476,
            1436,
            341,
            727,
            855,
            552,
            11,
            498,
            584,
            257,
            2339,
            336,
            390,
            2286,
            293,
            436,
            1062,
            50626
          ],
          "temperature": 0.0,
          "avg_logprob": -0.30110068070261103,
          "compression_ratio": 1.7124600638977636,
          "no_speech_prob": 0.05663055554032326
        },
        {
          "id": 11,
          "seek": 2832,
          "start": 33.72,
          "end": 35.8,
          "text": " potentially crash if they went into it.",
          "tokens": [
            50634,
            7263,
            8252,
            498,
            436,
            1437,
            666,
            309,
            13,
            50738
          ],
          "temperature": 0.0,
          "avg_logprob": -0.30110068070261103,
          "compression_ratio": 1.7124600638977636,
          "no_speech_prob": 0.05663055554032326
        },
        {
          "id": 12,
          "seek": 2832,
          "start": 35.92,
          "end": 39.44,
          "text": " And we found that the simplest, most bare bones interface was the very",
          "tokens": [
            50744,
            400,
            321,
            1352,
            300,
            264,
            22811,
            11,
            881,
            6949,
            10491,
            9226,
            390,
            264,
            588,
            50920
          ],
          "temperature": 0.0,
          "avg_logprob": -0.30110068070261103,
          "compression_ratio": 1.7124600638977636,
          "no_speech_prob": 0.05663055554032326
        },
        {
          "id": 13,
          "seek": 2832,
          "start": 39.44,
          "end": 40.96,
          "text": " best so that they weren't distracted.",
          "tokens": [
            50920,
            1151,
            370,
            300,
            436,
            4999,
            380,
            21658,
            13,
            50996
          ],
          "temperature": 0.0,
          "avg_logprob": -0.30110068070261103,
          "compression_ratio": 1.7124600638977636,
          "no_speech_prob": 0.05663055554032326
        },
        {
          "id": 14,
          "seek": 2832,
          "start": 41.24,
          "end": 45.2,
          "text": " So I've always had questions about self-driving cars and that problem of",
          "tokens": [
            51010,
            407,
            286,
            600,
            1009,
            632,
            1651,
            466,
            2698,
            12,
            47094,
            5163,
            293,
            300,
            1154,
            295,
            51208
          ],
          "temperature": 0.0,
          "avg_logprob": -0.30110068070261103,
          "compression_ratio": 1.7124600638977636,
          "no_speech_prob": 0.05663055554032326
        },
        {
          "id": 15,
          "seek": 2832,
          "start": 45.32,
          "end": 48.760000000000005,
          "text": " the attention of the driver, and that's really not solved.",
          "tokens": [
            51214,
            264,
            3202,
            295,
            264,
            6787,
            11,
            293,
            300,
            311,
            534,
            406,
            13041,
            13,
            51386
          ],
          "temperature": 0.0,
          "avg_logprob": -0.30110068070261103,
          "compression_ratio": 1.7124600638977636,
          "no_speech_prob": 0.05663055554032326
        },
        {
          "id": 16,
          "seek": 2832,
          "start": 48.879999999999995,
          "end": 53.120000000000005,
          "text": " And the studies I have seen on automatically generated language and",
          "tokens": [
            51392,
            400,
            264,
            5313,
            286,
            362,
            1612,
            322,
            6772,
            10833,
            2856,
            293,
            51604
          ],
          "temperature": 0.0,
          "avg_logprob": -0.30110068070261103,
          "compression_ratio": 1.7124600638977636,
          "no_speech_prob": 0.05663055554032326
        },
        {
          "id": 17,
          "seek": 2832,
          "start": 53.120000000000005,
          "end": 57.32,
          "text": " interfaces, even some we've done in the Scholarfy, Semantic Scholar project,",
          "tokens": [
            51604,
            28416,
            11,
            754,
            512,
            321,
            600,
            1096,
            294,
            264,
            2065,
            15276,
            22522,
            11,
            14421,
            7128,
            2065,
            15276,
            1716,
            11,
            51814
          ],
          "temperature": 0.0,
          "avg_logprob": -0.30110068070261103,
          "compression_ratio": 1.7124600638977636,
          "no_speech_prob": 0.05663055554032326
        },
        {
          "id": 18,
          "seek": 5732,
          "start": 57.52,
          "end": 61.12,
          "text": " Semantic Reader project, we don't have good answers for that.",
          "tokens": [
            50374,
            14421,
            7128,
            1300,
            8312,
            1716,
            11,
            321,
            500,
            380,
            362,
            665,
            6338,
            337,
            300,
            13,
            50554
          ],
          "temperature": 0.0,
          "avg_logprob": -0.20675340065589318,
          "compression_ratio": 1.3472222222222223,
          "no_speech_prob": 3.26938352372963e-05
        },
        {
          "id": 19,
          "seek": 5732,
          "start": 61.12,
          "end": 64.76,
          "text": " People just start to rely on the automatically generated output.",
          "tokens": [
            50554,
            3432,
            445,
            722,
            281,
            10687,
            322,
            264,
            6772,
            10833,
            5598,
            13,
            50736
          ],
          "temperature": 0.0,
          "avg_logprob": -0.20675340065589318,
          "compression_ratio": 1.3472222222222223,
          "no_speech_prob": 3.26938352372963e-05
        },
        {
          "id": 20,
          "seek": 5732,
          "start": 64.92,
          "end": 65.8,
          "text": " It's natural.",
          "tokens": [
            50744,
            467,
            311,
            3303,
            13,
            50788
          ],
          "temperature": 0.0,
          "avg_logprob": -0.20675340065589318,
          "compression_ratio": 1.3472222222222223,
          "no_speech_prob": 3.26938352372963e-05
        },
        {
          "id": 21,
          "seek": 5732,
          "start": 66.08,
          "end": 69.4,
          "text": " And so that's a huge problem that needs to be solved.",
          "tokens": [
            50802,
            400,
            370,
            300,
            311,
            257,
            2603,
            1154,
            300,
            2203,
            281,
            312,
            13041,
            13,
            50968
          ],
          "temperature": 0.0,
          "avg_logprob": -0.20675340065589318,
          "compression_ratio": 1.3472222222222223,
          "no_speech_prob": 3.26938352372963e-05
        }
      ],
      "language": "en"
    },
    {
      "text": " Text, please.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 0.84,
          "text": " Text, please.",
          "tokens": [
            50364,
            18643,
            11,
            1767,
            13,
            50406
          ],
          "temperature": 0.0,
          "avg_logprob": -0.9288266045706612,
          "compression_ratio": 0.6190476190476191,
          "no_speech_prob": 0.45810747146606445
        }
      ],
      "language": "en"
    },
    {
      "text": " What are some of the ways that we could help people if everyone comes to rely on Chat GPT for day-to-day work? What are some of the levers we can pull to help them?",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 3.88,
          "text": " What are some of the ways that we could help people if everyone comes to rely on",
          "tokens": [
            50364,
            708,
            366,
            512,
            295,
            264,
            2098,
            300,
            321,
            727,
            854,
            561,
            498,
            1518,
            1487,
            281,
            10687,
            322,
            50558
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2918679515520732,
          "compression_ratio": 1.3666666666666667,
          "no_speech_prob": 0.0026900183875113726
        },
        {
          "id": 1,
          "seek": 0,
          "start": 3.88,
          "end": 6.9,
          "text": " Chat GPT for day-to-day work?",
          "tokens": [
            50558,
            27503,
            26039,
            51,
            337,
            786,
            12,
            1353,
            12,
            810,
            589,
            30,
            50709
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2918679515520732,
          "compression_ratio": 1.3666666666666667,
          "no_speech_prob": 0.0026900183875113726
        },
        {
          "id": 2,
          "seek": 0,
          "start": 7.2,
          "end": 9.88,
          "text": " What are some of the levers we can pull to help them?",
          "tokens": [
            50724,
            708,
            366,
            512,
            295,
            264,
            45571,
            321,
            393,
            2235,
            281,
            854,
            552,
            30,
            50858
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2918679515520732,
          "compression_ratio": 1.3666666666666667,
          "no_speech_prob": 0.0026900183875113726
        }
      ],
      "language": "en"
    },
    {
      "text": " I haven't solved this problem. I mean, it's certainly good user interface design, understanding people. So HCI shows us how to study people and how they work and how they work with technology. So using HCI methods to deeply study that and in different contexts, it's different in a medical setting. There's a colleague that Ilifar Salehi here at the iSchool at Berkeley, who is looking at machine translation in a medical setting and when information is not translated correctly and how that can adversely impact marginalized communities when the translation isn't really the right thing and how to get the context right. So I think each setting is probably going to need some specialized research. And furthermore, one of your podcasts is about how do people inject poison, the training data and so on. And so you're gonna have to be very careful about attacks like that. It's not a field that I'm in. Perhaps it'll be important to have diversification in the different models so that there's ways to check them, make sure that they are safe and appropriate for a particular use. I think the techniques of HCI and ethnography really work independent of the context. It's not AI. People in AI don't necessarily want to sit down with people, humans, and see their details and what they do and so on. But that's the only way to have really working systems that are good for society.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 1.72,
          "text": " I haven't solved this problem.",
          "tokens": [
            50364,
            286,
            2378,
            380,
            13041,
            341,
            1154,
            13,
            50450
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25510884160580843,
          "compression_ratio": 1.7194244604316546,
          "no_speech_prob": 0.018518270924687386
        },
        {
          "id": 1,
          "seek": 0,
          "start": 1.72,
          "end": 5.64,
          "text": " I mean, it's certainly good user interface design, understanding people.",
          "tokens": [
            50450,
            286,
            914,
            11,
            309,
            311,
            3297,
            665,
            4195,
            9226,
            1715,
            11,
            3701,
            561,
            13,
            50646
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25510884160580843,
          "compression_ratio": 1.7194244604316546,
          "no_speech_prob": 0.018518270924687386
        },
        {
          "id": 2,
          "seek": 0,
          "start": 5.64,
          "end": 10.66,
          "text": " So HCI shows us how to study people and how they work and how they work with technology.",
          "tokens": [
            50646,
            407,
            389,
            25240,
            3110,
            505,
            577,
            281,
            2979,
            561,
            293,
            577,
            436,
            589,
            293,
            577,
            436,
            589,
            365,
            2899,
            13,
            50897
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25510884160580843,
          "compression_ratio": 1.7194244604316546,
          "no_speech_prob": 0.018518270924687386
        },
        {
          "id": 3,
          "seek": 0,
          "start": 10.66,
          "end": 15.860000000000001,
          "text": " So using HCI methods to deeply study that and in different contexts, it's different",
          "tokens": [
            50897,
            407,
            1228,
            389,
            25240,
            7150,
            281,
            8760,
            2979,
            300,
            293,
            294,
            819,
            30628,
            11,
            309,
            311,
            819,
            51157
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25510884160580843,
          "compression_ratio": 1.7194244604316546,
          "no_speech_prob": 0.018518270924687386
        },
        {
          "id": 4,
          "seek": 0,
          "start": 15.860000000000001,
          "end": 16.86,
          "text": " in a medical setting.",
          "tokens": [
            51157,
            294,
            257,
            4625,
            3287,
            13,
            51207
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25510884160580843,
          "compression_ratio": 1.7194244604316546,
          "no_speech_prob": 0.018518270924687386
        },
        {
          "id": 5,
          "seek": 0,
          "start": 16.86,
          "end": 21.400000000000002,
          "text": " There's a colleague that Ilifar Salehi here at the iSchool at Berkeley, who is looking",
          "tokens": [
            51207,
            821,
            311,
            257,
            13532,
            300,
            4416,
            351,
            289,
            48922,
            4954,
            510,
            412,
            264,
            741,
            50,
            21856,
            412,
            23684,
            11,
            567,
            307,
            1237,
            51434
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25510884160580843,
          "compression_ratio": 1.7194244604316546,
          "no_speech_prob": 0.018518270924687386
        },
        {
          "id": 6,
          "seek": 0,
          "start": 21.400000000000002,
          "end": 26.66,
          "text": " at machine translation in a medical setting and when information is not translated correctly",
          "tokens": [
            51434,
            412,
            3479,
            12853,
            294,
            257,
            4625,
            3287,
            293,
            562,
            1589,
            307,
            406,
            16805,
            8944,
            51697
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25510884160580843,
          "compression_ratio": 1.7194244604316546,
          "no_speech_prob": 0.018518270924687386
        },
        {
          "id": 7,
          "seek": 2666,
          "start": 26.66,
          "end": 31.9,
          "text": " and how that can adversely impact marginalized communities when the translation isn't really",
          "tokens": [
            50364,
            293,
            577,
            300,
            393,
            17641,
            736,
            2712,
            32522,
            4456,
            562,
            264,
            12853,
            1943,
            380,
            534,
            50626
          ],
          "temperature": 0.0,
          "avg_logprob": -0.23137301783407888,
          "compression_ratio": 1.6634615384615385,
          "no_speech_prob": 0.2450091391801834
        },
        {
          "id": 8,
          "seek": 2666,
          "start": 31.9,
          "end": 34.5,
          "text": " the right thing and how to get the context right.",
          "tokens": [
            50626,
            264,
            558,
            551,
            293,
            577,
            281,
            483,
            264,
            4319,
            558,
            13,
            50756
          ],
          "temperature": 0.0,
          "avg_logprob": -0.23137301783407888,
          "compression_ratio": 1.6634615384615385,
          "no_speech_prob": 0.2450091391801834
        },
        {
          "id": 9,
          "seek": 2666,
          "start": 34.5,
          "end": 39.06,
          "text": " So I think each setting is probably going to need some specialized research.",
          "tokens": [
            50756,
            407,
            286,
            519,
            1184,
            3287,
            307,
            1391,
            516,
            281,
            643,
            512,
            19813,
            2132,
            13,
            50984
          ],
          "temperature": 0.0,
          "avg_logprob": -0.23137301783407888,
          "compression_ratio": 1.6634615384615385,
          "no_speech_prob": 0.2450091391801834
        },
        {
          "id": 10,
          "seek": 2666,
          "start": 39.06,
          "end": 44.1,
          "text": " And furthermore, one of your podcasts is about how do people inject poison, the training",
          "tokens": [
            50984,
            400,
            3052,
            3138,
            11,
            472,
            295,
            428,
            24045,
            307,
            466,
            577,
            360,
            561,
            10711,
            10836,
            11,
            264,
            3097,
            51236
          ],
          "temperature": 0.0,
          "avg_logprob": -0.23137301783407888,
          "compression_ratio": 1.6634615384615385,
          "no_speech_prob": 0.2450091391801834
        },
        {
          "id": 11,
          "seek": 2666,
          "start": 44.1,
          "end": 45.1,
          "text": " data and so on.",
          "tokens": [
            51236,
            1412,
            293,
            370,
            322,
            13,
            51286
          ],
          "temperature": 0.0,
          "avg_logprob": -0.23137301783407888,
          "compression_ratio": 1.6634615384615385,
          "no_speech_prob": 0.2450091391801834
        },
        {
          "id": 12,
          "seek": 2666,
          "start": 45.1,
          "end": 47.7,
          "text": " And so you're gonna have to be very careful about attacks like that.",
          "tokens": [
            51286,
            400,
            370,
            291,
            434,
            799,
            362,
            281,
            312,
            588,
            5026,
            466,
            8122,
            411,
            300,
            13,
            51416
          ],
          "temperature": 0.0,
          "avg_logprob": -0.23137301783407888,
          "compression_ratio": 1.6634615384615385,
          "no_speech_prob": 0.2450091391801834
        },
        {
          "id": 13,
          "seek": 2666,
          "start": 47.7,
          "end": 48.900000000000006,
          "text": " It's not a field that I'm in.",
          "tokens": [
            51416,
            467,
            311,
            406,
            257,
            2519,
            300,
            286,
            478,
            294,
            13,
            51476
          ],
          "temperature": 0.0,
          "avg_logprob": -0.23137301783407888,
          "compression_ratio": 1.6634615384615385,
          "no_speech_prob": 0.2450091391801834
        },
        {
          "id": 14,
          "seek": 2666,
          "start": 48.900000000000006,
          "end": 52.94,
          "text": " Perhaps it'll be important to have diversification in the different models so that there's ways",
          "tokens": [
            51476,
            10517,
            309,
            603,
            312,
            1021,
            281,
            362,
            6111,
            3774,
            294,
            264,
            819,
            5245,
            370,
            300,
            456,
            311,
            2098,
            51678
          ],
          "temperature": 0.0,
          "avg_logprob": -0.23137301783407888,
          "compression_ratio": 1.6634615384615385,
          "no_speech_prob": 0.2450091391801834
        },
        {
          "id": 15,
          "seek": 5294,
          "start": 53.019999999999996,
          "end": 57.78,
          "text": " to check them, make sure that they are safe and appropriate for a particular use.",
          "tokens": [
            50368,
            281,
            1520,
            552,
            11,
            652,
            988,
            300,
            436,
            366,
            3273,
            293,
            6854,
            337,
            257,
            1729,
            764,
            13,
            50606
          ],
          "temperature": 0.0,
          "avg_logprob": -0.236010213692983,
          "compression_ratio": 1.594142259414226,
          "no_speech_prob": 0.02475874312222004
        },
        {
          "id": 16,
          "seek": 5294,
          "start": 57.78,
          "end": 63.66,
          "text": " I think the techniques of HCI and ethnography really work independent of the context.",
          "tokens": [
            50606,
            286,
            519,
            264,
            7512,
            295,
            389,
            25240,
            293,
            42589,
            5820,
            534,
            589,
            6695,
            295,
            264,
            4319,
            13,
            50900
          ],
          "temperature": 0.0,
          "avg_logprob": -0.236010213692983,
          "compression_ratio": 1.594142259414226,
          "no_speech_prob": 0.02475874312222004
        },
        {
          "id": 17,
          "seek": 5294,
          "start": 63.66,
          "end": 65.34,
          "text": " It's not AI.",
          "tokens": [
            50900,
            467,
            311,
            406,
            7318,
            13,
            50984
          ],
          "temperature": 0.0,
          "avg_logprob": -0.236010213692983,
          "compression_ratio": 1.594142259414226,
          "no_speech_prob": 0.02475874312222004
        },
        {
          "id": 18,
          "seek": 5294,
          "start": 65.34,
          "end": 70.82,
          "text": " People in AI don't necessarily want to sit down with people, humans, and see their details",
          "tokens": [
            50984,
            3432,
            294,
            7318,
            500,
            380,
            4725,
            528,
            281,
            1394,
            760,
            365,
            561,
            11,
            6255,
            11,
            293,
            536,
            641,
            4365,
            51258
          ],
          "temperature": 0.0,
          "avg_logprob": -0.236010213692983,
          "compression_ratio": 1.594142259414226,
          "no_speech_prob": 0.02475874312222004
        },
        {
          "id": 19,
          "seek": 5294,
          "start": 70.82,
          "end": 72.5,
          "text": " and what they do and so on.",
          "tokens": [
            51258,
            293,
            437,
            436,
            360,
            293,
            370,
            322,
            13,
            51342
          ],
          "temperature": 0.0,
          "avg_logprob": -0.236010213692983,
          "compression_ratio": 1.594142259414226,
          "no_speech_prob": 0.02475874312222004
        },
        {
          "id": 20,
          "seek": 5294,
          "start": 72.5,
          "end": 76.1,
          "text": " But that's the only way to have really working systems that are good for society.",
          "tokens": [
            51342,
            583,
            300,
            311,
            264,
            787,
            636,
            281,
            362,
            534,
            1364,
            3652,
            300,
            366,
            665,
            337,
            4086,
            13,
            51522
          ],
          "temperature": 0.0,
          "avg_logprob": -0.236010213692983,
          "compression_ratio": 1.594142259414226,
          "no_speech_prob": 0.02475874312222004
        }
      ],
      "language": "en"
    },
    {
      "text": " Yeah, I've noticed that there's this kind of mindset of people who build AI, generally people who build AI systems. It's the engineering mindset. The more you can take the person out of the equation, the better, because, you know, I want my development environment to be nice and clean and straightforward, and I want to build something that I understand. And as soon as you get people involved, oof, people are complicated. But what you're saying is you have to include the person.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 5.0,
          "text": " Yeah, I've noticed that there's this kind of mindset of people who build AI, generally",
          "tokens": [
            50364,
            865,
            11,
            286,
            600,
            5694,
            300,
            456,
            311,
            341,
            733,
            295,
            12543,
            295,
            561,
            567,
            1322,
            7318,
            11,
            5101,
            50614
          ],
          "temperature": 0.0,
          "avg_logprob": -0.26685323715209963,
          "compression_ratio": 1.7031802120141342,
          "no_speech_prob": 0.00015087572683114558
        },
        {
          "id": 1,
          "seek": 0,
          "start": 5.0,
          "end": 7.12,
          "text": " people who build AI systems.",
          "tokens": [
            50614,
            561,
            567,
            1322,
            7318,
            3652,
            13,
            50720
          ],
          "temperature": 0.0,
          "avg_logprob": -0.26685323715209963,
          "compression_ratio": 1.7031802120141342,
          "no_speech_prob": 0.00015087572683114558
        },
        {
          "id": 2,
          "seek": 0,
          "start": 7.12,
          "end": 9.32,
          "text": " It's the engineering mindset.",
          "tokens": [
            50720,
            467,
            311,
            264,
            7043,
            12543,
            13,
            50830
          ],
          "temperature": 0.0,
          "avg_logprob": -0.26685323715209963,
          "compression_ratio": 1.7031802120141342,
          "no_speech_prob": 0.00015087572683114558
        },
        {
          "id": 3,
          "seek": 0,
          "start": 9.32,
          "end": 12.8,
          "text": " The more you can take the person out of the equation, the better, because, you know, I",
          "tokens": [
            50830,
            440,
            544,
            291,
            393,
            747,
            264,
            954,
            484,
            295,
            264,
            5367,
            11,
            264,
            1101,
            11,
            570,
            11,
            291,
            458,
            11,
            286,
            51004
          ],
          "temperature": 0.0,
          "avg_logprob": -0.26685323715209963,
          "compression_ratio": 1.7031802120141342,
          "no_speech_prob": 0.00015087572683114558
        },
        {
          "id": 4,
          "seek": 0,
          "start": 12.8,
          "end": 16.2,
          "text": " want my development environment to be nice and clean and straightforward, and I want",
          "tokens": [
            51004,
            528,
            452,
            3250,
            2823,
            281,
            312,
            1481,
            293,
            2541,
            293,
            15325,
            11,
            293,
            286,
            528,
            51174
          ],
          "temperature": 0.0,
          "avg_logprob": -0.26685323715209963,
          "compression_ratio": 1.7031802120141342,
          "no_speech_prob": 0.00015087572683114558
        },
        {
          "id": 5,
          "seek": 0,
          "start": 16.2,
          "end": 17.2,
          "text": " to build something that I understand.",
          "tokens": [
            51174,
            281,
            1322,
            746,
            300,
            286,
            1223,
            13,
            51224
          ],
          "temperature": 0.0,
          "avg_logprob": -0.26685323715209963,
          "compression_ratio": 1.7031802120141342,
          "no_speech_prob": 0.00015087572683114558
        },
        {
          "id": 6,
          "seek": 0,
          "start": 17.2,
          "end": 21.68,
          "text": " And as soon as you get people involved, oof, people are complicated.",
          "tokens": [
            51224,
            400,
            382,
            2321,
            382,
            291,
            483,
            561,
            3288,
            11,
            277,
            2670,
            11,
            561,
            366,
            6179,
            13,
            51448
          ],
          "temperature": 0.0,
          "avg_logprob": -0.26685323715209963,
          "compression_ratio": 1.7031802120141342,
          "no_speech_prob": 0.00015087572683114558
        },
        {
          "id": 7,
          "seek": 0,
          "start": 21.68,
          "end": 23.8,
          "text": " But what you're saying is you have to include the person.",
          "tokens": [
            51448,
            583,
            437,
            291,
            434,
            1566,
            307,
            291,
            362,
            281,
            4090,
            264,
            954,
            13,
            51554
          ],
          "temperature": 0.0,
          "avg_logprob": -0.26685323715209963,
          "compression_ratio": 1.7031802120141342,
          "no_speech_prob": 0.00015087572683114558
        }
      ],
      "language": "en"
    },
    {
      "text": " Yeah, and that's why I'm heartened by the new interest in NLP plus HCI. I've given, you know, there's been workshops I've asked to talk at because I've been thinking about it for a long time. But it's true that a lot of people who are making the biggest advances in the NLP AI field are mathematicians or physicists, and it's just not what they think about. They like to think abstract way and and they're brilliant and they're really improving these systems. But we need teams to work on technology. No one, you know, this the one person band just doesn't exist in this space.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 4.12,
          "text": " Yeah, and that's why I'm heartened by the new interest in NLP plus HCI.",
          "tokens": [
            50364,
            865,
            11,
            293,
            300,
            311,
            983,
            286,
            478,
            1917,
            5320,
            538,
            264,
            777,
            1179,
            294,
            426,
            45196,
            1804,
            389,
            25240,
            13,
            50570
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2449555920016381,
          "compression_ratio": 1.7172619047619047,
          "no_speech_prob": 7.64519973017741e-06
        },
        {
          "id": 1,
          "seek": 0,
          "start": 4.12,
          "end": 6.72,
          "text": " I've given, you know, there's been workshops I've asked to talk at",
          "tokens": [
            50570,
            286,
            600,
            2212,
            11,
            291,
            458,
            11,
            456,
            311,
            668,
            19162,
            286,
            600,
            2351,
            281,
            751,
            412,
            50700
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2449555920016381,
          "compression_ratio": 1.7172619047619047,
          "no_speech_prob": 7.64519973017741e-06
        },
        {
          "id": 2,
          "seek": 0,
          "start": 6.72,
          "end": 8.92,
          "text": " because I've been thinking about it for a long time.",
          "tokens": [
            50700,
            570,
            286,
            600,
            668,
            1953,
            466,
            309,
            337,
            257,
            938,
            565,
            13,
            50810
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2449555920016381,
          "compression_ratio": 1.7172619047619047,
          "no_speech_prob": 7.64519973017741e-06
        },
        {
          "id": 3,
          "seek": 0,
          "start": 8.92,
          "end": 11.68,
          "text": " But it's true that a lot of people who are making the biggest advances",
          "tokens": [
            50810,
            583,
            309,
            311,
            2074,
            300,
            257,
            688,
            295,
            561,
            567,
            366,
            1455,
            264,
            3880,
            25297,
            50948
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2449555920016381,
          "compression_ratio": 1.7172619047619047,
          "no_speech_prob": 7.64519973017741e-06
        },
        {
          "id": 4,
          "seek": 0,
          "start": 11.68,
          "end": 15.48,
          "text": " in the NLP AI field are mathematicians or physicists,",
          "tokens": [
            50948,
            294,
            264,
            426,
            45196,
            7318,
            2519,
            366,
            32811,
            2567,
            420,
            48716,
            11,
            51138
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2449555920016381,
          "compression_ratio": 1.7172619047619047,
          "no_speech_prob": 7.64519973017741e-06
        },
        {
          "id": 5,
          "seek": 0,
          "start": 15.48,
          "end": 17.04,
          "text": " and it's just not what they think about.",
          "tokens": [
            51138,
            293,
            309,
            311,
            445,
            406,
            437,
            436,
            519,
            466,
            13,
            51216
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2449555920016381,
          "compression_ratio": 1.7172619047619047,
          "no_speech_prob": 7.64519973017741e-06
        },
        {
          "id": 6,
          "seek": 0,
          "start": 17.04,
          "end": 19.72,
          "text": " They like to think abstract way and and they're brilliant",
          "tokens": [
            51216,
            814,
            411,
            281,
            519,
            12649,
            636,
            293,
            293,
            436,
            434,
            10248,
            51350
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2449555920016381,
          "compression_ratio": 1.7172619047619047,
          "no_speech_prob": 7.64519973017741e-06
        },
        {
          "id": 7,
          "seek": 0,
          "start": 19.72,
          "end": 22.04,
          "text": " and they're really improving these systems.",
          "tokens": [
            51350,
            293,
            436,
            434,
            534,
            11470,
            613,
            3652,
            13,
            51466
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2449555920016381,
          "compression_ratio": 1.7172619047619047,
          "no_speech_prob": 7.64519973017741e-06
        },
        {
          "id": 8,
          "seek": 0,
          "start": 22.04,
          "end": 24.52,
          "text": " But we need teams to work on technology.",
          "tokens": [
            51466,
            583,
            321,
            643,
            5491,
            281,
            589,
            322,
            2899,
            13,
            51590
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2449555920016381,
          "compression_ratio": 1.7172619047619047,
          "no_speech_prob": 7.64519973017741e-06
        },
        {
          "id": 9,
          "seek": 0,
          "start": 24.52,
          "end": 28.96,
          "text": " No one, you know, this the one person band just doesn't exist in this space.",
          "tokens": [
            51590,
            883,
            472,
            11,
            291,
            458,
            11,
            341,
            264,
            472,
            954,
            4116,
            445,
            1177,
            380,
            2514,
            294,
            341,
            1901,
            13,
            51812
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2449555920016381,
          "compression_ratio": 1.7172619047619047,
          "no_speech_prob": 7.64519973017741e-06
        }
      ],
      "language": "en"
    },
    {
      "text": " So what would you say to students coming into these fields just now? Has the advice changed at all?",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 4.4,
          "text": " So what would you say to students coming into these fields just now?",
          "tokens": [
            50364,
            407,
            437,
            576,
            291,
            584,
            281,
            1731,
            1348,
            666,
            613,
            7909,
            445,
            586,
            30,
            50584
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3661917539743277,
          "compression_ratio": 1.125,
          "no_speech_prob": 0.0019803468603640795
        },
        {
          "id": 1,
          "seek": 0,
          "start": 4.6000000000000005,
          "end": 6.0,
          "text": " Has the advice changed at all?",
          "tokens": [
            50594,
            8646,
            264,
            5192,
            3105,
            412,
            439,
            30,
            50664
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3661917539743277,
          "compression_ratio": 1.125,
          "no_speech_prob": 0.0019803468603640795
        }
      ],
      "language": "en"
    },
    {
      "text": " It's hard to know what to say right now, it's moving so fast. What I say to all students is, what are you passionate about? What really interests you? Do that. Don't do the trendiest thing for its own sake. It's definitely a big question mark right now for research universities and AI labs, other research groups.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 2.84,
          "text": " It's hard to know what to say right now, it's moving so fast.",
          "tokens": [
            50364,
            467,
            311,
            1152,
            281,
            458,
            437,
            281,
            584,
            558,
            586,
            11,
            309,
            311,
            2684,
            370,
            2370,
            13,
            50506
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2745987204618232,
          "compression_ratio": 1.5317073170731708,
          "no_speech_prob": 0.00030482292640954256
        },
        {
          "id": 1,
          "seek": 0,
          "start": 2.84,
          "end": 5.68,
          "text": " What I say to all students is, what are you passionate about?",
          "tokens": [
            50506,
            708,
            286,
            584,
            281,
            439,
            1731,
            307,
            11,
            437,
            366,
            291,
            11410,
            466,
            30,
            50648
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2745987204618232,
          "compression_ratio": 1.5317073170731708,
          "no_speech_prob": 0.00030482292640954256
        },
        {
          "id": 2,
          "seek": 0,
          "start": 5.68,
          "end": 7.08,
          "text": " What really interests you?",
          "tokens": [
            50648,
            708,
            534,
            8847,
            291,
            30,
            50718
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2745987204618232,
          "compression_ratio": 1.5317073170731708,
          "no_speech_prob": 0.00030482292640954256
        },
        {
          "id": 3,
          "seek": 0,
          "start": 7.08,
          "end": 7.88,
          "text": " Do that.",
          "tokens": [
            50718,
            1144,
            300,
            13,
            50758
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2745987204618232,
          "compression_ratio": 1.5317073170731708,
          "no_speech_prob": 0.00030482292640954256
        },
        {
          "id": 4,
          "seek": 0,
          "start": 7.88,
          "end": 10.200000000000001,
          "text": " Don't do the trendiest thing for its own sake.",
          "tokens": [
            50758,
            1468,
            380,
            360,
            264,
            6028,
            6495,
            551,
            337,
            1080,
            1065,
            9717,
            13,
            50874
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2745987204618232,
          "compression_ratio": 1.5317073170731708,
          "no_speech_prob": 0.00030482292640954256
        },
        {
          "id": 5,
          "seek": 0,
          "start": 10.200000000000001,
          "end": 12.36,
          "text": " It's definitely a big question mark right now",
          "tokens": [
            50874,
            467,
            311,
            2138,
            257,
            955,
            1168,
            1491,
            558,
            586,
            50982
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2745987204618232,
          "compression_ratio": 1.5317073170731708,
          "no_speech_prob": 0.00030482292640954256
        },
        {
          "id": 6,
          "seek": 0,
          "start": 12.36,
          "end": 17.6,
          "text": " for research universities and AI labs, other research groups.",
          "tokens": [
            50982,
            337,
            2132,
            11779,
            293,
            7318,
            20339,
            11,
            661,
            2132,
            3935,
            13,
            51244
          ],
          "temperature": 0.0,
          "avg_logprob": -0.2745987204618232,
          "compression_ratio": 1.5317073170731708,
          "no_speech_prob": 0.00030482292640954256
        }
      ],
      "language": "en"
    },
    {
      "text": " If there's a big microscope that some people have and you don't, you know, how do you compete? And there's open source efforts, things that Hugging Face and others are doing. I think the government's, the US government's interested as well in giving everybody a microscope, meaning these large language models and the ability to run them. And I think that people are very aware of that issue. But then if you want to do advanced research on this, you know, you get brilliant people like Agent Choi at University of Washington and AI2 that are showing that you can do a lot with much less. You don't need to have all these parameters and so on. And that's where the university can help. The university people are also going to be looking at how do you save energy? Well, I mean, so is industry, but how do you save energy when you use these? It's very wasteful right now. These are all great areas for research. And of course, understanding what these models are doing, understanding the mind better. Can they help us understand the mind in some way? I'm sure psychologists are thinking about that. There's work already. I've seen work in linguistics on, say, using GANs and adversarial methods to model linguistics in other species. So there's always more research questions. And if you're interested in being in industry and business, then go do that. And if you're interested in research, then find a problem that just really interests you because that's how you can finish your PhD.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 4.28,
          "text": " If there's a big microscope that some people have and you don't, you know, how do you compete?",
          "tokens": [
            50364,
            759,
            456,
            311,
            257,
            955,
            29753,
            300,
            512,
            561,
            362,
            293,
            291,
            500,
            380,
            11,
            291,
            458,
            11,
            577,
            360,
            291,
            11831,
            30,
            50578
          ],
          "temperature": 0.0,
          "avg_logprob": -0.27499526451373923,
          "compression_ratio": 1.7345132743362832,
          "no_speech_prob": 0.031102152541279793
        },
        {
          "id": 1,
          "seek": 0,
          "start": 4.28,
          "end": 7.84,
          "text": " And there's open source efforts, things that Hugging Face and others are doing.",
          "tokens": [
            50578,
            400,
            456,
            311,
            1269,
            4009,
            6484,
            11,
            721,
            300,
            46892,
            3249,
            4047,
            293,
            2357,
            366,
            884,
            13,
            50756
          ],
          "temperature": 0.0,
          "avg_logprob": -0.27499526451373923,
          "compression_ratio": 1.7345132743362832,
          "no_speech_prob": 0.031102152541279793
        },
        {
          "id": 2,
          "seek": 0,
          "start": 7.84,
          "end": 13.120000000000001,
          "text": " I think the government's, the US government's interested as well in giving everybody a microscope,",
          "tokens": [
            50756,
            286,
            519,
            264,
            2463,
            311,
            11,
            264,
            2546,
            2463,
            311,
            3102,
            382,
            731,
            294,
            2902,
            2201,
            257,
            29753,
            11,
            51020
          ],
          "temperature": 0.0,
          "avg_logprob": -0.27499526451373923,
          "compression_ratio": 1.7345132743362832,
          "no_speech_prob": 0.031102152541279793
        },
        {
          "id": 3,
          "seek": 0,
          "start": 13.120000000000001,
          "end": 16.080000000000002,
          "text": " meaning these large language models and the ability to run them.",
          "tokens": [
            51020,
            3620,
            613,
            2416,
            2856,
            5245,
            293,
            264,
            3485,
            281,
            1190,
            552,
            13,
            51168
          ],
          "temperature": 0.0,
          "avg_logprob": -0.27499526451373923,
          "compression_ratio": 1.7345132743362832,
          "no_speech_prob": 0.031102152541279793
        },
        {
          "id": 4,
          "seek": 0,
          "start": 16.080000000000002,
          "end": 19.44,
          "text": " And I think that people are very aware of that issue.",
          "tokens": [
            51168,
            400,
            286,
            519,
            300,
            561,
            366,
            588,
            3650,
            295,
            300,
            2734,
            13,
            51336
          ],
          "temperature": 0.0,
          "avg_logprob": -0.27499526451373923,
          "compression_ratio": 1.7345132743362832,
          "no_speech_prob": 0.031102152541279793
        },
        {
          "id": 5,
          "seek": 0,
          "start": 19.44,
          "end": 23.0,
          "text": " But then if you want to do advanced research on this, you know, you get brilliant people",
          "tokens": [
            51336,
            583,
            550,
            498,
            291,
            528,
            281,
            360,
            7339,
            2132,
            322,
            341,
            11,
            291,
            458,
            11,
            291,
            483,
            10248,
            561,
            51514
          ],
          "temperature": 0.0,
          "avg_logprob": -0.27499526451373923,
          "compression_ratio": 1.7345132743362832,
          "no_speech_prob": 0.031102152541279793
        },
        {
          "id": 6,
          "seek": 0,
          "start": 23.0,
          "end": 27.400000000000002,
          "text": " like Agent Choi at University of Washington and AI2 that are showing that you can do a",
          "tokens": [
            51514,
            411,
            316,
            1766,
            83,
            33479,
            412,
            3535,
            295,
            6149,
            293,
            7318,
            17,
            300,
            366,
            4099,
            300,
            291,
            393,
            360,
            257,
            51734
          ],
          "temperature": 0.0,
          "avg_logprob": -0.27499526451373923,
          "compression_ratio": 1.7345132743362832,
          "no_speech_prob": 0.031102152541279793
        },
        {
          "id": 7,
          "seek": 0,
          "start": 27.400000000000002,
          "end": 28.76,
          "text": " lot with much less.",
          "tokens": [
            51734,
            688,
            365,
            709,
            1570,
            13,
            51802
          ],
          "temperature": 0.0,
          "avg_logprob": -0.27499526451373923,
          "compression_ratio": 1.7345132743362832,
          "no_speech_prob": 0.031102152541279793
        },
        {
          "id": 8,
          "seek": 2876,
          "start": 28.76,
          "end": 31.48,
          "text": " You don't need to have all these parameters and so on.",
          "tokens": [
            50364,
            509,
            500,
            380,
            643,
            281,
            362,
            439,
            613,
            9834,
            293,
            370,
            322,
            13,
            50500
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24687400873560106,
          "compression_ratio": 1.760797342192691,
          "no_speech_prob": 0.5037438273429871
        },
        {
          "id": 9,
          "seek": 2876,
          "start": 31.48,
          "end": 33.120000000000005,
          "text": " And that's where the university can help.",
          "tokens": [
            50500,
            400,
            300,
            311,
            689,
            264,
            5454,
            393,
            854,
            13,
            50582
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24687400873560106,
          "compression_ratio": 1.760797342192691,
          "no_speech_prob": 0.5037438273429871
        },
        {
          "id": 10,
          "seek": 2876,
          "start": 33.120000000000005,
          "end": 36.160000000000004,
          "text": " The university people are also going to be looking at how do you save energy?",
          "tokens": [
            50582,
            440,
            5454,
            561,
            366,
            611,
            516,
            281,
            312,
            1237,
            412,
            577,
            360,
            291,
            3155,
            2281,
            30,
            50734
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24687400873560106,
          "compression_ratio": 1.760797342192691,
          "no_speech_prob": 0.5037438273429871
        },
        {
          "id": 11,
          "seek": 2876,
          "start": 36.160000000000004,
          "end": 39.400000000000006,
          "text": " Well, I mean, so is industry, but how do you save energy when you use these?",
          "tokens": [
            50734,
            1042,
            11,
            286,
            914,
            11,
            370,
            307,
            3518,
            11,
            457,
            577,
            360,
            291,
            3155,
            2281,
            562,
            291,
            764,
            613,
            30,
            50896
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24687400873560106,
          "compression_ratio": 1.760797342192691,
          "no_speech_prob": 0.5037438273429871
        },
        {
          "id": 12,
          "seek": 2876,
          "start": 39.400000000000006,
          "end": 41.0,
          "text": " It's very wasteful right now.",
          "tokens": [
            50896,
            467,
            311,
            588,
            5964,
            906,
            558,
            586,
            13,
            50976
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24687400873560106,
          "compression_ratio": 1.760797342192691,
          "no_speech_prob": 0.5037438273429871
        },
        {
          "id": 13,
          "seek": 2876,
          "start": 41.0,
          "end": 43.08,
          "text": " These are all great areas for research.",
          "tokens": [
            50976,
            1981,
            366,
            439,
            869,
            3179,
            337,
            2132,
            13,
            51080
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24687400873560106,
          "compression_ratio": 1.760797342192691,
          "no_speech_prob": 0.5037438273429871
        },
        {
          "id": 14,
          "seek": 2876,
          "start": 43.08,
          "end": 47.040000000000006,
          "text": " And of course, understanding what these models are doing, understanding the mind better.",
          "tokens": [
            51080,
            400,
            295,
            1164,
            11,
            3701,
            437,
            613,
            5245,
            366,
            884,
            11,
            3701,
            264,
            1575,
            1101,
            13,
            51278
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24687400873560106,
          "compression_ratio": 1.760797342192691,
          "no_speech_prob": 0.5037438273429871
        },
        {
          "id": 15,
          "seek": 2876,
          "start": 47.040000000000006,
          "end": 49.28,
          "text": " Can they help us understand the mind in some way?",
          "tokens": [
            51278,
            1664,
            436,
            854,
            505,
            1223,
            264,
            1575,
            294,
            512,
            636,
            30,
            51390
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24687400873560106,
          "compression_ratio": 1.760797342192691,
          "no_speech_prob": 0.5037438273429871
        },
        {
          "id": 16,
          "seek": 2876,
          "start": 49.28,
          "end": 51.56,
          "text": " I'm sure psychologists are thinking about that.",
          "tokens": [
            51390,
            286,
            478,
            988,
            41562,
            366,
            1953,
            466,
            300,
            13,
            51504
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24687400873560106,
          "compression_ratio": 1.760797342192691,
          "no_speech_prob": 0.5037438273429871
        },
        {
          "id": 17,
          "seek": 2876,
          "start": 51.56,
          "end": 52.56,
          "text": " There's work already.",
          "tokens": [
            51504,
            821,
            311,
            589,
            1217,
            13,
            51554
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24687400873560106,
          "compression_ratio": 1.760797342192691,
          "no_speech_prob": 0.5037438273429871
        },
        {
          "id": 18,
          "seek": 5256,
          "start": 52.56,
          "end": 58.72,
          "text": " I've seen work in linguistics on, say, using GANs and adversarial methods to model linguistics",
          "tokens": [
            50364,
            286,
            600,
            1612,
            589,
            294,
            21766,
            6006,
            322,
            11,
            584,
            11,
            1228,
            460,
            1770,
            82,
            293,
            17641,
            44745,
            7150,
            281,
            2316,
            21766,
            6006,
            50672
          ],
          "temperature": 0.0,
          "avg_logprob": -0.289152311242145,
          "compression_ratio": 1.6666666666666667,
          "no_speech_prob": 0.4144881069660187
        },
        {
          "id": 19,
          "seek": 5256,
          "start": 58.72,
          "end": 60.68000000000001,
          "text": " in other species.",
          "tokens": [
            50672,
            294,
            661,
            6172,
            13,
            50770
          ],
          "temperature": 0.0,
          "avg_logprob": -0.289152311242145,
          "compression_ratio": 1.6666666666666667,
          "no_speech_prob": 0.4144881069660187
        },
        {
          "id": 20,
          "seek": 5256,
          "start": 60.68000000000001,
          "end": 63.160000000000004,
          "text": " So there's always more research questions.",
          "tokens": [
            50770,
            407,
            456,
            311,
            1009,
            544,
            2132,
            1651,
            13,
            50894
          ],
          "temperature": 0.0,
          "avg_logprob": -0.289152311242145,
          "compression_ratio": 1.6666666666666667,
          "no_speech_prob": 0.4144881069660187
        },
        {
          "id": 21,
          "seek": 5256,
          "start": 63.160000000000004,
          "end": 66.64,
          "text": " And if you're interested in being in industry and business, then go do that.",
          "tokens": [
            50894,
            400,
            498,
            291,
            434,
            3102,
            294,
            885,
            294,
            3518,
            293,
            1606,
            11,
            550,
            352,
            360,
            300,
            13,
            51068
          ],
          "temperature": 0.0,
          "avg_logprob": -0.289152311242145,
          "compression_ratio": 1.6666666666666667,
          "no_speech_prob": 0.4144881069660187
        },
        {
          "id": 22,
          "seek": 5256,
          "start": 66.64,
          "end": 70.32000000000001,
          "text": " And if you're interested in research, then find a problem that just really interests",
          "tokens": [
            51068,
            400,
            498,
            291,
            434,
            3102,
            294,
            2132,
            11,
            550,
            915,
            257,
            1154,
            300,
            445,
            534,
            8847,
            51252
          ],
          "temperature": 0.0,
          "avg_logprob": -0.289152311242145,
          "compression_ratio": 1.6666666666666667,
          "no_speech_prob": 0.4144881069660187
        },
        {
          "id": 23,
          "seek": 5256,
          "start": 70.32000000000001,
          "end": 72.32000000000001,
          "text": " you because that's how you can finish your PhD.",
          "tokens": [
            51252,
            291,
            570,
            300,
            311,
            577,
            291,
            393,
            2413,
            428,
            14476,
            13,
            51352
          ],
          "temperature": 0.0,
          "avg_logprob": -0.289152311242145,
          "compression_ratio": 1.6666666666666667,
          "no_speech_prob": 0.4144881069660187
        }
      ],
      "language": "en"
    },
    {
      "text": " And just to bring it to a close, what's coming up in your life that listeners might be interested to know about? Is there a project or an event on the horizon?",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 5.92,
          "text": " And just to bring it to a close, what's coming up in your life that listeners might be interested",
          "tokens": [
            50364,
            400,
            445,
            281,
            1565,
            309,
            281,
            257,
            1998,
            11,
            437,
            311,
            1348,
            493,
            294,
            428,
            993,
            300,
            23274,
            1062,
            312,
            3102,
            50660
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25969540200582364,
          "compression_ratio": 1.2926829268292683,
          "no_speech_prob": 0.0006954994751140475
        },
        {
          "id": 1,
          "seek": 0,
          "start": 5.92,
          "end": 9.68,
          "text": " to know about? Is there a project or an event on the horizon?",
          "tokens": [
            50660,
            281,
            458,
            466,
            30,
            1119,
            456,
            257,
            1716,
            420,
            364,
            2280,
            322,
            264,
            18046,
            30,
            50848
          ],
          "temperature": 0.0,
          "avg_logprob": -0.25969540200582364,
          "compression_ratio": 1.2926829268292683,
          "no_speech_prob": 0.0006954994751140475
        }
      ],
      "language": "en"
    },
    {
      "text": " Well, I think the project that I'm most excited about is working with my PhD student, Chase Stokes, on understanding this interaction between language and visualization. And we just finished a paper that we submitted on if you place text on a chart and the goal of the chart is to make a prediction, how does text impact that prediction? Like who's gonna win an election by looking at this chart? And we actually found surprisingly that the text did not influence the prediction all that much in this case where people relied more on the visual input. But in another study we did where it was more what are you taking away information-wise than the way the text was used did have an influence. So we really need to do is understand this interplay more. And I'm just very excited about that topic. I know it's kind of a niche topic, but it's what interests me.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 1.96,
          "text": " Well, I think the project that I'm most excited about",
          "tokens": [
            50364,
            1042,
            11,
            286,
            519,
            264,
            1716,
            300,
            286,
            478,
            881,
            2919,
            466,
            50462
          ],
          "temperature": 0.0,
          "avg_logprob": -0.1974460177951389,
          "compression_ratio": 1.674772036474164,
          "no_speech_prob": 0.0014541305135935545
        },
        {
          "id": 1,
          "seek": 0,
          "start": 1.96,
          "end": 4.42,
          "text": " is working with my PhD student, Chase Stokes,",
          "tokens": [
            50462,
            307,
            1364,
            365,
            452,
            14476,
            3107,
            11,
            21384,
            745,
            8606,
            11,
            50585
          ],
          "temperature": 0.0,
          "avg_logprob": -0.1974460177951389,
          "compression_ratio": 1.674772036474164,
          "no_speech_prob": 0.0014541305135935545
        },
        {
          "id": 2,
          "seek": 0,
          "start": 4.42,
          "end": 6.140000000000001,
          "text": " on understanding this interaction",
          "tokens": [
            50585,
            322,
            3701,
            341,
            9285,
            50671
          ],
          "temperature": 0.0,
          "avg_logprob": -0.1974460177951389,
          "compression_ratio": 1.674772036474164,
          "no_speech_prob": 0.0014541305135935545
        },
        {
          "id": 3,
          "seek": 0,
          "start": 6.140000000000001,
          "end": 7.66,
          "text": " between language and visualization.",
          "tokens": [
            50671,
            1296,
            2856,
            293,
            25801,
            13,
            50747
          ],
          "temperature": 0.0,
          "avg_logprob": -0.1974460177951389,
          "compression_ratio": 1.674772036474164,
          "no_speech_prob": 0.0014541305135935545
        },
        {
          "id": 4,
          "seek": 0,
          "start": 7.66,
          "end": 10.200000000000001,
          "text": " And we just finished a paper that we submitted",
          "tokens": [
            50747,
            400,
            321,
            445,
            4335,
            257,
            3035,
            300,
            321,
            14405,
            50874
          ],
          "temperature": 0.0,
          "avg_logprob": -0.1974460177951389,
          "compression_ratio": 1.674772036474164,
          "no_speech_prob": 0.0014541305135935545
        },
        {
          "id": 5,
          "seek": 0,
          "start": 10.200000000000001,
          "end": 13.92,
          "text": " on if you place text on a chart",
          "tokens": [
            50874,
            322,
            498,
            291,
            1081,
            2487,
            322,
            257,
            6927,
            51060
          ],
          "temperature": 0.0,
          "avg_logprob": -0.1974460177951389,
          "compression_ratio": 1.674772036474164,
          "no_speech_prob": 0.0014541305135935545
        },
        {
          "id": 6,
          "seek": 0,
          "start": 13.92,
          "end": 16.82,
          "text": " and the goal of the chart is to make a prediction,",
          "tokens": [
            51060,
            293,
            264,
            3387,
            295,
            264,
            6927,
            307,
            281,
            652,
            257,
            17630,
            11,
            51205
          ],
          "temperature": 0.0,
          "avg_logprob": -0.1974460177951389,
          "compression_ratio": 1.674772036474164,
          "no_speech_prob": 0.0014541305135935545
        },
        {
          "id": 7,
          "seek": 0,
          "start": 16.82,
          "end": 18.66,
          "text": " how does text impact that prediction?",
          "tokens": [
            51205,
            577,
            775,
            2487,
            2712,
            300,
            17630,
            30,
            51297
          ],
          "temperature": 0.0,
          "avg_logprob": -0.1974460177951389,
          "compression_ratio": 1.674772036474164,
          "no_speech_prob": 0.0014541305135935545
        },
        {
          "id": 8,
          "seek": 0,
          "start": 18.66,
          "end": 21.26,
          "text": " Like who's gonna win an election by looking at this chart?",
          "tokens": [
            51297,
            1743,
            567,
            311,
            799,
            1942,
            364,
            6618,
            538,
            1237,
            412,
            341,
            6927,
            30,
            51427
          ],
          "temperature": 0.0,
          "avg_logprob": -0.1974460177951389,
          "compression_ratio": 1.674772036474164,
          "no_speech_prob": 0.0014541305135935545
        },
        {
          "id": 9,
          "seek": 0,
          "start": 21.26,
          "end": 22.86,
          "text": " And we actually found surprisingly",
          "tokens": [
            51427,
            400,
            321,
            767,
            1352,
            17600,
            51507
          ],
          "temperature": 0.0,
          "avg_logprob": -0.1974460177951389,
          "compression_ratio": 1.674772036474164,
          "no_speech_prob": 0.0014541305135935545
        },
        {
          "id": 10,
          "seek": 0,
          "start": 22.86,
          "end": 26.26,
          "text": " that the text did not influence the prediction all that much",
          "tokens": [
            51507,
            300,
            264,
            2487,
            630,
            406,
            6503,
            264,
            17630,
            439,
            300,
            709,
            51677
          ],
          "temperature": 0.0,
          "avg_logprob": -0.1974460177951389,
          "compression_ratio": 1.674772036474164,
          "no_speech_prob": 0.0014541305135935545
        },
        {
          "id": 11,
          "seek": 0,
          "start": 26.26,
          "end": 29.28,
          "text": " in this case where people relied more on the visual input.",
          "tokens": [
            51677,
            294,
            341,
            1389,
            689,
            561,
            35463,
            544,
            322,
            264,
            5056,
            4846,
            13,
            51828
          ],
          "temperature": 0.0,
          "avg_logprob": -0.1974460177951389,
          "compression_ratio": 1.674772036474164,
          "no_speech_prob": 0.0014541305135935545
        },
        {
          "id": 12,
          "seek": 2928,
          "start": 29.28,
          "end": 31.580000000000002,
          "text": " But in another study we did where it was more",
          "tokens": [
            50364,
            583,
            294,
            1071,
            2979,
            321,
            630,
            689,
            309,
            390,
            544,
            50479
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21047055861529182,
          "compression_ratio": 1.5049019607843137,
          "no_speech_prob": 4.93675543111749e-06
        },
        {
          "id": 13,
          "seek": 2928,
          "start": 31.580000000000002,
          "end": 33.54,
          "text": " what are you taking away information-wise",
          "tokens": [
            50479,
            437,
            366,
            291,
            1940,
            1314,
            1589,
            12,
            3711,
            50577
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21047055861529182,
          "compression_ratio": 1.5049019607843137,
          "no_speech_prob": 4.93675543111749e-06
        },
        {
          "id": 14,
          "seek": 2928,
          "start": 33.54,
          "end": 36.980000000000004,
          "text": " than the way the text was used did have an influence.",
          "tokens": [
            50577,
            813,
            264,
            636,
            264,
            2487,
            390,
            1143,
            630,
            362,
            364,
            6503,
            13,
            50749
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21047055861529182,
          "compression_ratio": 1.5049019607843137,
          "no_speech_prob": 4.93675543111749e-06
        },
        {
          "id": 15,
          "seek": 2928,
          "start": 36.980000000000004,
          "end": 40.0,
          "text": " So we really need to do is understand this interplay more.",
          "tokens": [
            50749,
            407,
            321,
            534,
            643,
            281,
            360,
            307,
            1223,
            341,
            728,
            2858,
            544,
            13,
            50900
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21047055861529182,
          "compression_ratio": 1.5049019607843137,
          "no_speech_prob": 4.93675543111749e-06
        },
        {
          "id": 16,
          "seek": 2928,
          "start": 40.0,
          "end": 42.120000000000005,
          "text": " And I'm just very excited about that topic.",
          "tokens": [
            50900,
            400,
            286,
            478,
            445,
            588,
            2919,
            466,
            300,
            4829,
            13,
            51006
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21047055861529182,
          "compression_ratio": 1.5049019607843137,
          "no_speech_prob": 4.93675543111749e-06
        },
        {
          "id": 17,
          "seek": 2928,
          "start": 42.120000000000005,
          "end": 43.32,
          "text": " I know it's kind of a niche topic,",
          "tokens": [
            51006,
            286,
            458,
            309,
            311,
            733,
            295,
            257,
            19956,
            4829,
            11,
            51066
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21047055861529182,
          "compression_ratio": 1.5049019607843137,
          "no_speech_prob": 4.93675543111749e-06
        },
        {
          "id": 18,
          "seek": 2928,
          "start": 43.32,
          "end": 44.68,
          "text": " but it's what interests me.",
          "tokens": [
            51066,
            457,
            309,
            311,
            437,
            8847,
            385,
            13,
            51134
          ],
          "temperature": 0.0,
          "avg_logprob": -0.21047055861529182,
          "compression_ratio": 1.5049019607843137,
          "no_speech_prob": 4.93675543111749e-06
        }
      ],
      "language": "en"
    },
    {
      "text": " Oh, far from niche. We're going into a very momentous political year and these little interactions between a person and a piece of information can have massive, massive effects. You're right. We don't really understand how they work. Do we?",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 1.0,
          "text": " Oh, far from niche.",
          "tokens": [
            50364,
            876,
            11,
            1400,
            490,
            19956,
            13,
            50414
          ],
          "temperature": 0.0,
          "avg_logprob": -0.35971303419633344,
          "compression_ratio": 1.4035087719298245,
          "no_speech_prob": 0.0007655209628865123
        },
        {
          "id": 1,
          "seek": 0,
          "start": 1.0,
          "end": 6.5200000000000005,
          "text": " We're going into a very momentous political year and these little",
          "tokens": [
            50414,
            492,
            434,
            516,
            666,
            257,
            588,
            1623,
            563,
            3905,
            1064,
            293,
            613,
            707,
            50690
          ],
          "temperature": 0.0,
          "avg_logprob": -0.35971303419633344,
          "compression_ratio": 1.4035087719298245,
          "no_speech_prob": 0.0007655209628865123
        },
        {
          "id": 2,
          "seek": 0,
          "start": 6.640000000000001,
          "end": 11.120000000000001,
          "text": " interactions between a person and a piece of information can have massive,",
          "tokens": [
            50696,
            13280,
            1296,
            257,
            954,
            293,
            257,
            2522,
            295,
            1589,
            393,
            362,
            5994,
            11,
            50920
          ],
          "temperature": 0.0,
          "avg_logprob": -0.35971303419633344,
          "compression_ratio": 1.4035087719298245,
          "no_speech_prob": 0.0007655209628865123
        },
        {
          "id": 3,
          "seek": 0,
          "start": 11.120000000000001,
          "end": 12.040000000000001,
          "text": " massive effects.",
          "tokens": [
            50920,
            5994,
            5065,
            13,
            50966
          ],
          "temperature": 0.0,
          "avg_logprob": -0.35971303419633344,
          "compression_ratio": 1.4035087719298245,
          "no_speech_prob": 0.0007655209628865123
        },
        {
          "id": 4,
          "seek": 0,
          "start": 12.200000000000001,
          "end": 12.64,
          "text": " You're right.",
          "tokens": [
            50974,
            509,
            434,
            558,
            13,
            50996
          ],
          "temperature": 0.0,
          "avg_logprob": -0.35971303419633344,
          "compression_ratio": 1.4035087719298245,
          "no_speech_prob": 0.0007655209628865123
        },
        {
          "id": 5,
          "seek": 0,
          "start": 12.68,
          "end": 14.16,
          "text": " We don't really understand how they work.",
          "tokens": [
            50998,
            492,
            500,
            380,
            534,
            1223,
            577,
            436,
            589,
            13,
            51072
          ],
          "temperature": 0.0,
          "avg_logprob": -0.35971303419633344,
          "compression_ratio": 1.4035087719298245,
          "no_speech_prob": 0.0007655209628865123
        },
        {
          "id": 6,
          "seek": 0,
          "start": 14.24,
          "end": 14.64,
          "text": " Do we?",
          "tokens": [
            51076,
            1144,
            321,
            30,
            51096
          ],
          "temperature": 0.0,
          "avg_logprob": -0.35971303419633344,
          "compression_ratio": 1.4035087719298245,
          "no_speech_prob": 0.0007655209628865123
        }
      ],
      "language": "en"
    },
    {
      "text": " No, I like to work in topics where there isn't a lot of work at that time, like search interfaces and so on. And then when it becomes popular, I tend to move on. I think I can't compete or something. So I have to find a new thing that nobody's thinking about.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 4.96,
          "text": " No, I like to work in topics where there isn't a lot of work at that time, like search interfaces",
          "tokens": [
            50364,
            883,
            11,
            286,
            411,
            281,
            589,
            294,
            8378,
            689,
            456,
            1943,
            380,
            257,
            688,
            295,
            589,
            412,
            300,
            565,
            11,
            411,
            3164,
            28416,
            50612
          ],
          "temperature": 0.0,
          "avg_logprob": -0.223611238840464,
          "compression_ratio": 1.505813953488372,
          "no_speech_prob": 0.002972546499222517
        },
        {
          "id": 1,
          "seek": 0,
          "start": 4.96,
          "end": 5.96,
          "text": " and so on.",
          "tokens": [
            50612,
            293,
            370,
            322,
            13,
            50662
          ],
          "temperature": 0.0,
          "avg_logprob": -0.223611238840464,
          "compression_ratio": 1.505813953488372,
          "no_speech_prob": 0.002972546499222517
        },
        {
          "id": 2,
          "seek": 0,
          "start": 5.96,
          "end": 7.5600000000000005,
          "text": " And then when it becomes popular, I tend to move on.",
          "tokens": [
            50662,
            400,
            550,
            562,
            309,
            3643,
            3743,
            11,
            286,
            3928,
            281,
            1286,
            322,
            13,
            50742
          ],
          "temperature": 0.0,
          "avg_logprob": -0.223611238840464,
          "compression_ratio": 1.505813953488372,
          "no_speech_prob": 0.002972546499222517
        },
        {
          "id": 3,
          "seek": 0,
          "start": 7.5600000000000005,
          "end": 9.64,
          "text": " I think I can't compete or something.",
          "tokens": [
            50742,
            286,
            519,
            286,
            393,
            380,
            11831,
            420,
            746,
            13,
            50846
          ],
          "temperature": 0.0,
          "avg_logprob": -0.223611238840464,
          "compression_ratio": 1.505813953488372,
          "no_speech_prob": 0.002972546499222517
        },
        {
          "id": 4,
          "seek": 0,
          "start": 9.64,
          "end": 11.76,
          "text": " So I have to find a new thing that nobody's thinking about.",
          "tokens": [
            50846,
            407,
            286,
            362,
            281,
            915,
            257,
            777,
            551,
            300,
            5079,
            311,
            1953,
            466,
            13,
            50952
          ],
          "temperature": 0.0,
          "avg_logprob": -0.223611238840464,
          "compression_ratio": 1.505813953488372,
          "no_speech_prob": 0.002972546499222517
        }
      ],
      "language": "en"
    },
    {
      "text": " Uh oh, I might have just ruined your picnic. Now everyone's going to get interested in language and visualization.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 1.84,
          "text": " Uh oh, I might have just ruined your picnic.",
          "tokens": [
            50364,
            4019,
            1954,
            11,
            286,
            1062,
            362,
            445,
            17013,
            428,
            32137,
            13,
            50456
          ],
          "temperature": 0.0,
          "avg_logprob": -0.4453045981270926,
          "compression_ratio": 1.1287128712871286,
          "no_speech_prob": 0.0008647155482321978
        },
        {
          "id": 1,
          "seek": 0,
          "start": 1.84,
          "end": 4.88,
          "text": " Now everyone's going to get interested in language and visualization.",
          "tokens": [
            50456,
            823,
            1518,
            311,
            516,
            281,
            483,
            3102,
            294,
            2856,
            293,
            25801,
            13,
            50608
          ],
          "temperature": 0.0,
          "avg_logprob": -0.4453045981270926,
          "compression_ratio": 1.1287128712871286,
          "no_speech_prob": 0.0008647155482321978
        }
      ],
      "language": "en"
    },
    {
      "text": " No, no, I want that. In fact, the keynote I gave, I think, you know, helped with that. So I want people to be working on this.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 1.0,
          "text": " No, no, I want that.",
          "tokens": [
            50364,
            883,
            11,
            572,
            11,
            286,
            528,
            300,
            13,
            50414
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3475294556728629,
          "compression_ratio": 1.2115384615384615,
          "no_speech_prob": 0.0012203468941152096
        },
        {
          "id": 1,
          "seek": 0,
          "start": 1.0,
          "end": 3.64,
          "text": " In fact, the keynote I gave, I think, you know, helped with that.",
          "tokens": [
            50414,
            682,
            1186,
            11,
            264,
            33896,
            286,
            2729,
            11,
            286,
            519,
            11,
            291,
            458,
            11,
            4254,
            365,
            300,
            13,
            50546
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3475294556728629,
          "compression_ratio": 1.2115384615384615,
          "no_speech_prob": 0.0012203468941152096
        },
        {
          "id": 2,
          "seek": 0,
          "start": 3.64,
          "end": 5.6000000000000005,
          "text": " So I want people to be working on this.",
          "tokens": [
            50546,
            407,
            286,
            528,
            561,
            281,
            312,
            1364,
            322,
            341,
            13,
            50644
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3475294556728629,
          "compression_ratio": 1.2115384615384615,
          "no_speech_prob": 0.0012203468941152096
        }
      ],
      "language": "en"
    },
    {
      "text": " Marti, thanks so much for talking with us.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 2.0,
          "text": " Marti, thanks so much for talking with us.",
          "tokens": [
            50364,
            5807,
            72,
            11,
            3231,
            370,
            709,
            337,
            1417,
            365,
            505,
            13,
            50464
          ],
          "temperature": 0.0,
          "avg_logprob": -0.3932268960135324,
          "compression_ratio": 0.84,
          "no_speech_prob": 0.0003602959623094648
        }
      ],
      "language": "en"
    },
    {
      "text": " It was a pleasure, really fun.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 1.8,
          "text": " It was a pleasure, really fun.",
          "tokens": [
            50364,
            467,
            390,
            257,
            6834,
            11,
            534,
            1019,
            13,
            50454
          ],
          "temperature": 0.0,
          "avg_logprob": -0.4764642281965776,
          "compression_ratio": 0.7894736842105263,
          "no_speech_prob": 0.00015959401207510382
        }
      ],
      "language": "en"
    },
    {
      "text": " All right, everyone, that's our show for today. To learn more about today's guest or the topics mentioned in this interview, visit twimmelai.com. Of course, if you like what you hear on the podcast, please subscribe, rate, and review the show on your favorite podcatcher. Thanks so much for listening and catch you next time.",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 3.12,
          "text": " All right, everyone, that's our show for today.",
          "tokens": [
            50364,
            1057,
            558,
            11,
            1518,
            11,
            300,
            311,
            527,
            855,
            337,
            965,
            13,
            50520
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24906966997229535,
          "compression_ratio": 1.5258215962441315,
          "no_speech_prob": 0.00042139459401369095
        },
        {
          "id": 1,
          "seek": 0,
          "start": 3.12,
          "end": 4.68,
          "text": " To learn more about today's guest",
          "tokens": [
            50520,
            1407,
            1466,
            544,
            466,
            965,
            311,
            8341,
            50598
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24906966997229535,
          "compression_ratio": 1.5258215962441315,
          "no_speech_prob": 0.00042139459401369095
        },
        {
          "id": 2,
          "seek": 0,
          "start": 4.68,
          "end": 6.76,
          "text": " or the topics mentioned in this interview,",
          "tokens": [
            50598,
            420,
            264,
            8378,
            2835,
            294,
            341,
            4049,
            11,
            50702
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24906966997229535,
          "compression_ratio": 1.5258215962441315,
          "no_speech_prob": 0.00042139459401369095
        },
        {
          "id": 3,
          "seek": 0,
          "start": 6.76,
          "end": 9.08,
          "text": " visit twimmelai.com.",
          "tokens": [
            50702,
            3441,
            683,
            6753,
            4053,
            72,
            13,
            1112,
            13,
            50818
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24906966997229535,
          "compression_ratio": 1.5258215962441315,
          "no_speech_prob": 0.00042139459401369095
        },
        {
          "id": 4,
          "seek": 0,
          "start": 9.08,
          "end": 11.8,
          "text": " Of course, if you like what you hear on the podcast,",
          "tokens": [
            50818,
            2720,
            1164,
            11,
            498,
            291,
            411,
            437,
            291,
            1568,
            322,
            264,
            7367,
            11,
            50954
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24906966997229535,
          "compression_ratio": 1.5258215962441315,
          "no_speech_prob": 0.00042139459401369095
        },
        {
          "id": 5,
          "seek": 0,
          "start": 11.8,
          "end": 14.72,
          "text": " please subscribe, rate, and review the show",
          "tokens": [
            50954,
            1767,
            3022,
            11,
            3314,
            11,
            293,
            3131,
            264,
            855,
            51100
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24906966997229535,
          "compression_ratio": 1.5258215962441315,
          "no_speech_prob": 0.00042139459401369095
        },
        {
          "id": 6,
          "seek": 0,
          "start": 14.72,
          "end": 16.88,
          "text": " on your favorite podcatcher.",
          "tokens": [
            51100,
            322,
            428,
            2954,
            2497,
            66,
            49871,
            13,
            51208
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24906966997229535,
          "compression_ratio": 1.5258215962441315,
          "no_speech_prob": 0.00042139459401369095
        },
        {
          "id": 7,
          "seek": 0,
          "start": 16.88,
          "end": 19.8,
          "text": " Thanks so much for listening and catch you next time.",
          "tokens": [
            51208,
            2561,
            370,
            709,
            337,
            4764,
            293,
            3745,
            291,
            958,
            565,
            13,
            51354
          ],
          "temperature": 0.0,
          "avg_logprob": -0.24906966997229535,
          "compression_ratio": 1.5258215962441315,
          "no_speech_prob": 0.00042139459401369095
        }
      ],
      "language": "en"
    },
    {
      "text": " you",
      "segments": [
        {
          "id": 0,
          "seek": 0,
          "start": 0.0,
          "end": 2.06,
          "text": " you",
          "tokens": [
            50364,
            291,
            50467
          ],
          "temperature": 0.0,
          "avg_logprob": -0.9541356563568115,
          "compression_ratio": 0.2727272727272727,
          "no_speech_prob": 0.9292590022087097
        }
      ],
      "language": "en"
    }
  ]
}